{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "545c0beb",
   "metadata": {},
   "source": [
    "# üìò Tutorial PySpark: Fun√ß√µes de Agrega√ß√£o e Cria√ß√£o de Fun√ß√µes Personalizadas\n",
    "\n",
    "## Objetivo Geral\n",
    "- Apresentar os principais conceitos e ferramentas do PySpark relacionados a agrupamentos e agrega√ß√µes de dados.  \n",
    "- Ensinar como criar fun√ß√µes personalizadas e aplic√°-las com `groupBy`.  \n",
    "- Preparar a base conceitual para c√°lculos como o PSI (Population Stability Index), mas com aplicabilidade mais ampla.  \n",
    "\n",
    "---\n",
    "\n",
    "## Sum√°rio\n",
    "\n",
    "\n",
    "1. [Prepara√ß√£o do Ambiente](#2-prepara√ß√£o-do-ambiente)\n",
    "2. [Introdu√ß√£o ao PySpark](#1-introdu√ß√£o-ao-pyspark)  \n",
    "3. [Explora√ß√£o do Dataset](#3-explora√ß√£o-do-dataset)  \n",
    "4. [üîç Agrupamentos com groupBy](#4-agrupamentos-com-groupby)  \n",
    "5. [üß± Janela e Agrupamentos Avan√ßados](#5-janela-e-agrupamentos-avan√ßados)  \n",
    "6. [üõ†Ô∏è Fun√ß√µes Personalizadas com UDF](#6-fun√ß√µes-personalizadas-com-udf)  \n",
    "7. [üß™ Estudos de Caso](#7-estudos-de-caso)  \n",
    "8. [üìä Exemplo Aplicado: C√°lculo do PSI](#8-exemplo-aplicado-c√°lculo-do-psi)  \n",
    "9. [üîö Conclus√µes e Pr√≥ximos Passos](#9-conclus√µes-e-pr√≥ximos-passos)  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f1e6e",
   "metadata": {},
   "source": [
    "## 1. Prepara√ß√£o do Ambiente\n",
    "\n",
    "### 1.1. Importa√ß√µes necess√°rias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85671a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas padr√£o\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PySpark - Sess√£o\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# PySpark - Fun√ß√µes\n",
    "from pyspark.sql.functions import (\n",
    "    concat_ws,\n",
    "    avg,\n",
    "    col,\n",
    "    count,\n",
    "    lit,\n",
    "    log,\n",
    "    percentile_approx,\n",
    "    sum as Fsum,\n",
    "    udf,\n",
    "    when,\n",
    "    to_date,\n",
    "    lpad,\n",
    ")\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# PySpark - Tipos\n",
    "from pyspark.sql.types import IntegerType, StringType, DoubleType\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "\n",
    "# PySpark - Janela\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a8996",
   "metadata": {},
   "source": [
    "### 1.2. Simula√ß√£o de um dataset \n",
    "\n",
    "Iremos simular um dataset com colunas `score`, `ambiente`, `modelo`, `target`.\n",
    "\n",
    "üéØ Objetivo:\n",
    "\t‚Ä¢\tSimular dois modelos (modelo_a, modelo_b)\n",
    "\t‚Ä¢\tCada um com dados nos ambientes:\n",
    "\t‚Ä¢\tDEV: 6 meses\n",
    "\t‚Ä¢\tOOT: 3 meses\n",
    "\t‚Ä¢\tPRD: 12 meses\n",
    "\t‚Ä¢\tmodelo_a permanece calibrado\n",
    "\t‚Ä¢\tmodelo_b vai descalibrando ao longo do tempo\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üì¶ Etapas da simula√ß√£o:\n",
    "\t1.\tGerar uma base com colunas: score, env, year, month, model\n",
    "\t2.\tmodelo_a: score est√°vel em todos os ambientes\n",
    "\t3.\tmodelo_b: score muda ao longo do tempo (ex: m√©dia ou vari√¢ncia cresce em PRD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d300da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de eventos no total: 9.024%\n",
      "      model  env  year  month     score  vr\n",
      "0  modelo_a  DEV  2023      1  0.065236   0\n",
      "1  modelo_a  DEV  2023      1  0.010000   0\n",
      "2  modelo_a  DEV  2023      1  0.087523   0\n",
      "3  modelo_a  DEV  2023      1  0.097028   0\n",
      "4  modelo_a  DEV  2023      1  0.010000   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def simulate_model_data(model_name, start_year=2023):\n",
    "    \"\"\"\n",
    "    Simula scores e vari√°vel resposta para um modelo nos ambientes DEV, OOT e PRD.\n",
    "    \n",
    "    - modelo_a: score calibrado e est√°vel\n",
    "    - modelo_b: score descalibrando em PRD (aumenta m√©dia ao longo do tempo)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    rng = np.random.default_rng(seed=42 if model_name == 'modelo_a' else 99)\n",
    "\n",
    "    def generate_block(env, year, month, loc, size=1000):\n",
    "        # Gera scores com m√©dia 'loc' e desvio padr√£o 0.05\n",
    "        scores = rng.normal(loc=loc, scale=0.05, size=size)\n",
    "        scores = np.clip(scores, 0.01, 0.99)\n",
    "        vr = rng.binomial(1, p=scores)\n",
    "        return pd.DataFrame({\n",
    "            'model': model_name,\n",
    "            'env': env,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'score': scores,\n",
    "            'vr': vr\n",
    "        })\n",
    "\n",
    "    # Par√¢metros calibrados para taxa de evento baixa (~5%)\n",
    "    base_loc = 0.05\n",
    "    incremento = 0.02\n",
    "\n",
    "    # Ambiente DEV (6 meses est√°veis)\n",
    "    for month in range(1, 7):\n",
    "        rows.append(generate_block('DEV', start_year, month, loc=base_loc))\n",
    "\n",
    "    # Ambiente OOT (3 meses)\n",
    "    for month in range(7, 10):\n",
    "        loc = base_loc if model_name == 'modelo_a' else base_loc + 0.01\n",
    "        rows.append(generate_block('OOT', start_year, month, loc=loc))\n",
    "\n",
    "    # Ambiente PRD (12 meses)\n",
    "    for month in range(1, 13):\n",
    "        year = start_year + 1\n",
    "        loc = base_loc if model_name == 'modelo_a' else base_loc + incremento * month\n",
    "        rows.append(generate_block('PRD', year, month, loc=loc))\n",
    "\n",
    "    return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# Gerar os dados simulados\n",
    "df_a = simulate_model_data('modelo_a')\n",
    "df_b = simulate_model_data('modelo_b')\n",
    "df = pd.concat([df_a, df_b], ignore_index=True)\n",
    "\n",
    "# Checar taxa de eventos\n",
    "taxa_eventos = df['vr'].mean()\n",
    "print(f\"Taxa de eventos no total: {taxa_eventos:.3%}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae91a50",
   "metadata": {},
   "source": [
    "üß™ Colunas do DataFrame final:\n",
    "\n",
    "* model: \"modelo_a\" ou \"modelo_b\"\n",
    "* env: ambiente (DEV, OOT, PRD)\n",
    "* year: ano\n",
    "* month: m√™s\n",
    "* score: probabilidade estimada pelo modelo (entre 0 e 1)\n",
    "* vr: vari√°vel resposta (0 ou 1), simulada com base no score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db7211c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 2. Introdu√ß√£o ao PySpark\n",
    "\n",
    "### 2.1. Por que usar PySpark para grandes volumes de dados?\n",
    "\n",
    "Em projetos de ci√™ncia de dados ou engenharia de dados que lidam com grandes volumes de informa√ß√£o (de gigabytes a terabytes ou mais), bibliotecas tradicionais como `pandas` deixam de ser eficientes, pois operam em mem√≥ria (RAM) e em apenas uma m√°quina. Isso limita o processamento a conjuntos de dados menores e torna as opera√ß√µes mais lentas e sujeitas a erros de mem√≥ria.\n",
    "\n",
    "O **PySpark** √© a API em Python do **Apache Spark**, um motor de processamento distribu√≠do altamente escal√°vel. Ele permite:\n",
    "\n",
    "- **Processamento paralelo em cluster**: divide os dados entre v√°rias m√°quinas ou n√∫cleos.\n",
    "- **Escalabilidade**: funciona localmente, em clusters locais (como com `Spark Standalone`) ou em ambientes distribu√≠dos como Hadoop/YARN, Kubernetes, Databricks, EMR (AWS), etc.\n",
    "- **Toler√¢ncia a falhas**: reexecuta automaticamente tarefas que falham.\n",
    "- **Alto desempenho**: otimizado para processar dados em lote e em tempo real.\n",
    "\n",
    "> üí° Em resumo: PySpark permite que voc√™ escale seu c√≥digo em Python para trabalhar com big data de maneira eficiente e robusta.\n",
    "\n",
    "\n",
    "### 2.2. O que √© o `SparkSession` e por que ele √© essencial?\n",
    "\n",
    "O `SparkSession` √© a **porta de entrada** para utilizar o PySpark. Ele √© o ponto central por onde voc√™ acessa todas as funcionalidades do Spark, como:\n",
    "\n",
    "- Leitura e escrita de dados (CSV, Parquet, JSON, JDBC, etc.)\n",
    "- Manipula√ß√£o de DataFrames e execu√ß√£o de SQL\n",
    "- Cria√ß√£o de RDDs (Resilient Distributed Datasets)\n",
    "- Configura√ß√£o do ambiente de execu√ß√£o (como n√∫mero de parti√ß√µes, uso de cache, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a26936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/10 21:11:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/Users/cristianooliveira/Documents/funcoes_agregacao_pyspark/.venv/bin/python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/Users/cristianooliveira/Documents/funcoes_agregacao_pyspark/.venv/bin/python'\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Tutorial PySpark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b57eb",
   "metadata": {},
   "source": [
    "üß† Explicando o c√≥digo:\n",
    "\n",
    "*\t.builder: inicia a configura√ß√£o.\n",
    "*\t.appName(\"Tutorial PySpark\"): define o nome da aplica√ß√£o, √∫til para monitoramento.\n",
    "*\t.getOrCreate(): cria a sess√£o Spark se n√£o existir, ou reutiliza uma existente.\n",
    "\n",
    "\n",
    "üìù Nota: O objeto spark ser√° utilizado ao longo de todo o tutorial para criar e manipular DataFrames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5363937f",
   "metadata": {},
   "source": [
    "### 2.3. Transformando o pandas em um dataframe do pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "spkdf = spark.createDataFrame(df)\n",
    "spkdf = spkdf.withColumn(\"periodo\", F.concat(col(\"year\").cast(\"string\"), F.lit(\"-\"), col(\"month\").cast(\"string\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507c932",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Explora√ß√£o do Dataset\n",
    "\n",
    "- Inspe√ß√£o inicial com `.show()`, `.printSchema()`, `.select()`, `.filter()`, `.distinct()`.\n",
    "- Entendimento da estrutura dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a269573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+--------------------+---+\n",
      "|   model|env|year|month|               score| vr|\n",
      "+--------+---+----+-----+--------------------+---+\n",
      "|modelo_a|DEV|2023|    1| 0.06523585398772157|  0|\n",
      "|modelo_a|DEV|2023|    1|                0.01|  0|\n",
      "|modelo_a|DEV|2023|    1| 0.08752255979032286|  0|\n",
      "|modelo_a|DEV|2023|    1|  0.0970282358195607|  0|\n",
      "|modelo_a|DEV|2023|    1|                0.01|  0|\n",
      "|modelo_a|DEV|2023|    1|                0.01|  0|\n",
      "|modelo_a|DEV|2023|    1|0.056392020158364274|  0|\n",
      "|modelo_a|DEV|2023|    1| 0.03418787038282089|  0|\n",
      "|modelo_a|DEV|2023|    1| 0.04915994212478556|  0|\n",
      "|modelo_a|DEV|2023|    1|                0.01|  0|\n",
      "+--------+---+----+-----+--------------------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2648df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- model: string (nullable = true)\n",
      " |-- env: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- month: long (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- vr: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76ce4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|   model|env|\n",
      "+--------+---+\n",
      "|modelo_a|DEV|\n",
      "|modelo_a|DEV|\n",
      "|modelo_a|DEV|\n",
      "+--------+---+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+---+\n",
      "|   model|env|\n",
      "+--------+---+\n",
      "|modelo_a|DEV|\n",
      "|modelo_a|DEV|\n",
      "|modelo_a|DEV|\n",
      "+--------+---+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+---+\n",
      "|   model|env|\n",
      "+--------+---+\n",
      "|modelo_a|DEV|\n",
      "|modelo_a|DEV|\n",
      "|modelo_a|DEV|\n",
      "+--------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Select columns by different ways\n",
    "spkdf.select(\"model\",\"env\").show(3)\n",
    "spkdf.select(spkdf.model,spkdf.env).show(3)\n",
    "spkdf.select(spkdf[\"model\"],spkdf[\"env\"]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93786d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|   model|env|\n",
      "+--------+---+\n",
      "|modelo_a|DEV|\n",
      "|modelo_a|DEV|\n",
      "|modelo_a|DEV|\n",
      "+--------+---+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+\n",
      "|   model|\n",
      "+--------+\n",
      "|modelo_a|\n",
      "|modelo_a|\n",
      "|modelo_a|\n",
      "+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+----+-----+\n",
      "|year|month|\n",
      "+----+-----+\n",
      "|2023|    1|\n",
      "|2023|    1|\n",
      "|2023|    1|\n",
      "+----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By using col() function\n",
    "spkdf.select(col(\"model\"),col(\"env\")).show(3)\n",
    "\n",
    "# Select columns by regular expression\n",
    "spkdf.select(spkdf.colRegex(\"`.*(mod).*`\")).show(3)\n",
    "\n",
    "#Selects columns 2 to 4  and top 3 rows\n",
    "spkdf.select(spkdf.columns[2:4]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac737cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------------------+---+\n",
      "|   model|env|year|month|              score| vr|\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "|modelo_a|DEV|2023|    1|0.06523585398772157|  0|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|\n",
      "|modelo_a|DEV|2023|    1|0.08752255979032286|  0|\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "|   model|env|year|month|              score| vr|\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "|modelo_a|DEV|2023|    1|0.06523585398772157|  0|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|\n",
      "|modelo_a|DEV|2023|    1|0.08752255979032286|  0|\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "|   model|env|year|month|              score| vr|\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "|modelo_a|DEV|2023|    1|0.06523585398772157|  0|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|\n",
      "|modelo_a|DEV|2023|    1|0.08752255979032286|  0|\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "spkdf.filter(col(\"model\") == \"modelo_a\").show(3)\n",
    "spkdf.filter(spkdf.model == \"modelo_a\").show(3)\n",
    "spkdf.filter(\"model = 'modelo_a'\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "537abf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------------------+---+\n",
      "|   model|env|year|month|              score| vr|\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "|modelo_a|DEV|2023|    1|0.06523585398772157|  0|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|\n",
      "|modelo_a|DEV|2023|    1|0.08752255979032286|  0|\n",
      "+--------+---+----+-----+-------------------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf.filter(\"model = 'modelo_a' AND env = 'DEV'\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0b24a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Agrupamentos com `groupBy`\n",
    "\n",
    "O m√©todo `.groupBy()` em PySpark √© usado para agrupar linhas de um DataFrame com base nos valores de uma ou mais colunas, permitindo aplicar fun√ß√µes de agrega√ß√£o sobre esses grupos. Ele √© equivalente ao `groupby()` do pandas, mas funciona de forma distribu√≠da e escal√°vel.\n",
    "\n",
    "\n",
    "### 4.1. Sintaxe b√°sica\n",
    "\n",
    "```python\n",
    "df.groupBy(\"coluna\").agg(fun√ß√£o_agregadora)\n",
    "```\n",
    "\n",
    "Voc√™ pode agrupar por uma ou mais colunas, e aplicar fun√ß√µes como `count()`, `sum()`, `avg()`, `min()`, `max()`, entre outras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20bcfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   model|count|\n",
      "+--------+-----+\n",
      "|modelo_a|21000|\n",
      "|modelo_b|21000|\n",
      "+--------+-----+\n",
      "\n",
      "+---+--------------------+\n",
      "|env|          avg(score)|\n",
      "+---+--------------------+\n",
      "|PRD|  0.1180247751059192|\n",
      "|OOT| 0.06133385077278047|\n",
      "|DEV|0.055934157757326165|\n",
      "+---+--------------------+\n",
      "\n",
      "+--------+---+-------+\n",
      "|   model|env|sum(vr)|\n",
      "+--------+---+-------+\n",
      "|modelo_a|DEV|    349|\n",
      "|modelo_a|OOT|    205|\n",
      "|modelo_a|PRD|    674|\n",
      "|modelo_b|DEV|    310|\n",
      "|modelo_b|OOT|    206|\n",
      "|modelo_b|PRD|   2046|\n",
      "+--------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contagem de registros por model\n",
    "spkdf.groupBy(\"model\").count().show()\n",
    "\n",
    "# M√©dia de score por env\n",
    "spkdf.groupBy(\"env\").agg(F.avg(\"score\")).show()\n",
    "\n",
    "# Soma de eventos por model e env\n",
    "spkdf.groupBy(\"model\", \"env\").agg(F.sum(\"vr\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c06589c",
   "metadata": {},
   "source": [
    "### 4.2. Agrega√ß√µes m√∫ltiplas com .agg({})\n",
    "\n",
    "Voc√™ pode aplicar v√°rias agrega√ß√µes ao mesmo tempo, inclusive sobre diferentes colunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81e7d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------+\n",
      "|   model|          avg(score)|sum(vr)|\n",
      "+--------+--------------------+-------+\n",
      "|modelo_a|0.056223241218516816|   1228|\n",
      "|modelo_b| 0.12814854927037073|   2562|\n",
      "+--------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf.groupBy(\"model\").agg({\n",
    "    \"score\": \"avg\",\n",
    "    \"vr\": \"sum\"\n",
    "}).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6aebb",
   "metadata": {},
   "source": [
    "\n",
    "‚ö†Ô∏è Essa forma √© mais limitada: voc√™ n√£o pode adicionar alias com nomes personalizados.\n",
    "\n",
    "\n",
    "\n",
    "### 4.3. Agrega√ß√µes m√∫ltiplas com .agg(F.func()) (forma recomendada)\n",
    "\n",
    "A forma mais flex√≠vel √© usando `F.func()` com alias (`.alias(\"nome_coluna\")`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e3ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+--------------------+-------------+--------------------+------------+\n",
      "|   model|env|         media_score|total_eventos|quantidade_registros|exposi√ß√£o(%)|\n",
      "+--------+---+--------------------+-------------+--------------------+------------+\n",
      "|modelo_a|DEV|0.055953284685808936|          349|                6000|        5.82|\n",
      "|modelo_a|OOT|0.056341076211994884|          205|                3000|        6.83|\n",
      "|modelo_a|PRD| 0.05632876073650206|          674|               12000|        5.62|\n",
      "|modelo_b|DEV| 0.05591503082884339|          310|                6000|        5.17|\n",
      "|modelo_b|OOT| 0.06632662533356605|          206|                3000|        6.87|\n",
      "|modelo_b|PRD| 0.17972078947533635|         2046|               12000|       17.05|\n",
      "+--------+---+--------------------+-------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf.groupBy(\"model\", \"env\").agg(\n",
    "    F.avg(\"score\").alias(\"media_score\"),\n",
    "    F.sum(\"vr\").alias(\"total_eventos\"),\n",
    "    F.count(\"*\").alias(\"quantidade_registros\"),\n",
    "    F.round(\n",
    "        (F.sum(\"vr\") / F.count(\"*\")) * 100,\n",
    "        2\n",
    "    ).alias(\"exposi√ß√£o(%)\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c401b",
   "metadata": {},
   "source": [
    "### 4.4. Agrupamentos n√£o agregativos\n",
    "\n",
    "Voc√™ tamb√©m pode usar `groupBy()` para opera√ß√µes que n√£o s√£o diretamente agrega√ß√µes, como `collect_list` e `collect_set`:\n",
    "\n",
    "*\t`collect_list`: junta os valores de uma coluna em listas (permite repeti√ß√£o).\n",
    "*\t`collect_set`: junta os valores sem repetir (como um set).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acfb8919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|   model|        lista_scores|\n",
      "+--------+--------------------+\n",
      "|modelo_a|[0.06523585398772...|\n",
      "|modelo_b|[0.05412471521418...|\n",
      "+--------+--------------------+\n",
      "\n",
      "+--------+----------------+\n",
      "|   model|ambientes_unicos|\n",
      "+--------+----------------+\n",
      "|modelo_a| [DEV, PRD, OOT]|\n",
      "|modelo_b| [DEV, PRD, OOT]|\n",
      "+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lista de scores por model\n",
    "spkdf.groupBy(\"model\").agg(F.collect_list(\"score\").alias(\"lista_scores\")).show(truncate=True)\n",
    "\n",
    "# Conjunto √∫nico de ambientes por model\n",
    "spkdf.groupBy(\"model\").agg(F.collect_set(\"env\").alias(\"ambientes_unicos\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2cd19c",
   "metadata": {},
   "source": [
    "### 4.5.Uso com `.select()` ou `.withColumn()`\n",
    "\n",
    "Em algumas situa√ß√µes, voc√™ pode querer transformar os resultados do groupBy() usando .select() ou .withColumn() para criar colunas derivadas ou realizar novos c√°lculos.\n",
    "\n",
    "Exemplo: criar uma nova coluna com score m√©dio classificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02a5110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------------+\n",
      "|   model|         media_score|classificacao|\n",
      "+--------+--------------------+-------------+\n",
      "|modelo_a|0.056223241218516816|        Baixo|\n",
      "|modelo_b| 0.12814854927037073|        Baixo|\n",
      "+--------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "media_df = spkdf.groupBy(\"model\").agg(F.avg(\"score\").alias(\"media_score\"))\n",
    "\n",
    "# Adiciona uma nova coluna que classifica o score como alto ou baixo\n",
    "media_df = media_df.withColumn(\n",
    "    \"classificacao\",\n",
    "    F.when(F.col(\"media_score\") >= 0.6, \"Alto\").otherwise(\"Baixo\")\n",
    ")\n",
    "\n",
    "media_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ed424",
   "metadata": {},
   "source": [
    "\n",
    "Voc√™ tamb√©m pode fazer .select() para reordenar ou renomear colunas ap√≥s a agrega√ß√£o:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00007ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+\n",
      "|   model|classificacao|         media_score|\n",
      "+--------+-------------+--------------------+\n",
      "|modelo_a|        Baixo|0.056223241218516816|\n",
      "|modelo_b|        Baixo| 0.12814854927037073|\n",
      "+--------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "media_df.select(\"model\", \"classificacao\", \"media_score\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea198ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+--------------------+\n",
      "|   model|env|         media_score|\n",
      "+--------+---+--------------------+\n",
      "|modelo_a|DEV|0.055953284685808936|\n",
      "|modelo_a|OOT|0.056341076211994884|\n",
      "|modelo_a|PRD| 0.05632876073650206|\n",
      "|modelo_b|DEV| 0.05591503082884339|\n",
      "|modelo_b|OOT| 0.06632662533356605|\n",
      "|modelo_b|PRD| 0.17972078947533635|\n",
      "+--------+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf.groupBy(\"model\", \"env\") \\\n",
    "    .agg(F.avg(\"score\").alias(\"media_score\")) \\\n",
    "    .orderBy(\"model\", \"env\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c21a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Janela e Agrupamentos Avan√ßados\n",
    "\n",
    "### 5.1. Diferen√ßa entre groupBy e fun√ß√µes de janela (window functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f9fd20",
   "metadata": {},
   "source": [
    "\n",
    "Embora `groupBy()` e `window functions` (fun√ß√µes de janela) pare√ßam semelhantes √† primeira vista (pois ambos trabalham com agrega√ß√µes), eles t√™m finalidades e comportamentos bem diferentes:\n",
    "\n",
    "\n",
    "\n",
    "| Caracter√≠stica        | `groupBy()`                                  | Window Functions                                           |\n",
    "|-----------------------|-----------------------------------------------|-------------------------------------------------------------|\n",
    "| Tipo de opera√ß√£o      | Reduz a cardinalidade do DataFrame           | Mant√©m a cardinalidade (n√£o reduz n√∫mero de linhas)         |\n",
    "| Retorno por linha     | N√£o (gera 1 linha por grupo)                 | Sim (retorna uma nova coluna com valores agregados)         |\n",
    "| Exemplo de uso        | Soma total por categoria                     | Soma acumulada dentro de cada categoria                     |\n",
    "| Ideal para            | Resumos agregados                            | C√°lculos linha a linha dentro de grupos                     |\n",
    "\n",
    "\n",
    "\n",
    "### 5.2. Uso de Window.partitionBy().orderBy()\n",
    "\n",
    "As fun√ß√µes de janela exigem que voc√™ defina um ‚Äúescopo‚Äù, ou seja, dentro de qual grupo a fun√ß√£o deve operar. Isso √© feito com partitionBy().\n",
    "\n",
    "Voc√™ pode tamb√©m ordenar os dados dentro de cada parti√ß√£o com orderBy() ‚Äî o que √© necess√°rio para fun√ß√µes como rank() ou row_number().\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215d4754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------------------+---+----------+\n",
      "|   model|env|year|month|              score| vr|rank_score|\n",
      "+--------+---+----+-----+-------------------+---+----------+\n",
      "|modelo_a|PRD|2024|   11| 0.2663460370305066|  0|         1|\n",
      "|modelo_a|PRD|2024|    9|  0.254396153541065|  0|         2|\n",
      "|modelo_a|DEV|2023|    5|0.25129120213636325|  0|         3|\n",
      "|modelo_a|PRD|2024|    2|0.22781813927750655|  0|         4|\n",
      "|modelo_a|PRD|2024|    8|0.22382836775265536|  1|         5|\n",
      "+--------+---+----+-----+-------------------+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "janela = Window.partitionBy(\"model\").orderBy(F.desc(\"score\"))\n",
    "\n",
    "spkdf.withColumn(\"rank_score\", F.rank().over(janela)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d2340c",
   "metadata": {},
   "source": [
    "**Exemplo 1**: C√°lculo de propor√ß√µes dentro de grupos\n",
    "\n",
    "Queremos calcular a propor√ß√£o de cada linha em rela√ß√£o ao total do grupo (por exemplo, propor√ß√£o de eventos dentro de cada modelo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd045953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------------------+---+-------------------+\n",
      "|   model|env|year|month|              score| vr|prop_eventos_modelo|\n",
      "+--------+---+----+-----+-------------------+---+-------------------+\n",
      "|modelo_a|DEV|2023|    1|0.06523585398772157|  0|                0.0|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|                0.0|\n",
      "|modelo_a|DEV|2023|    1|0.08752255979032286|  0|                0.0|\n",
      "|modelo_a|DEV|2023|    1| 0.0970282358195607|  0|                0.0|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|                0.0|\n",
      "+--------+---+----+-----+-------------------+---+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "janela_model = Window.partitionBy(\"model\")\n",
    "\n",
    "spkdf.withColumn(\"prop_eventos_modelo\", \n",
    "                F.round(\n",
    "                    F.col(\"vr\") / F.sum(\"vr\").over(janela_model)*100, 2\n",
    "                )\n",
    "                ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97521f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------------------+---+---------+\n",
      "|   model|env|year|month|              score| vr|exposicao|\n",
      "+--------+---+----+-----+-------------------+---+---------+\n",
      "|modelo_a|DEV|2023|    1|0.06523585398772157|  0|     5.82|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|     5.82|\n",
      "|modelo_a|DEV|2023|    1|0.08752255979032286|  0|     5.82|\n",
      "|modelo_a|DEV|2023|    1| 0.0970282358195607|  0|     5.82|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|     5.82|\n",
      "+--------+---+----+-----+-------------------+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "janela_model = Window.partitionBy(\"model\", 'env')\n",
    "\n",
    "spkdf.withColumn(\"exposicao\", \n",
    "                F.round(\n",
    "                    F.sum(\"vr\").over(janela_model)/F.count(\"vr\").over(janela_model)*100, 2\n",
    "                )\n",
    "                ).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed7d3f",
   "metadata": {},
   "source": [
    "**Exemplo 2**: Ranking por score dentro de cada modelo\n",
    "\n",
    "Aqui usamos `row_number()` e `rank()` para identificar os maiores scores por modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8db8719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------------------+---+-------+\n",
      "|   model|env|year|month|              score| vr|posicao|\n",
      "+--------+---+----+-----+-------------------+---+-------+\n",
      "|modelo_a|PRD|2024|   11| 0.2663460370305066|  0|      1|\n",
      "|modelo_a|PRD|2024|    9|  0.254396153541065|  0|      2|\n",
      "|modelo_a|DEV|2023|    5|0.25129120213636325|  0|      3|\n",
      "|modelo_a|PRD|2024|    2|0.22781813927750655|  0|      4|\n",
      "|modelo_a|PRD|2024|    8|0.22382836775265536|  1|      5|\n",
      "|modelo_a|DEV|2023|    3|0.22270232011220908|  0|      6|\n",
      "|modelo_a|PRD|2024|    4| 0.2163736143214973|  0|      7|\n",
      "|modelo_a|PRD|2024|   10|0.21540296625940583|  0|      8|\n",
      "|modelo_a|PRD|2024|   11|0.21453484068109085|  0|      9|\n",
      "|modelo_a|DEV|2023|    3|0.21355130611072948|  0|     10|\n",
      "|modelo_a|PRD|2024|    5| 0.2112996562073962|  1|     11|\n",
      "|modelo_a|DEV|2023|    4|0.21040804569582475|  0|     12|\n",
      "|modelo_a|OOT|2023|    9|0.21001214902585322|  1|     13|\n",
      "|modelo_a|PRD|2024|   10|0.20965660189008484|  0|     14|\n",
      "|modelo_a|DEV|2023|    1|0.20894268396837679|  0|     15|\n",
      "|modelo_a|DEV|2023|    6|0.20630864713962443|  0|     16|\n",
      "|modelo_a|PRD|2024|    6|0.20555136609186186|  0|     17|\n",
      "|modelo_a|PRD|2024|    7|0.20552960695315192|  0|     18|\n",
      "|modelo_a|DEV|2023|    4|0.20509429018724318|  0|     19|\n",
      "|modelo_a|DEV|2023|    2| 0.2029765614498412|  0|     20|\n",
      "+--------+---+----+-----+-------------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "janela_ordenada = Window.partitionBy(\"model\").orderBy(F.desc(\"score\"))\n",
    "\n",
    "spkdf.withColumn(\"posicao\", F.row_number().over(janela_ordenada)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89276a5d",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è **Aten√ß√£o**\n",
    "> - `row_number()` d√° n√∫meros √∫nicos e sequenciais (`1, 2, 3, ‚Ä¶`)\n",
    "> - `rank()` atribui a mesma posi√ß√£o a empates e pode pular posi√ß√µes (`1, 1, 3, ‚Ä¶`)\n",
    "\n",
    "### 5.3. Quando usar Window Functions?\n",
    "\n",
    "Use fun√ß√µes de janela quando voc√™ quiser:\n",
    "\n",
    "*\tCalcular totais ou m√©dias sem colapsar o DataFrame\n",
    "*\tComparar cada linha com outras do mesmo grupo\n",
    "*\tAplicar fun√ß√µes acumuladas, ranking, diferen√ßa entre linhas, entre outros\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed01a1d",
   "metadata": {},
   "source": [
    "## 6. Fun√ß√µes Personalizadas com UDF (User Defined Functions)\n",
    "\n",
    "Por que criar UDFs no PySpark?\n",
    "\n",
    "Embora o PySpark ofere√ßa diversas fun√ß√µes nativas (pyspark.sql.functions), em muitos cen√°rios do mundo real precisamos aplicar regras de neg√≥cio espec√≠ficas, condi√ß√µes complexas, ou transforma√ß√µes personalizadas. Para isso, usamos UDFs (User Defined Functions).\n",
    "\n",
    "> ‚ö†Ô∏è **Importante**\n",
    ">As UDFs n√£o s√£o otimizadas pelo motor Catalyst do Spark, ent√£o seu uso deve ser reservado para casos em que as fun√ß√µes nativas n√£o s√£o suficientes. Sempre que poss√≠vel, prefira usar fun√ß√µes embutidas como `when()`, `filter()`, `withColumn()`, `expr()` etc.\n",
    "\n",
    "\n",
    "\n",
    "### 6.1. Como criar uma UDF?\n",
    "\n",
    "H√° duas formas principais de criar uma UDF no PySpark:\n",
    "\n",
    "‚úÖ Forma 1: Usando o decorador @udf com tipo de retorno\n",
    "\n",
    "‚úÖ Forma 2: Usando `F.udf()` diretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddaff282",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def categoriza_score(score):\n",
    "    if score < 0.2:\n",
    "        return \"baixo\"\n",
    "    elif score < 0.5:\n",
    "        return \"m√©dio\"\n",
    "    else:\n",
    "        return \"alto\"\n",
    "\n",
    "\n",
    "categoriza_score_udf = F.udf(\n",
    "    lambda s: \"baixo\" if s < 0.2 else \"m√©dio\" if s < 0.5 else \"alto\",\n",
    "    returnType=StringType()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac455f",
   "metadata": {},
   "source": [
    "### 6.2. Aplicando a UDF no DataFrame\n",
    "\n",
    "A UDF pode ser aplicada como uma nova coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d87f8d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|               score|categoria_score|\n",
      "+--------------------+---------------+\n",
      "| 0.06523585398772157|          baixo|\n",
      "|                0.01|          baixo|\n",
      "| 0.08752255979032286|          baixo|\n",
      "|  0.0970282358195607|          baixo|\n",
      "|                0.01|          baixo|\n",
      "|                0.01|          baixo|\n",
      "|0.056392020158364274|          baixo|\n",
      "| 0.03418787038282089|          baixo|\n",
      "| 0.04915994212478556|          baixo|\n",
      "|                0.01|          baixo|\n",
      "+--------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf = spkdf.withColumn(\"categoria_score\", categoriza_score(F.col(\"score\")))\n",
    "spkdf.select(\"score\", \"categoria_score\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69035a70",
   "metadata": {},
   "source": [
    "**Exemplo**: Categorizar score com base em percentis\n",
    "\n",
    "UDFs s√£o especialmente √∫teis quando queremos criar faixas din√¢micas com base em estat√≠sticas do pr√≥prio dataset, como os quantis (percentis) do score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b38d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantis: [0.01999548173668604, 0.05461328000715887, 0.08789542210164754, 0.1444450508413554]\n",
      "+-------------------+---------------+\n",
      "|              score|faixa_percentil|\n",
      "+-------------------+---------------+\n",
      "|0.06523585398772157|             Q3|\n",
      "|               0.01|             Q1|\n",
      "|0.08752255979032286|             Q3|\n",
      "| 0.0970282358195607|             Q4|\n",
      "|               0.01|             Q1|\n",
      "+-------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Passo 1: Calcular quantis de score\n",
    "\n",
    "# Obter limites baseados nos percentis 20%, 40%, 60%, 80%\n",
    "quantis = spkdf.approxQuantile(\n",
    "    col=\"score\", \n",
    "    probabilities=[0.2, 0.4, 0.6, 0.8], \n",
    "    relativeError=0.01\n",
    ")\n",
    "print(\"Quantis:\", quantis)\n",
    "\n",
    "# Passo 2: Criar fun√ß√£o UDF com base nos quantis\n",
    "\n",
    "limites = quantis  # lista com 4 valores\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def faixa_percentil(score):\n",
    "    if score <= limites[0]:\n",
    "        return \"Q1\"\n",
    "    elif score <= limites[1]:\n",
    "        return \"Q2\"\n",
    "    elif score <= limites[2]:\n",
    "        return \"Q3\"\n",
    "    elif score <= limites[3]:\n",
    "        return \"Q4\"\n",
    "    else:\n",
    "        return \"Q5\"\n",
    "\n",
    "# Passo 3: Aplicar ao DataFrame\n",
    "\n",
    "spkdf = spkdf.withColumn(\"faixa_percentil\", faixa_percentil(F.col(\"score\")))\n",
    "spkdf.select(\"score\", \"faixa_percentil\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77550a41",
   "metadata": {},
   "source": [
    "**Comparando com uma abordagem nativa**:\n",
    "\n",
    "Se voc√™ n√£o precisa de quantis din√¢micos, muitas classifica√ß√µes podem ser feitas sem UDF. Essa abordagem √© mais perform√°tica e permite que o Spark otimize o plano de execu√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ff18095",
   "metadata": {},
   "outputs": [],
   "source": [
    "spkdf = spkdf.withColumn(\n",
    "    \"score_categoria\",\n",
    "    when(F.col(\"score\") < 0.2, \"baixo\")\n",
    "    .when(F.col(\"score\") < 0.5, \"m√©dio\")\n",
    "    .otherwise(\"alto\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091985bc",
   "metadata": {},
   "source": [
    "> üí° **Dica:**\n",
    "> - **UDFs com m√∫ltiplos argumentos:**\n",
    "> Voc√™ tamb√©m pode usar UDFs com mais de uma coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96cb17e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------------------+---+---------------+---------------+---------------+----------------+\n",
      "|   model|env|year|month|              score| vr|categoria_score|faixa_percentil|score_categoria|evento_relevante|\n",
      "+--------+---+----+-----+-------------------+---+---------------+---------------+---------------+----------------+\n",
      "|modelo_a|DEV|2023|    1|0.06523585398772157|  0|          baixo|             Q3|          baixo|           false|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|          baixo|             Q1|          baixo|           false|\n",
      "|modelo_a|DEV|2023|    1|0.08752255979032286|  0|          baixo|             Q3|          baixo|           false|\n",
      "+--------+---+----+-----+-------------------+---+---------------+---------------+---------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "@udf(BooleanType())\n",
    "def is_evento_relevante(score, vr):\n",
    "    return score > 0.7 and vr == 1\n",
    "\n",
    "spkdf = spkdf.withColumn(\"evento_relevante\", is_evento_relevante(\"score\", \"vr\"))\n",
    "\n",
    "spkdf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a28bf0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|faixa_percentil|count|\n",
      "+---------------+-----+\n",
      "|             Q1| 8266|\n",
      "|             Q2| 8382|\n",
      "|             Q3| 8307|\n",
      "|             Q4| 8354|\n",
      "|             Q5| 8691|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf.groupBy(\"faixa_percentil\").count().orderBy(\"faixa_percentil\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8057181",
   "metadata": {},
   "source": [
    "> üß† **Reflex√£o**: quando evitar UDFs?\n",
    ">> Use UDFs com modera√ß√£o, especialmente em grandes volumes de dados. Prefira:\n",
    ">> * when, otherwise\n",
    ">> * F.bucketizer ou F.quantileDiscretizer\n",
    ">> * F.expr() com l√≥gica SQL\n",
    ">> * F.transform() e fun√ß√µes de arrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297e2ad",
   "metadata": {},
   "source": [
    "### 6.3. Substituindo UDFs por Fun√ß√µes Nativas em PySpark\n",
    "\n",
    "Evitar UDFs sempre que poss√≠vel ajuda a:\n",
    "*\tMelhorar a performance (UDFs n√£o s√£o otimizadas pelo Catalyst).\n",
    "*\tManter compatibilidade com a API SQL do Spark.\n",
    "*\tReduzir erros relacionados √† serializa√ß√£o ou tipos de dados.\n",
    "\n",
    "**Exemplo 01:** Objetivo: classificar scores em ‚Äúbaixo‚Äù, ‚Äúm√©dio‚Äù, ‚Äúalto‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48690278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UDF: 0.049 s\n",
      "Native: 0.047 s\n"
     ]
    }
   ],
   "source": [
    "# Com UDF:\n",
    "import time\n",
    "@udf(StringType())\n",
    "def categoria(score):\n",
    "    if score < 0.2:\n",
    "        return \"baixo\"\n",
    "    elif score < 0.5:\n",
    "        return \"m√©dio\"\n",
    "    else:\n",
    "        return \"alto\"\n",
    "\n",
    "start = time.time()\n",
    "spkdf_udf = spkdf.withColumn(\"cat_udf\", categoria(\"score\"))\n",
    "print(\"UDF:\", round(time.time() - start, 3), \"s\")\n",
    "\n",
    "# Com when/otherwise:\n",
    "\n",
    "start = time.time()\n",
    "spkdf_native = spkdf.withColumn(\n",
    "    \"cat_native\",\n",
    "    when(F.col(\"score\") < 0.2, \"baixo\")\n",
    "    .when(F.col(\"score\") < 0.5, \"m√©dio\")\n",
    "    .otherwise(\"alto\")\n",
    ")\n",
    "print(\"Native:\", round(time.time() - start, 3), \"s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ef930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucketizer: 0.161 s\n"
     ]
    }
   ],
   "source": [
    "# Substituindo UDF com Bucketizer\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "splits = [0.0, 0.2, 0.5, 1.0]  # define os limites\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"score\", outputCol=\"bucket_id\")\n",
    "\n",
    "start = time.time()\n",
    "spkdf_bucket = bucketizer.transform(spkdf)\n",
    "print(\"Bucketizer:\", round(time.time() - start, 3), \"s\")\n",
    "\n",
    "# Mapear o id para nomes de categoria\n",
    "bucket_labels = {0.0: \"baixo\", 1.0: \"m√©dio\", 2.0: \"alto\"}\n",
    "spkdf_bucket = spkdf_bucket.withColumn(\n",
    "    \"cat_bucket\",\n",
    "    F.when(F.col(\"bucket_id\") == 0.0, \"baixo\")\n",
    "    .when(F.col(\"bucket_id\") == 1.0, \"m√©dio\")\n",
    "    .otherwise(\"alto\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4932efab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantileDiscretizer: 0.282 s\n"
     ]
    }
   ],
   "source": [
    "# Substituindo UDF com QuantileDiscretizer\n",
    "\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "\n",
    "quant_disc = QuantileDiscretizer(\n",
    "    numBuckets=5, inputCol=\"score\", outputCol=\"faixa_score\", relativeError=0.01\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "spkdf_qdisc = quant_disc.fit(spkdf).transform(spkdf)\n",
    "print(\"QuantileDiscretizer:\", round(time.time() - start, 3), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bba609ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr: 0.154 s\n"
     ]
    }
   ],
   "source": [
    "# Substituindo UDF com expr (express√£o SQL)\n",
    "\n",
    "# Objetivo: aplicar uma regra condicional complexa usando SQL:\n",
    "\n",
    "start = time.time()\n",
    "spkdf_expr = spkdf.withColumn(\n",
    "    \"cat_expr\",\n",
    "    F.expr(\"\"\"\n",
    "        CASE\n",
    "            WHEN score < 0.2 THEN 'baixo'\n",
    "            WHEN score < 0.5 THEN 'm√©dio'\n",
    "            ELSE 'alto'\n",
    "        END\n",
    "    \"\"\")\n",
    ")\n",
    "print(\"Expr:\", round(time.time() - start, 3), \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b73d593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------------------+\n",
      "|score_array                               |score_array_scaled|\n",
      "+------------------------------------------+------------------+\n",
      "|[0.06523585398772157, 0.06523585398772157]|[6.52, 6.52]      |\n",
      "|[0.01, 0.01]                              |[1.0, 1.0]        |\n",
      "|[0.08752255979032286, 0.08752255979032286]|[8.75, 8.75]      |\n",
      "|[0.0970282358195607, 0.0970282358195607]  |[9.7, 9.7]        |\n",
      "|[0.01, 0.01]                              |[1.0, 1.0]        |\n",
      "+------------------------------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usando transform() e arrays para aplicar l√≥gica a listas\n",
    "\n",
    "# Objetivo: aplicar l√≥gica condicional sobre arrays (√∫til em processamento vetorial ou cen√°rios multilabel/multiclasse).\n",
    "\n",
    "\n",
    "# Exemplo: score fict√≠cio por semana\n",
    "df_array = spkdf.withColumn(\"score_array\", F.array(\"score\", \"score\"))\n",
    "\n",
    "# Aplicar transforma√ß√£o no array (ex: normalizar valores)\n",
    "df_array = df_array.withColumn(\n",
    "    \"score_array_scaled\",\n",
    "    F.expr(\"transform(score_array, x -> round(x * 100, 2))\")\n",
    ")\n",
    "\n",
    "df_array.select(\"score_array\", \"score_array_scaled\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a54c85",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d2b19",
   "metadata": {},
   "source": [
    "# 7. Estudos de Caso\n",
    "\n",
    "**Exemplo 01** - Analisar o comportamento de modelos ao longo do tempo e entre ambientes √© essencial para identificar problemas de desempenho, estabilidade e descalibra√ß√£o.\n",
    "\n",
    "\n",
    "**Objetivo**\n",
    "*\tCriar faixas de score.\n",
    "*\tCalcular a propor√ß√£o de eventos por faixa.\n",
    "*\tComparar a distribui√ß√£o entre ambientes (DEV, OOT, PRD).\n",
    "*\tIdentificar sinais de descalibra√ß√£o ou deriva nos modelos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e81b6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------------------+---+---------------+---------------+---------------+----------------+-----------+\n",
      "|   model|env|year|month|              score| vr|categoria_score|faixa_percentil|score_categoria|evento_relevante|faixa_score|\n",
      "+--------+---+----+-----+-------------------+---+---------------+---------------+---------------+----------------+-----------+\n",
      "|modelo_a|DEV|2023|    1|0.06523585398772157|  0|          baixo|             Q3|          baixo|           false|        2.0|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|          baixo|             Q1|          baixo|           false|        0.0|\n",
      "|modelo_a|DEV|2023|    1|0.08752255979032286|  0|          baixo|             Q3|          baixo|           false|        2.0|\n",
      "|modelo_a|DEV|2023|    1| 0.0970282358195607|  0|          baixo|             Q4|          baixo|           false|        3.0|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|          baixo|             Q1|          baixo|           false|        0.0|\n",
      "+--------+---+----+-----+-------------------+---+---------------+---------------+---------------+----------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf_qdisc.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edd4da77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----------+-----+-------+-----------------+\n",
      "|model   |env|faixa_label|total|eventos|proporcao_eventos|\n",
      "+--------+---+-----------+-----+-------+-----------------+\n",
      "|modelo_a|DEV|P1 (baixo) |1623 |19     |1.17             |\n",
      "|modelo_a|DEV|P2         |1625 |64     |3.94             |\n",
      "|modelo_a|DEV|P3         |1422 |98     |6.89             |\n",
      "|modelo_a|DEV|P4         |1156 |132    |11.42            |\n",
      "|modelo_a|DEV|P5 (alto)  |174  |36     |20.69            |\n",
      "|modelo_a|OOT|P1 (baixo) |791  |12     |1.52             |\n",
      "|modelo_a|OOT|P2         |825  |42     |5.09             |\n",
      "|modelo_a|OOT|P3         |717  |60     |8.37             |\n",
      "|modelo_a|OOT|P4         |566  |69     |12.19            |\n",
      "|modelo_a|OOT|P5 (alto)  |101  |22     |21.78            |\n",
      "|modelo_a|PRD|P1 (baixo) |3284 |48     |1.46             |\n",
      "|modelo_a|PRD|P2         |3135 |115    |3.67             |\n",
      "|modelo_a|PRD|P3         |2844 |212    |7.45             |\n",
      "|modelo_a|PRD|P4         |2358 |235    |9.97             |\n",
      "|modelo_a|PRD|P5 (alto)  |379  |64     |16.89            |\n",
      "|modelo_b|DEV|P1 (baixo) |1662 |18     |1.08             |\n",
      "|modelo_b|DEV|P2         |1522 |52     |3.42             |\n",
      "|modelo_b|DEV|P3         |1509 |100    |6.63             |\n",
      "|modelo_b|DEV|P4         |1141 |121    |10.6             |\n",
      "|modelo_b|DEV|P5 (alto)  |166  |19     |11.45            |\n",
      "+--------+---+-----------+-----+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Criar faixas de score com QuantileDiscretizer\n",
    "\n",
    "qdisc = QuantileDiscretizer(\n",
    "    numBuckets=5,\n",
    "    inputCol=\"score\",\n",
    "    outputCol=\"faixa_score\",\n",
    "    relativeError=0.01\n",
    ")\n",
    "\n",
    "spkdf_qdisc = qdisc.fit(spkdf).transform(spkdf)\n",
    "\n",
    "# Opcional: mapear ids para r√≥tulos leg√≠veis\n",
    "faixa_labels = {0.0: 'P1 (mais baixo)', 1.0: 'P2', 2.0: 'P3', 3.0: 'P4', 4.0: 'P5 (mais alto)'}\n",
    "\n",
    "spkdf_qdisc = spkdf_qdisc.withColumn(\n",
    "    \"faixa_label\",\n",
    "    when(F.col(\"faixa_score\") == 0.0, \"P1 (baixo)\")\n",
    "    .when(F.col(\"faixa_score\") == 1.0, \"P2\")\n",
    "    .when(F.col(\"faixa_score\") == 2.0, \"P3\")\n",
    "    .when(F.col(\"faixa_score\") == 3.0, \"P4\")\n",
    "    .otherwise(\"P5 (alto)\")\n",
    ")\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Calcular a propor√ß√£o de eventos por faixa e ambiente\n",
    "\n",
    "agg = spkdf_qdisc.groupBy(\"model\", \"env\", \"faixa_label\").agg(\n",
    "    F.count(\"*\").alias(\"total\"),\n",
    "    F.sum(\"vr\").alias(\"eventos\")\n",
    ").withColumn(\n",
    "    \"proporcao_eventos\", F.round(F.col(\"eventos\") / F.col(\"total\") * 100, 2)\n",
    ")\n",
    "\n",
    "agg.orderBy(\"model\", \"env\", \"faixa_label\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94a21774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Compara√ß√£o entre ambientes (DEV vs PRD)\n",
    "# 4Ô∏è‚É£ Visualiza√ß√£o com seaborn e matplotlib\n",
    "\n",
    "# Filtrar apenas os dois ambientes para compara√ß√£o:\n",
    "\n",
    "\n",
    "df_plot = agg.filter(F.col(\"env\").isin(\"DEV\", \"PRD\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a3853b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    data=df_plot,\n",
    "    x=\"faixa_label\",\n",
    "    y=\"proporcao_eventos\",\n",
    "    hue=\"env\"\n",
    ")\n",
    "plt.title(\"Propor√ß√£o de eventos por faixa de score (DEV vs PRD)\")\n",
    "plt.ylabel(\"Propor√ß√£o de eventos (%)\")\n",
    "plt.xlabel(\"Faixa de score\")\n",
    "plt.legend(title=\"Ambiente\")\n",
    "# Ajustando a est√©tica\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.grid(True, linestyle='-', linewidth=0.2)\n",
    "ax.xaxis.grid(True, linestyle='-', linewidth=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3f587",
   "metadata": {},
   "source": [
    "üîç Interpreta√ß√£o\n",
    "\n",
    "Esse tipo de gr√°fico √© √∫til para:\n",
    "\n",
    "*\tAvaliar mudan√ßas na taxa de eventos por faixa de score entre ambientes.\n",
    "*\tDetectar deriva nos dados ou na pontua√ß√£o do modelo:\n",
    "*\tSe a propor√ß√£o de eventos em faixas altas aumentar muito no PRD, pode ser sinal de descalibra√ß√£o.\n",
    "*\tDiferen√ßas entre DEV e PRD indicam instabilidade do modelo ou mudan√ßa no perfil dos dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b303a7",
   "metadata": {},
   "source": [
    "**Exemplo 02** - Estudo com Faixas Fixas baseadas no Ambiente DEV.\n",
    "\n",
    "Agora vamos construir um estudo onde:\n",
    "\n",
    "*\tUsamos todo o ambiente DEV como refer√™ncia est√°tica.\n",
    "*\tDefinimos quintis fixos (5 faixas de score) com base nos percentis do DEV.\n",
    "*\tEstimamos a propor√ß√£o de eventos por faixa em cada m√™s fora de DEV (OOT e PRD).\n",
    "*\tEssa abordagem √© ideal para estabilidade de caracter√≠sticas e monitoramento de performance fora da amostra.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a090dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spkdf = spark.createDataFrame(df)\n",
    "spkdf = spkdf.withColumn(\"periodo\", F.concat(col(\"year\").cast(\"string\"), F.lit(\"-\"), col(\"month\").cast(\"string\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68ac4487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 228:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-------+-----------+---------------+-----------------+-----------------+-----------+---------------------+------------------+\n",
      "|   model|env|periodo|faixa_score|count_por_faixa|eventos_por_faixa|count_por_periodo|risco_faixa|taxa_evento_por_faixa|taxa_obs_por_faixa|\n",
      "+--------+---+-------+-----------+---------------+-----------------+-----------------+-----------+---------------------+------------------+\n",
      "|modelo_a|DEV| 2023-1|          1|            228|                5|             1000|       2.19|                  0.5|              22.8|\n",
      "|modelo_a|DEV| 2023-1|          2|            173|                5|             1000|       2.89|                  0.5|              17.3|\n",
      "|modelo_a|DEV| 2023-1|          3|            201|               10|             1000|       4.98|                  1.0|              20.1|\n",
      "|modelo_a|DEV| 2023-1|          4|            212|               14|             1000|        6.6|                  1.4|              21.2|\n",
      "|modelo_a|DEV| 2023-1|          5|            186|               23|             1000|      12.37|                  2.3|              18.6|\n",
      "|modelo_a|DEV| 2023-2|          1|            202|                5|             1000|       2.48|                  0.5|              20.2|\n",
      "|modelo_a|DEV| 2023-2|          2|            181|                4|             1000|       2.21|                  0.4|              18.1|\n",
      "|modelo_a|DEV| 2023-2|          3|            199|                9|             1000|       4.52|                  0.9|              19.9|\n",
      "|modelo_a|DEV| 2023-2|          4|            207|               17|             1000|       8.21|                  1.7|              20.7|\n",
      "|modelo_a|DEV| 2023-2|          5|            211|               21|             1000|       9.95|                  2.1|              21.1|\n",
      "|modelo_a|DEV| 2023-3|          1|            211|                3|             1000|       1.42|                  0.3|              21.1|\n",
      "|modelo_a|DEV| 2023-3|          2|            199|                6|             1000|       3.02|                  0.6|              19.9|\n",
      "|modelo_a|DEV| 2023-3|          3|            187|                8|             1000|       4.28|                  0.8|              18.7|\n",
      "|modelo_a|DEV| 2023-3|          4|            217|                9|             1000|       4.15|                  0.9|              21.7|\n",
      "|modelo_a|DEV| 2023-3|          5|            186|               26|             1000|      13.98|                  2.6|              18.6|\n",
      "|modelo_a|DEV| 2023-4|          1|            214|                0|             1000|        0.0|                  0.0|              21.4|\n",
      "|modelo_a|DEV| 2023-4|          2|            198|                4|             1000|       2.02|                  0.4|              19.8|\n",
      "|modelo_a|DEV| 2023-4|          3|            217|               13|             1000|       5.99|                  1.3|              21.7|\n",
      "|modelo_a|DEV| 2023-4|          4|            155|                9|             1000|       5.81|                  0.9|              15.5|\n",
      "|modelo_a|DEV| 2023-4|          5|            216|               40|             1000|      18.52|                  4.0|              21.6|\n",
      "+--------+---+-------+-----------+---------------+-----------------+-----------------+-----------+---------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spkdf = spark.createDataFrame(df)\n",
    "spkdf = spkdf.withColumn(\"periodo\", F.concat(col(\"year\").cast(\"string\"), F.lit(\"-\"), col(\"month\").cast(\"string\")))\n",
    "\n",
    "# üìå N√∫mero de faixas\n",
    "n_faixas_score = 5\n",
    "quantis = [i / n_faixas_score for i in range(1, n_faixas_score)]\n",
    "\n",
    "\n",
    "# ‚ö†Ô∏è Use uma √∫nica chamada para calcular todos os quantis\n",
    "df_dev_cuts = (\n",
    "    spkdf.filter(F.col(\"env\") == \"DEV\")\n",
    "    .groupBy(\"model\")\n",
    "    .agg(F.percentile_approx(\"score\", quantis, 10000).alias(\"cuts_score\"))\n",
    ")\n",
    "spkdf = spkdf.join(df_dev_cuts, on=\"model\", how=\"left\")\n",
    "# UDF para determinar a faixa de score com base na lista de cuts\n",
    "def definir_faixa(score, cuts):\n",
    "    if cuts is None:\n",
    "        return None\n",
    "    for i, limite in enumerate(cuts):\n",
    "        if score <= limite:\n",
    "            return i + 1\n",
    "    return len(cuts) + 1  # √öltima faixa\n",
    "\n",
    "faixa_udf = udf(definir_faixa, IntegerType())\n",
    "\n",
    "# Aplicar a UDF para criar a coluna faixa_score\n",
    "spkdf = spkdf.withColumn(\"faixa_score\", faixa_udf(F.col(\"score\"), F.col(\"cuts_score\")))\n",
    "\n",
    "janela_periodo = Window.partitionBy(\"model\", \"periodo\")\n",
    "\n",
    "spkdf_faixas_score = spkdf\\\n",
    "    .groupBy(\"model\", \"env\", \"periodo\", \"faixa_score\")\\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count_por_faixa\"),\n",
    "        F.sum(\"vr\").alias(\"eventos_por_faixa\")\n",
    "    ).withColumn(\n",
    "        \"count_por_periodo\", \n",
    "        F.sum(\"count_por_faixa\").over(janela_periodo)\n",
    "    ).withColumn(\n",
    "    \"risco_faixa\", \n",
    "    F.round(F.col(\"eventos_por_faixa\") / F.col(\"count_por_faixa\") * 100, 2)\n",
    "    ).withColumn(\n",
    "    \"taxa_evento_por_faixa\", \n",
    "    F.round(F.col(\"eventos_por_faixa\") / F.col(\"count_por_periodo\") * 100, 2)\n",
    "    ).withColumn(\n",
    "    \"taxa_obs_por_faixa\", \n",
    "    F.round(F.col(\"count_por_faixa\") / F.col(\"count_por_periodo\") * 100, 2)\n",
    "    ).orderBy(\n",
    "        \"model\", \"periodo\", \"faixa_score\"\n",
    "    )\n",
    "\n",
    "spkdf_faixas_score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "da55c23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAGGCAYAAACJ/96MAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAA9kpJREFUeJzsnQd8G/X5/z+atry3Y8d29t57swIECHvTFrqAQumgu/TX0lLa0v67B120QEtL2YQdZsLK3ns5znA84r1ka/9fn0c+R3YkWbY1Tva9Xy9Z0kk6ne9O33u+z/g8Oo/H44GGhoaGhoaGhkZA9IFf0tDQ0NDQ0NDQIJrBpKGhoaGhoaHRC5rBpKGhoaGhoaHRC5rBpKGhoaGhoaHRC5rBpKGhoaGhoaHRC5rBpKGhoaGhoaHRC5rBpKGhoaGhoaHRC5rBpKGhoaGhoaHRC5rBpKGhoaGhoaHRC5rBpKERh5x33nly0zib6upqXH/99cjOzoZOp8Pvfve7kD977Ngx+czjjz8ONcDt4PZwuzQ0NGKLZjBpaKjowqjcjEYjhg8fjs985jM4depUrDcvrvja176GN998E/fddx+eeOIJXHLJJbHeJA0NjUGAMdYboKGhcYYf//jHGDVqFDo6OrBhwwYxpD766CPs2bMHiYmJXe976623Yrqdaua9997DVVddhW9+85t9/uyIESPQ3t4Ok8kUkW3T0NCIXzSDSUNDRVx66aWYO3euPL799tuRk5ODX/ziF3j55Zdx4403dr3PbDZjqNLW1obk5OSAr58+fRoZGRn9Wje9e76GqUb0j5+GhlrRQnIaGipm2bJlcl9aWtprDtMf//hHTJkyBUlJScjMzBTD68knn+z2Hob3Pv/5z6OwsBAJCQnizbr77rtht9u73nP06FHccMMNyMrKknUtXLgQr732WsgGx5e+9CX897//xYQJE8T4mDNnDj744IOz3rt9+3YxENPS0pCSkoLly5eLV81fqPL999/HF7/4ReTl5aGoqMjvdyvv9Xg8ePjhh7vCm6S+vl48TtOmTZPv4nfyu3fu3Bk0h4nGV25uruxrrlfhyJEjctG/6aabupZ9+OGHst9KSkpk3xYXF0t4kB6rUNi7dy8uuOACWCwW+R9/8pOfwO12+33vG2+8IecGtyE1NRUrV66Uz/eGw+HAAw88gHHjxsmxYZ7X0qVL8fbbb3d734EDB8RA5//O7eGx/L//+7+wH7/+/h8aGrFA8zBpaKgYJdmXBlAwHnnkEXzlK1+RZOevfvWrEtLbtWsXNm7ciE984hPynoqKCsyfPx+NjY248847MXHiRDGgnnvuOVitVvFaMWF68eLF8pzr4wX1X//6F6688kp53zXXXNPrNvPi+PTTT8vnaTj8+c9/ljyiTZs2YerUqfIeXhR5oeTF9tvf/raEwP72t7+JYcLPL1iwoNs6ebHlxfv+++8XD4U/zjnnHMlZuvXWW3HRRRfhtttu62YErlq1SgwaGon8P/l95557Lvbt2ycGpD94gf/LX/4in6NByv+JRgxzy3iB5/+m8Oyzz8p+owHK/cb/l58pLy+X14JRVVWF888/H06nE9/97nfFgPj73/8uxkpP+D9++tOfxooVK8T7yO/kNtLwoREzcuTIgN/zox/9CA899JB4L3kuNDc3Y8uWLdi2bZvsM8LzhseGx4TnCddHg/2VV17BT3/607Adv4H8HxoaMcGjoaERcx577DG6LzzvvPOOp6amxnPy5EnPc88958nNzfUkJCTIc1/OPfdcuSlcddVVnilTpgT9jttuu82j1+s9mzdvPus1t9st9/fee69sx4cfftj1WktLi2fUqFGekSNHelwuV9Dv4Gd527JlS9ey48ePexITEz3XXHNN17Krr77aYzabPaWlpV3LKioqPKmpqZ5zzjnnrP2ydOlSj9PpDPrdvttwzz33dFvW0dFx1raXlZXJvv3xj3/cbRk/z+/15ZZbbvEkJSV5Dh065PnlL38p71m1alW391it1rO25aGHHvLodDrZB8FQ9vvGjRu7lp0+fdqTnp4uy7ldyrHIyMjw3HHHHd0+X1VVJe/tubwnM2bM8KxcuTLoe7j/eRx6brNyjoTj+A30/9DQiAVaSE5DQ0VceOGFMhNnOIfeInoamL8UKAylwJwdejI2b97s93V6RehhueKKK7pypHxRQlevv/66eB44y1dguIWeBnq76I3pjUWLFkkYToEhKiZhs3LN5XLJjUnrV199NUaPHt31voKCAvGGMcmdng9f7rjjDhgMBvQXerr0eu9wx++vq6uT/4uhJnpXeuNPf/oT0tPT5Zj84Ac/EC8W/ydffL1B9KLU1taKt442HD0mweB+Z+iT+16B58EnP/nJbu9j6IwewltuuUXWr9y4b+jVWbNmTa/nCb1Dhw8f9vt6TU2NhE8/97nPyXHzd46E4/gN9P/Q0IgFmsGkoaEimHvDiwnDX5dddplcRHix743vfOc7YgDwgsv8lHvuuQcff/xxtwshL2JKSCwQx48fFyOiJ5MmTep6vTf4/T0ZP368hFy4HbzxcaDvoXF38uTJbssZRhsIXOdvf/tb2TbuTybT0yBh+KmpqanXzzOf6w9/+IO8n4YTH/fkxIkTEqrje3ksuH6G/Ehv38H96m+/9dxHiqHDXCeu3/dGI4Y5V71VYdJQ4fFgPte3vvUt+Z98Q5ck2HkSjuM30P9DQyMWaDlMGhoqggaP4gHiDJ6eHs7aDx48KBfhQPBCxfe8+uqrWL16NZ5//nnJr2HOCJN84x1/uTx94Wc/+5l4hug5efDBB8Woocfp3nvvDZhY3RN6yEhDQ4N483wr8eh1YQ4Qk8tpvDI/jN5B5ojRiAr1O3pDWQ/zf4YNG3bW69TvCgbzvJiP9NJLL4lh8o9//EMMyb/+9a+S1xSt4zfQ/0NDIxZoZ6WGhkpheIIJukwGZkiIycDBUKq2eGPV27XXXitJuhRw5MydCbrUc+pNh4iGV09YNaW83hv+wj2HDh2SijtuB+HjQN9DQ4YhyXBCjx334z//+c9uy+ltobepN2iE0rhggjMrAJmszIR65cK+e/du+R+ZIO+bbN6z+iwQ3K/+9lvPfTRmzJiuZHSGb/sDjcXPfvazcmttbRUjisngNJiUEFuw84THcKDHLxz/h4ZGtNFCchoaKoZVR/Q6sb0HK98CwZwcX1jxNnnyZMmfYSk5L2L0WLHSiVVRPVFK5hkGZHXX+vXru+XjsGKLVUtcZ2/ws755QQzP0KNx8cUXixHIGx9zmW/LD1auUQaBXjUad+GE3+krC0BYuRaKijqNKqWqjJ4qGk78//jYd/3E9zv4+Pe//31I28f9zpJ87nvf0BeNM19YUcZ9w+/mce0JPxOMnucJvZZjx46FzWbrMoZoQD366KMSYvRF+d/CcfwG+n9oaMQCzcOkoaFymGfCsnZq2tx1111+38MLGEMbS5YsQX5+Pvbv3y9eKerasPyd8OLEMAzzapjEzTBeZWWlGA5M1GWIiV6s//3vf6KvwxJ6eiPoNSkrK5Mwn5I4HQzmv/CC6CsrQHxDg9QYoveFF1eWnNNTw7J0Xrj/3//7fwg3l19+ueTv0KvCRGx6hGiM+CYtB4IyDTQ03nnnHTEWKJFAA4r/AxO/Z8yYISE4ek2o9UQjjMYA9xfDd6FAz5XSxoXfp8gK0PPkm2PE9bL0nknns2fPxs033yxGDo0bamXx+PO4B4IGL41wJuXz2NJ4pveN2lkKzM/iceH6eZ4w/4iGEde/Y8eOsBy/gf4fGhoxISa1eRoaGt1Qyq/9lfyzHH7MmDFyU0qze8oK/O1vf5Ny7uzsbCmV53u/9a1veZqamrqti6XilBdQ5ApGjx4tJfg2m63rPSwVv/7666Xsm3IA8+fP97z66qt9Kun/z3/+4xk3bpx8x6xZszxr1qw5673btm3zrFixwpOSkiIl++eff75n3bp1Ie+X3rahp6zAN77xDU9BQYHHYrF4lixZ4lm/fv1Z+7GnrMBLL70kz3/96193W19zc7NnxIgRUqZvt9tl2b59+zwXXnih/D85OTlSGr9z506/MgX+2LVrl2wL9/nw4cM9Dz74oOef//xnN1kBBe5P7juW4PP9PN6f+cxnusk5+OMnP/mJHE8eW+6HiRMnen760592/Q8Ke/bsERkI5RyYMGGC5wc/+EHYj19//w8NjVig45/YmGoaGhqDDZaes0JP8w5oaGgMNrQcJg0NDQ0NDQ2NXtAMJg0NDQ0NDQ2NXtAMJg0NDQ0NDQ2NXtCq5DQ0NMKGlhKpoaExWNE8TBoaGhoaGhoavaAZTBoaGhoaGhoavaAZTAHCCmxUqoUXNDQ0NDQ0NIhmMPmhpaVFOpLzPtywdxNvkSBe1x3p9Udy3UeOHMH3vvc9UcwON9o+GTz7JNLr19atrVsN62+N03ElVDSDSUNjAFRVVUmD3Fj+iNWGtk80NDQG47iiGUwaGhoaGhoaGr2gGUwaGgOADW/vu+8+FBQUxHpTVIO2TzQ0NAbjuKLpMGloDPBHzLh6SkpKrDdFNWj7RENDYzCOK5qHSUNjALCa8p133pF7DS/aPtHQ0BiM44rmYdLQGABHjx7FNddcg61bt2L27Nmx3hxV7hO32w273R6WddtsNrk3GsM/dEVy3ZFav9lshl6vzXs1Bj9HVTDWagaThoZGxKChVFZWJkZTOFDWEwkjIZLrjtT6ua5Ro0aFbX0aGhqB0QwmDdWgzZQHFxR+ZQmwwWBAcXFxWI6vy+WSe64z3ERy3ZFYPw2wiooK2cdZWVnQ6XRhWa+GhoZ/NINJI+Y43R2wJCXA7rbC5XHC43HCqE+M9WZphAGr1YrCwkIkJSWFZX2awdSd3NxcMZootBupUKKGhoYX7RemEVNcbjv217+Egw1vwOFug0mfjAmZl2Fy1tUw6M1QOwkJCRg9erTca3TfJ8yvIcq9RvhR9m24Qp4aGmolQQVjrWYwacTUs0RjaU/dc13LaDTtqXtWHk/KulL1nqZJkyZh586dWgm9n31Cjwfzl7RQUeRQ9q3W91JjsDNJBWOtljSiETN0OqN4lvxxsOF1eV1DQ0NDQ0MNaAaTRsxwuNrEo+T3NXcbHC4r1M6ePXswcuRI7Nq1K9aborp9cvDgwaDvo1fkzjvv7EpY3rFjR9D3Hzt2TLxWvb1PQ0Nj8LFHBWOtNoXXiBkmQ7LkLPkzmrjcZAhPonAkcTqdqKurk3uNs/dJsPyl1atX4/HHH8fatWslNyEnJyfoellpV15e3uv7NDQ0Bh9OFYy1modJI2awGm585iV+X2PiN1/XGLyUlpZKX6jFixdL24PeqrxYXRbK++IVh8MR603Q0NAIgmYwacQMu8uK8RmXYUr2deJRIryfmn2DVMmpPeFbo/985jOfwZe//GWcOHFCwnF0tdPjtHTpUmRkZCA7OxuXX365GFWBQnI//vGPRbKAs06FlStX4vzzz++qGvvNb36DadOmITk5WTxUX/ziF9Ha2hrSNh4/fhxXXHEFMjMz5fNTpkzB66+/3vX63r17ZRvT0tKQmpqKZcuWdW0vv5/bV1RUJFU9M2fOlP/P93/h//3000/j3HPPRWJiIv773//Ka//4xz8kwZXLJk6ciD//+c8D3t8aGhoDZ3BO1TTigtKmd3Gi5WPMy78TU7KuQ4erEQmGVLQ7G+NCUkCj//z+97/HmDFj8Pe//x2bN28W79EHH3yAr3/965g+fboYNffff7+0QqCB5E/08v/+7//ECLn99tvx4osv4uGHH8a6deukkkZ5P+//8Ic/iBo2WyvQYPr2t78dkhFyzz33iFI5t4sG0759+7oqdE6dOoVzzjkH5513Ht577z0xmj7++OOucAH/v1//+tf429/+hlmzZuHRRx+V/4X5FzSCFL773e/K+/gexWji//2nP/1Jlm3fvh133HGHfP+nP/3pMB4BDQ2NPuPROIumpibW6Mp9uGlpaZFbJIindbvcTs+qI3d5njxwvaes6QNZ9+6qVZ7nD3/O80H5//PEy36prKz0vPPOOxFZfzwdT3/7pLa21rNv3z5Pe3u73/f99re/9YwYMSLgempqauR3uHv3bnleVlYmz7ds2dL1ntLSUk9qaqrnO9/5jsdisXj++9//Bt22Z5991pOdne33NafTKTeFadOmeX70ox/5fe99993nGTVqlMdut/t9vbCw0PPTn/6027K5c+d67r777m7/y+9+97tu7xkzZoznySef7LbswQcf9CxatMjv93Dfch9zX8fjuaKtO7rrjvT6W+J0rA0VLSSnEROqrXtgddZKCK4oZb4syzSPg83VjIq27XC42xEP0OOwYMECTYfJzz6hV6QvHD58GLfccoskgNNjwzAdYdguEHzvr371K/ziF7/AlVdeiU984hPdXmd38+XLl2P48OESNrv11lslhEcF8t74yle+gp/85CdYsmQJfvjDH3arzqHXiyE4k8l01ufYTZ3q2/ycL8zV2r9/f7dlc+fO7Xrc1tYmIb3Pf/7zsg+VG7fBNzSpoTEUSVHBWKsZTBox4WjTu3I/Mm0pjHqvcmuasRip5kK4PQ6cat2CeIChGYZVWL2l0X2fVFVV9elzzBeqr6/HI488go0bN8qNMCwWDIbMGNJjXpBvBQ2fM8eIIb7nn39eupwzbBfKOglDfQzj0cjavXu3GDd//OMf5TWLxYJw4GtUKrlV/P9pkCk3llNv2LAhLN+noRGvnFLBWBtTg4kDHQdJJm4yAXLVqlXdXucyf7df/vKXAdf5ox/96Kz3++YMaMQem7MZ5a2b5fHo9OVdy3msSlIXyeMTLesQD9TU1MhF+PTp07HeFNXtE99k7N7ge6nb9P3vf188Qkx6bmho6PVzTJp+4YUXRJqAnqgHH3yw6zUaSEy+Zo7QwoULMX78ePH89AUmit91113yHd/4xjfEmCE0wj788EO/lW30jnFMY06TL8yvmjx5csDvys/Pl8/RSBs7dmy3G3OwNDSGMjUqGGtjmvRNF/SMGTPwuc99Dtdee+1Zr7MLty9vvPGGuKuvu+66oOtlNQtd8QqDtQw5Xilr/hBujxOZCaOQldj9QlCSuhh7655HZdsO2F1tMBv6FtbRiE9YicbKOCaBU2qAxg9nk8HgTPPuu++WcByr6x577DHxKF166aViINHQoEFDrxAnZjRg/vrXv4a8Tffee6+si4YWjbc1a9aIIUe+9KUvyXpvvvlm3HfffdL8ll6g+fPnY8KECfjWt74lYTwmtrNCjtvGZPQnnngi6Hc+8MADEgrk+i655BLYbDZs2bJFvp8J8RoaGrEjppYEByPeAkHNFV9eeuklKRlm3kIwaCD1/KyGOqC6sxKOG+PjXVJINxcjzTwczfZTEpYblX5uDLZSI9qwmu2pp54SY2Hq1KlidLC6jVVogc4jShPQQKHxQlasWCEG1Kc+9SkJZXEyRlkBGlQ0aljV9tBDD+G2224LaZtcLpdUytEwo9eIBsxvf/tbeY3GHavjaBhRFoAhQRpGSt4S/4+mpibxSnFGTM8SK/nGjRvXaxgwKSlJvOhcN0N2lEWg8aahoRFb4sb1Ul1djddeew3/+te/QkoepWubZbqLFi2SQbKkpCQq26kRnPqOI2iyn4RBZ8KItKVnve4Nyy3BnrpnJCynGUyDFxoBvobAhRdeKKX7vvg2lWUSuJKjxPPE14usQCOLN4Wvfe1rcvOFOUmhoOQrBYJhuTfffDOgAUgPE2++Bpjv/xKoYS4T13smr2toaMSeuDGYaCixysVf6M4XZtGz3QJnqAzp0cXNahYmTvLz/qDbmzffKhclCdOf/stACKU6ZzCv+0CD9wIzLHEO7O0e2NF61vpzDNMBPIPKtp2ob66GuVPUUo37hd6Az372s5IEHKog4mA6nsH2CScszCGioeBrLAwERZAyEkRy3ZFaP/cr19vR0RG2fTxYzkNt3dFfvzVOx1oSSvVd3FTJUfjtk5/8pAzCwWCI74YbbpDZH130VOZtbGzEM888E/Az9EAxZ0C5MdFTI/w43TZUtHsrn0qSA3uOUk3DkWocDg9cqGrfBjVDJeef//zn2jnjZ5+oPSxOVXDf3z3zqHjjY44JGhoa6qFIBWNtXHiYWI3CChpWxPQVtllg0uaRI0cCvof5Db4JlfQw8aAoOiiRIJJaEmpd99GmzXB6OpBiyseIrDkSVgm0/pG2Zdhd+xROO7ZhckrgPLdY7xfOqA4dOoTZs2fLDGgoHc/e9gmLL+ihZX4Pb+EkHOv75z//ifb2M3pfioeG687Kygr7NiuEc71cF/cxJ5JswRJv54q27tisO9LrT4nTsXZQGEwc2ObMmSNJnH2FrjuKvgXLW+BAw5tGZDna9J7cj06/wK+x5EtJ6kIxmKradsPmapGWKWqEP2CGfFnCzh+yxpl9wuquWA1soUAxS198DSYNDQ11cUgFY21MQ3I0ZhRxNlJWViaPfZV96e159tlnpXrEH9RsYd8lhW9+85t4//33RbSOuifs38QBkArCGrGDVW817Qeggw6j0v1XPvnCSrmMhBESlitv2RSVbdTQ0NDQ0FClh4kzUMoEKChhMTaZZOI2Yakxq0kCGTz0HtXW1nY9Zwkw30shvNzcXNFnoT4KH2vEjtJGr3epIHk2koxZIX2G1XKNtuNSLTcm42wJAg0NDQ0NjSFhMFFjJVBprcKdd94pt0DQk+QLDSwNdUGRyrLm9+XxmPQLQv4cw3K7ap+UvnMdziYkGtMjuJUaGhoaGhqDoEpOI36paN0Gm6sJiYZ0FKaEHntONReIGrgHbpS3qjMsx4RbylWEW34intH2iYaGxmAcV+Ii6VsjvintTPZm7pJe17dTjmG5BluZhOXGZlwEtUH5CvYni2UHbbXuEyruMy9RQ0NDYzCMtdoUUCOiWB11qGzzaimNTj+Tr9aXsBw5bd2Ldmdj2LdPQ0NDQ0MjFDSDSSOiMHfJAw9yLROl8q2vpJjzkZU4RtZR3uIVvVQTBw4cwLx5885q6TGUUfZJMO2zwcwHH3wgzX7ZnonyGatWrYr1JmloxD0HVDDWagaTRsTweNzdtJf6S0nqYrlnWE5tsCUFf8i81+i+T3zbDcUKm8sJp9uFFnuH3PN5pGlraxPNuIcffjji36WhMVToUMFYq+UwaUSM0+370eqohlFvQUnqon6vh5/dUfOErK/d2QCLMTOs26kxOHG4XXjz5D6sqTwIq9OBJKMJ5xdOwKXFU2DSR06cku2ZeNPQ0BhcaAaTRsQobXxX7kekLoFRH7wHYDCSTbnIThyHuo7DONmyAeMztYvRUIQSJIqHyIDgciRujwdvl+/Hayf3dC2j0fTaCe/zi4ZPgr6H2nyX0nePdZv1hl6V6TU0NAY/msGkERHsrjaUt27os/ZSsLAcDSaG5TSDaWhid7vwtY3P9/q+FFMCfjbvKvEs+WNNxUGsKJqM721+Ca2O3sOGf1h8IxIM2lCpoTHU0XKYNCLC8eaP4PI4kG4uRlbi2AGvTwnpsb0KK+/UwsiRI0UsdfTo0bHeFNXtk1h1FU8zJaLF0SEeJX9wOV/n+zQ0NOKDkSoYa7Vpk0ZEKG3yhuPY0iQc4YwkUzZyLBNQ234QJ1s3YELmSqiBjIwMrFy5UtNh8rNPqMPEFkXhgqGx3y64LqQGuQadTnKW/BlNXJ5htuC7M1eE1HyX36uhoRFb1DDWah4mjbBT31EmYpMUqRyZdk7Y1ttVLdesnmq56upq/OpXv0JVVVWsN0V1+6Smpias66XhzdBYKDeXxyMJ3v7gcr4e6rq0/CUNjdijhrFWM5g0ws7RTu9SUco8JBhSw7beYhGx1KG24xDaHOG9GPeXyspKPPDAA6JAq9F9n5w+fTpm20BDh9VwK0umikeJ8J7PuTySOUmtra3YsWOH3AjVzvn4xIkTEftODY3BTqUKxlotJKcRVpxuG441fySPR6cvD+u6k4xZIoBZ075fquUmZl0R1vVrDC4oHcDk7suKp6Dd5YDFYBLPUiQlBciWLVtw/vlnVO2//vWvy/1tt92GRx99NKLfraGhETk0g0kjrLBJrsPdhmRjLoYlTQv7+hmWo8HEajnNYNLoDcWTlNppJEVjwDvvvPNEAqEnSo6UhoZGfKKF5DQikuw9Kv186HThP72KUxdABx3qOo6g1RG7kI+GhoaGxtBCM5g0wkaLvUqa5DLPaHT6eRH5Dqp85yZNlscnW9Yj1qSnp+Pqq6+WCg6N7vskLS0t1puioaExSEhXwVirGUwaYaOsaY3cD0uaLurckUJN1XKjRo3CE088oekw+dknsdJh0tDQGHyMUsFYqxlMGmHB7XHhaPPaLu2lSFKc4g3L1duOilcrltjtdpw6dUruNbxo+0RDQ2MwjiuawaQRFirbdqDdWQ+zIRXDk+dG9LsSjenIS5qqirDcvn37MHHiROzZc6Zn2VBH2SeHDx+O9aZoaGgMEvapYKzVDCaNsHC06T25H5V2Dgx6r+5NJFHCcsdbYh+W09DQ0NAY/GgGk8aAaXc24lTrVnk8OgyNdkOhOGU+dNCj0XYMzXZNNFJDQ2PwoNdrl2Y1oh0VjQFzrPkDeOBCduI4ZCSUROU7E4xpyO/UeYp1WE5DQ0MjHDjdHbAkJUBndsDlccpzDfUQU4Ppgw8+wBVXXIHCwkLp17Rq1apur3/mM5+R5b63Sy65pNf1Pvzww9LZODExEQsWLMCmTZsi+F8MbSjQp2gvRcu7pFCS1hmWU0G1nIaGhsZAcLnt2F//El4svQOrSm/Hi0dux/76l2W5hjqIqcHU1taGGTNmiIETCBpI7CGj3P73v/8FXefTTz8trQh++MMfYtu2bbL+FStWxLSv1WCmtv0gWuwVMOgSMKIzryhasFedDgY02U+gyVaOWDB9+nTU1tZi5syZMfl+NcJ9Ul9fj0mTJsV6UzQ04gJ6kvbVv4g9dc9JpwTC+z11z2Jf/SrN0wR1jLUxNZguvfRS/OQnP8E111wT8D0JCQkYNmxY1y0zMzPoOn/zm9/gjjvuwGc/+1lMnjwZf/3rX5GUlKT1cIoQpZ3J3iWpi2AyJEX1u9nYtyB5ekzDcsw14Dmq5Rx44cCenGJBYqoeHp3bb4uQwcxDDz2EefPmITU1FXl5eSK0d/DgwVhvlobK0emMONjwht/XDja8Lq8PdfQqGGtVP8qvXbtWBp4JEybg7rvvRl1dXcD3Up9h69atuPDCC7uWcefy+fr1Wp5LuHG4rNLTjYwJc6PdUCmOcbUcS+dp+B86dAhDHSWk8PA7N2LO4rF48uN74XBb4fG4Y7ZNHocNHpcTHmuz995hi+j3vf/++7jnnnuwYcMGvP3223A4HLj44ovFm66hEQiHq63Ls3TWa+42GWuHOodVMNaq2mxlOO7aa68Vhc/S0lJ873vfkx1G48dgOLvjON11bHCZn5/fbTmfHzhwIOD32Gw2uSk0NzfLfWtra9itWas1cid+tNd9vO19uDw2JBuHIdE1XPZXONcfCpm6ydDDiGZ7OSobDiLVNDxs6w4FGvAfffSRhHyZizdUzxVTgg6Hml6VkEJrawv2b66F1cqLgBUdzmYkuBMQDmeT2x268aX3uOHZ/AY8298FbFYgIQm6WcuB+Svh9tPnsC/rDsRrr73W7fk///lPFBQUSB7l0qVLEW443nG7Ozo6ItbcN57Ow3hdtyUpCSZ9sl+jictNesuAxtd43S/RGmtJSkpKfBtMN998c9fjadOmSQxzzJgx4nVavnx5WN3oDzzwQNjWN1Q40faB3JcknSMJ+bHApE9CbuJUVHfsQEX7JkwwBQ7vakQOo8EcMKRgc7dCp8sbeHiOn1c8RL1MZPQ6wLP1LXg2vOKzIdau5/o5F8Pdc3MUg6nnuo1mxkz6tclNTU1yn5WV1a/PawwNnC47JmReJjlLPeFyvq4Re1RtMPWEPWRycnJw5MgRvwYTX6Pnqbq6uttyPmf+UyDuu+8+SRT39TCxDxYtzlCszv4QqfVGa91NtpNodByVpOsJuRfBYkyJ2baPci1DddUOVNq2YHbypwIab5HYL6zEJMyTG4rnCo2gFkclbK6EgCEFD9zwwOPXK9yn76Kx9Nev9v5GSwpw+//zepb8rWf7u9DNuxT4x7eB9jOz9kAmmP7Lf4bOmNDn7aXn5xvf+AaWLFkixSeKB2ig+8EXrotecJ6HzO9Q87mirTs4k7Oult/KoYbV8luiZ2l85qWy3KA3I8E0NPdLNMfaQWUwlZeXi1uOLm5/mM1mzJkzB++++64kWyqDFp9/6UtfCrheDjS8aYSOIiUwPGUOLMbYdY8mRSlzodeZpFqv0XYCmYkjYro9QwEazMxfO9GyHjZXC64c/XDAkAIFRnmLGsnpgLXZG4bzB5dbW7zv8zGYwg1zmdjGgWGEeEcraog8DF1nJYzG1WP+CrurDWZDMuo7joqxpKEOYmowMSZLb5FCWVkZduzYIe5r3hgmu+6668Q7xBymb3/72xg7dqzIBCjQ08QqO8Ugoqfo05/+NObOnYv58+fjd7/7nSRcsmpOIzy43A6UNX8QE+0lf7A6rzB5JspbN+Nky7qoGkxFRUX44x//iJKS6Ah2xt5IWi+GUrP9VNdyvc6IBttxTMi8VHKYsguTcMeDc5CR550RJug5G2T8a4BhW4bGvvhH73f25qXRGyRnya/RxOUpGdDf8n/dFrs7PUBnrZvf20c4Hr366quiNcdzJN6FFO1uqwgpejxOGPXe46oRXo61fIBdtf9DgWUupqTfhNU135YcwGvHPio5TEOdIhWMtTE1mLZs2YLzzz+/67kSFqPB85e//AW7du3Cv/71LzQ2NkqSF6tNHnzwwW7eIBpSTPZWuOmmm1BTU4P7778fVVVVotmwevXqsxLBNfrPqbYtsLtaYDFmoiBZHfpDrJajwcRquWk5N0ctp4phYAqsxspFHGmvAfWtaCRRtqHJfvLMZ3VGFCTNkP1OLyNnw1kJo8QoOqh/HeffkIAkTwZMziQkGtOg85Nk3VfkmJq8v31dLwYTw3e6WRfCs+Hls9cz60JaR9B1ruvMP+UKad1Bv9fjwZe//GW8+OKLkmvJgpV4r3pkbpoSImI+jRIi0ggfPG+ONX8oj/MSpiNRny1Gks3VjKq2XShOXYChTo4KxtqYGkznnXde0ETQN998s9d1HDt2zO/sLlgITmNglDZ6w3Gj0s6DXhe+fIyBwIu2QWdCq6MKDbZjyEqMzoWKxjo9CSxQ4A96MHgN6D060ez1JHUzkmDAsOSZork1PGWuGEm+8CI6KetK5LmX4fkXn8HSy6+SyU4slJjEGJp/mTz2bH/Hp0ruQujmXwad0RSxMNyTTz6Jl156SbSYOGkj6enpkjIQL/AcobFEj6GCIqRIeJw1T1P4aLQdl0pfphYUWObI5KAwZQ4ONbwufTo1gwmqGGvjKodJI/a0OWpQZd2lmnCcAmdjBcmzUd66US700TKYmFdHj8LixYvjwmAK5DWYlHUVyprfx5HGt2Tw7m4kzUCJeJLONpJ6wovo4UOluOeue5Hw+nHMGH51p4ZMdEVNiRhF8y6BbsFKwNYOJFi8nqUIGUuEnnFlMujLY489hltvvRWDRUhxcva1Ud+mwYziXRqePFsqf72P54rBVNG2TbTMwuGljWfKVTDWagaTRp8oa1or+Sh5SVOQag5ceRgL2JpFMZhm5HwiZlIH8eg1YHUOE05pLLHycVjydPEksf2M2dA/F3hu0ni5t7uZWB2bAa4r7JaU6r03RHbIC+Yxj5ROUqyEFA3GtKhv12CExtCJlo/l8Yi0ZV3Lc5MmdoblmlDXUYocy7gYbqUG0QwmjZCh/VHesjmmyt7BKEyZDYPOjDbHadTbjiI7cUysNyluvAYsZb56zN+wqOCrKEieIW1nBkquZbLcOz12ON02GPVaJWq8YDIkBxdSjHIbpMFMTft+WJ114lkqTJ6FdqtXc4kpBgyBM3+wonWLZjCpgKHt49PoU86L3uzAhSN+jHOGfxdFKeqLqTMcxLg/OdEcm1Yp8ew1oFEzMm1pWIwlwvCdYiQxeVUjfmBeGzWA/MEQLl/XCG84rjh14VnJ9MOTvePZqbatMdk2je5oHiaNPue8cCAdljQNaoRhOc7IeJuZG1jEMlwkJydLy4t4qJKLltdA2ScUmOP5Q2yuViQZs4d8Hka8UNd+BOMzaDB5eggpXqJVyYVZouVEywZ5PCL17NY59DjpoJNQOfNHk025GKokq2Cs1QwmjT7nvOyte05+xGqslClIngWjLgFtzhrUdRyJuBt73LhxeOONN+LCYFK8Bjx+Ab0GYeiKruwTo9GIsrKjMOiMkiNld7UiQct7UT0Odzs2VP1JftuLC76KKVnXiR4Qn1e27cTR5rUYl3FxrDdzUFDZtkPGVEq05CV5Q9i+8PeSbRmP2vaDqGjdhnGZZzQIhxrjVDDWatM9jX5XyvB1tcEQUGHKXHnM5O9IQyV5Nm4OR+PWSNPQUSZegynZ14m3gPB+avYN4jUIl/HbfZ/oYO78rg4tLBcX7K59WnJqXB4HUs2FaLfa4LabUNG2HR9V/BLbT/8bVkddrDdzUHCs5cMu71IgiRZWy5GhHpZzq2Cs1QwmjQFVyqg1LEcYlmMFSiShuCpLXKlQr2aYn7S+6k949+T9KEqZj2vGPIJrxvwD14z9h3gKwxliUfbJ/v37u3KZGBh1emyyHRrqpb6jVErZybz8O7py0HiRKk5ZgBzLBLg8Nuyo+U+MtzT+4fjJZG4yIu3scJyvxhyptu4Rr/9QZZcKxlrNYNLoNefF72sqrpSh+rhRlyiz5NqOw7HeHFXAsCqrBzngppoLurwGDJdFOqxKVXDlPGLfOQ114va4sKnqb9IoeUTqkrNU/JkPOCePLaZ0ON7yEWqsB2K2rYOBk62bxIuXZh6OTFHJ90+auQjJpjy4PQ5R/daIHZrBpBEQ5rQwtyXeKmXoLRmeMi9qYTm1w4TRA/WvyOM5eZ/v6ksVTdd2giGty2CKtNdPo38cangDDbYyMW5n5X3G73uyEsdgdLq3ndW2049px3IAHO+sjqP2UrDiFL6mVcupA81g0ggIPQ9UgI50zkskGJEWvbCcmuH/vrnq7/DAJSKURaleQzLa0Eg7k/ztP8yrETtYgbW79il5PCv3VliMGQHfOz3nFjme1Do72rQmils5eGh3NqDaulse05vXG4pcSkXr1iE9nsUa9WXtaqiKfXUvIitxtIgaMpzDMB09S2ovKx6WNEMGdQ5MjY5jyE4ci6HIkaZ3UNtxSEKU9C7FCs6S6WWyOutFkynBGB6tJ43wqJNvqf6n5JjlWiZ1eZACQWNqSvYN2FHzb+ys/Z/oB/XWMkejO/R8M/SZnTgupI4JrKAz6i3ocDWhvuMosi1DazxzujuQkOi95rD/JZ/HYsKueZg0AmJzNuNAw8v4sOKXqGw8GLWcl3Bg0JswNmMFlhV+GwUZE6EzO7p+aOFk8uTJOHDgAKZOnQq1QWNxZ81/5fH03FuQZMqOyvcq+4RlwL6YDamS/O3wdMDZqc80GGE/uenTpyMtLU1uixYtknJotXKydQMq2rZK38B5+XeGpJVFPSZW0LFtx96656OynYNRrHKkTyuUYFD1uyBphjw+1eZNFB9qWoBHLH/EH9dehiOJf8T++pe7NN6iiWYwaQT1TjApkT3GMkyj4qJ03heGEuttpVhVeidWld6OF4/cHvYfGjvQDx8+XJWd6Ledflz0c5h3Mi4jevotgfaJoVvyd3QkBhwOF1wuN6ztDrnn80hTVFSEn//859i6dSu2bNmCCy64AFdddRX27t0LtcHw6Lbqx+Tx5OxrkJ5QFPIFfHbuZ7okRprtpyK6nYOJFnulVCPqoJem1qGihOVOtQ6dPCanuwP76l/0agEaO5A9LEnu2f9yX/2qqFcNagaThl/cHicON66Wx+MzV8ZdI1v+kA7UvySzX0UaQWk0G84fWllZmXShP3r0KNRERet2cftTYHRe/hcCarxEAmWfnDx58qzXlLYr9igkfztdbmzeU4W/PrOz68bnXB5JrrjiClx22WXiYRs/fjx++tOfitjexo0boTZ21j6JdlcDUk0FmJx1TZ8+W5gyC4XJsyU/btvpf0VsGwcbx5o/kns2uE40pof8Oap+s0Kx0XZsyOhg6Xy0AKtPtuJ3X10v97HSAtQMJg2/UK6fIZ1EQwZK0hYh3oiW6GZTUxNWrVqFxsZGqAUag1uqH+kydrMSA5csRwJlnzQ3n+1FYoNRA4xwM/k7gMZXsFwbh9PlvTmC32x2JzbtqsSGXZWw2b1eJd7zOZfz9bM+F2Dd/N7+4nK58NRTT6GtrQ0LFy6EmqB69JHGt+XxvGFf6Fde4qy8T0sor7JtuyhRawSH51JXdVxqaOE4BRpXOYnjh1S1nMNHC9Da7MCmN0/Jfay0ALWkbw2/P+qDDa/KY4Zy6H4HbINOdNMwSNt0iOaSswZJxhxMy7kRasKb/J0Kq6tBcuT60ujX6XTjz0/1rkNjSTDi9uumYfuB035f5/J5U4fhH8/vRrutd2mML39iFkymvnnodu/eLblLHR0d4l168cUXJbdLTR5kai6xV9yotPORnzSlX+tJMxdifOZlONDwioSA85OndY4XGv5gZWGLoxIGnblfFasMy9V2sE3KliHRnsYUpf6XoaJ5mDTOoq7jkMTY9TomTl+EeCReRTcHSkPHsS7Npbn5t3dpLqkJsyGtK/k7EombyRYTrB3OLs9ST7jcanPK+yLFhAkTRJGYYbi7774bn/70p7Fv3z6ohf31r6DJflIM1ll5tw5oXVOzr0eiIV0MAWo5aQRG8S5RJ64/v01F9btqiKh+25xNUmCgFi1AzcOkcRYHG16T+5FpS/sUY1ej6CZzliLZaFZtSs2bq6m55G1joQyuasOgZ/J3EuxuqyR/J+lzQvqc0ajHF2+e3rmO4B4fvV6HBLPBr9HE5SkWE265bGK35S63y++6+b19hQnvY8d6S7/nzJmDzZs3449//KNU0MWaFnsV9nb+LmblfqZPXj5/cPIxI/eT2Fj1Z/FusvKLzWQ1zv59Hm/+uE/VcT1JNxcj2ZgrHuQq627RVhvcTaAfxuKCeyV366Te246H8gqKFmC05W00D5NGN9octTjZ4k1OHZ+xEvEKpQ/4g+IPy1d0k5Vz4RTdLCgowA9/+EMUFhYi1pQ2voO6jsMyoMzO/1zMtkPZJ3l5eSEof7eGnPzNcJ7JaPDeTMFvbrcHsyb6/34u5+tnfS7AusNR8KA0DlVDuJ1GNatf85Om9fvC3ZNRaedKNabT3Y5dtf8LyzoHG6ete9HhaoRZnyIJ3/2B56KviOVgZmfNf0Xc8+OK32JS5hX45Pw/48c/uR+fXPCXsPe/DJXBNcXWGDCsjKOHIi9pCjITRyCe4Q+KPyxW/zDB2KRPRGXbLtR3HENukjd5cqDk5+fjm9/8puSpxBIKQu6s9Wouzcj5BJKMWTHbFmWfGI1GtLZ6K1p6Qg8Tk4XdcImnKcEQ3v1HQ2f+9IKunCV6muhZorHE5UZD5OaK9913Hy699FKUlJSgpaUFTz75JNauXYvXX/c2tY21/g8vQswzYnPdcFW/UruJfebePvF9HG1aKxpo2YljwrLuwaa9VJK6aEB5XsNT5so4zSR7TjZC0c2KN6qte3G48U15PDn7avFipqe58Y2vfQdJSbFLpxh8e1qj3zAmTi8FmZAZv94lX+hJYqNZj92MPbXP46OKX2JbzaNhK2lnddxrr70W8yo5aunQhU3l4FjnnSn7xF+VXE/l70hqMtEoYnL3XTfOwF03zZB7Po+ksUROnz6N2267TfKYli9fLuG4N998ExddFNvjwj5+22sel8dTsq+XJszhJMcyodNj5cG26kcHVF042HC6bTjZ6vXcD9Srl2eZLMr9lIOot5VhsOFwt0t4l4xJvxAFyTO6xpVXXnklpmNtTA2mDz74QDRLGM7gAMpSZAWHw4HvfOc7mDZtGpKTk+U9HIQqKiqCrvNHP/qRrMv3NnFi91wFDf+UNX8gnpgUU77oqwwmGBKZmHW5DDRMaD/Rsj4s6z127BhuvvnmmOowUciOas0UwqNSczQ1l4LtE386TL4ouTMcICOl2ktPk8GgR1KiSe77Wu3WH/75z3/KPmAIjsbTO++8E3NjiWw//YQYTcyDmZh1RUS+Y0bOJ2HUJUg7nuMtXr0hDaCibZuEK1m5SsNyoF0MhnUaEYMxLLez5r9oc5yWfcW+hmoaa2NqMFGbZMaMGXj44YfPes1qtWLbtm34wQ9+IPcvvPACDh48iCuvvLLX9U6ZMgWVlZVdt48+UtcPV69Xn2OPHpdDDd6QAcuEY33RjQRMYGeIjjDPgnkc8Q6NjS3V/5DHEzIvR2biSMQLHPjNeq97nRdyjciGOMqa15zRXIpQ6T/b70zOvlYe76h5Qs5PjTPVcSPSloYlhKYUdJxq3TJoQ3Hzh92lumrmmOYwMc7Pmz/S09Px9tteUTWFP/3pT5g/fz5OnDgh+QGBYO7EsGG9NzSMRcjLkpQgORvsa8ZKLbX0Zau07pT2Bix17a35ZjwzIety+UG2Oqol/Dg+0//5Fy/sqX0WVmetVM5My7kB8Qa9TN5quRaprBqM+RixxuV2SKI3GZt+EXIH6OHojYmZl+No03vyG2Pz7hm5n8BQxu5qRUXbdnkcriR7bwRAhwZbmah+R6tPZCxCcWoirkYnKggzxJaRkRH0fYcPH5YQ3ujRo/HJT35SDCy1NBB8sfSOiPU1GwiKd2l0+gWq1O4Jl1eP/xsr5whLoKOtFBtO6jvKuiQg5ubfoRrjuy+wclFJ/mbfO43ww15cLfYKUe1n+X80ii1m5d4mjw80vIpWezWGMqw6plBourkEGQmBJ/p99ZZnJ47tCvcN5lCcmoibKjkq5jKn6ZZbbpEO4IFYsGABHn/8cUm4ZDjugQcewLJly7Bnzx6kpvrXG2GugW/Jr5KsygqfcITPTAk6HGp61dtAsBOlrxkZn74SDtvAEyQZxuwPLY4KVLbtkBnLcPM5fiub+rvuUInE+mlcm/UmJCUmwW1zwONyw2l3YphpIZKNr6LNWYVd1c9jQlrfemj5wsRWnmvMkQpUERaJfcIQ6oaaP0tFY6FlHtIwrk/fH8njqewT3nO/sD0Ib4FgmXWHuwkdzmYYENxYj2QD6Eg3l47E+rlfuV6Oj/72McUk6eUhU9I/AXu7B3b07Tztz7mSjknISZiMWts+bK58FPOyvxy2dYeKWtZd2rBW7gsT54f0Gw113TnmaSIjcqJpI4YZF8XdfvGl1nagKxQ3Pf0zsLW7YetxnkZyrCWhVDrHhYeJCeA33nij7LDehN8Y4rvhhhswffp0rFixQkp5mVX/zDPPBPzMQw89JCFA5VZcXBzW7TcazEH7mvH1WFLW5q2MG5Y4C8nGwNo58QSNJYs5ER1bK1Hz542o/fNmnH54Izq2VSI5IQWT0q6T95W2vokOV1O/v4c/YBYvRLuw4Fjbe2hyHINRZ5ELoZpQ9smoUaH1sDPrO5O/Pe0yE9cIDzSqdzX+C244kZcwAwWJc6P6+5ua/gkpRKjq2IaaDvWonEeTdlc96uwH5XGhJby9BIclzpR77ltW4cUrTncHdjY8Ko9Lks5FbuIUVY21ceVhUoyl48eP47333gvqXfIHw3fsGH7kyJGguilf//rXu3mYaDTR4gyHvk6Hsyl4XzN3O1JSwtfXrC/bzNyR8gqv+uyU3CuRkhT8s5HWGwrX+t0OF9o2lqNt/ZlKLY/NhbZ13uej5y1FmfUtmaGVtb+GecPuHND3RXK/9Fw3cxYOVDwvj2fmfQo56UVhW3c4YS4hPbQGAyvVAhcRGGCAyW2R34HD04okY+/5GMHWN1Aiue5wr5/r4j5OTExEQkJCt+NZ2vgu6u0HYdAlYOHwLyDZNDBF776eKymYgHH2FTjU+Ab2tzyFEdm/DFhMEs3fTzTXfbL+PZFZyLVMQl7GiLCuO9kzEUn1OZLD2KY/1mdlf7Xs8y3VT8Hq8va+nF/4uV4TvWOpeaePB2OJOUkszc3O7ntiG113paWloj4cCA40NMR8b0OlrxkHVZfHjoyEkci1qKc56EDR6XWwbvMvQWHdWgG9QY+ZuZ+S56VN76LZHlyuIhC7du2SfDn2DYsWW08/CqenQzqXj02/EGpD2Sf79+8P+TNnNJlaNP2eMMBJGqvUyPScm5Bsyo3JdrD5s9mQKn3rjjS+haEqVhmuZO+eXrx4r5ar7kNVXCzGWlUZTDRm+M8rO6CsrEweM0mbxtL111+PLVu24L///a/E56uqquRmt59JlKYwHKvnFKgw/P7774tmw7p163DNNdfILIy5T7Hua+aPCZmXRr2BoALDH1SM9W7HZWFT/VUDbptTPEr+4HLe8pImozB5juQB7ap5sn/f43aLmnOk818Uyls2o7x1E3QwiFdMjVVl/dknlBfQkr/Dx7bTj4umWmbCKJEJiRVmQwqmZ98kj3fXPj2k5COabCfRaDsm53VxanjDcQpdbVLatsbdRMPRx6q4aI+1/ojpaEtjaNasWXIjDIvx8f33349Tp07h5ZdfRnl5OWbOnCkeIuVGQ0iB3qPa2tqu53w/jSPGO+mdoldqw4YNyM2NzQyrt75m4zNXQh8hTZTeKG/ZBKuzDgmGdIxIXYLBhD7BCF2Cf/c/lyuvseRZx8aOrRtR234Iah9gtp7+pzym8GBGQny3rvGFhp8iZBkp5e+hAgs4KBrJ83r+sC/EXFNtTMaFcq7SgNtV+xSGCsebvfp/BckzB9zgOBD5likiFNrubBCJgXhiZxxUxakqh+m8884LahWHYjHTk+TLU089pfq+ZpxBs5cWB7Z3Tnxf3LU0nqKNUpI+LuPimDQyjCQetwdJcwq7cpZ84XK+zusIy3xHpp0non47av6D5cUPqNbTxhk6DdxkUx6mZl+PwQYvKu2uRq9OmdshwpYafYPJv5urH5HH4zIvlYa4sYYG2+y8z+K9kz9CaePbGJt+cdz3qewNXruOdSqdj4hAOE6B4zYb+Za3bhbF/6zE0YgHqlUuUBkI9fnzBzFKXzO33SQXA864KBa5u/YZ1LR7KymiRW37YWlfoNcZY957LBLoTQYkzytC8qLiLm8S75MXFyNlQbG87ptnQeXjmvb9qtU0YTsXRSuLTVON+gQMNjj4KxpggyV08/Of/1wM8HvvvTfi38Xkb2q7eWft2ZieczPUQn7SFBSnLISHfeZOPxZ34aO+wrGVx4GtmNgsN5IUdq6fYbl4wBEHApWB0AymGKDEYEelnYsRqcskh2Z9xe9hd/mvpIsEhzq9SwzFUWF5MNK+uwqm/BTk3T0fuV+Yi9y75sMyKQ86Y/fTPtmU05XnQTex2xNYM6gnrMD88MMPI1rqyu3ZVPU3udjweNHFr2aUfULh2L6iJH/bw5T8zWpJ6m+5rHa55/Nowaa7f/vb30TiJJJwPyVazNCZbJiUdQWWFX4LC4bdozoB2ll5t8nE5HT7Xul9OBRaoRSlzo/45Ebp+8lJldVZj8EaihsfhbG2NzSDKYZw5jkv/3ZpdtvmrMGm6r9FZebFsvQTLd4BizlUg5WO/TVoXLUfTXsr0HqoBjV/34ym1Yf9vpc5ZmZ9slTzHGv+IOTvSEpKkhw73kfKa1Da+J7kJzDvbVbeZ6B2lH1isfT9gq0kf7vgHHDyt8fpFmkJ6m/VPLxJ7ts2lcvyaBS0sMvAI488gszMzIhqLXE/vXPifqw6eidWld4lHewj3f6kP7BSb1LWVfJ4x+kn4lo7qLdimhMt6yJWHdcTizHjjOp3qzo95OEIxUV6rA0FzWCKMTxhFhd8VaqeTraslx5MkYYnrAcu0QbJSgxNXDDecLc74Kj0qsHqhyVDV5wCT4cTjlPNcNZb/VbzTO7MI2OuUKiD+cmTJ6VYIdztd5S+gzqTHaPSl4nXYF7+nTI4qh1ln1RUVPQz+TvFb/I3JxMeeowcLrjtvdxsTrRuOCk6XEq1pKLD1brxpLze8zOB1t2fScw999yDlStX4sILL4yosUR1dBpMDo+1S9dtb91z2Fe/Ss4htTEp62oJF3KCeKD+FdU2Ix8IVW27JKTMYpr8pGlR+c54CMs5BhiKi9RYO6iEK4cC2ZZxmJ5zC3bW/kc0dnIsE5Ce0H8xwmDQEDjS5FX2njCIvUu2441yb8xJgj7Fm9CeMDoTttIGtO+uRuq5ZxuK4zNWSJ4QheAONazG5GzvbDgYdXV14kW46667gjaE7k/fQarD8wJIz9L4zEswJcvbBV7tKPvkC1/4Qr9mgwzLtbso9srkbycMeu8w5XG4UfvHTb1+XmcxIvfOeUF1uJjfRo+jp713SY+8ry6Czhx6pRkLT7Zt2yYhuciig83dGrCDwORs9Z0vDE/NzL1V2kJlJoxUbTPygXCsszpuROriqFUoDk+ejd21T4mxxjFejTmOOwdYFReJsbavDC7TPo5h7gFnIxSRXFf5u4g15aWQGvND6B6PdDJiLLEf8xpM5hFnPDKWacPkvn3Pacln8Zd0rCTKsmFpLBKP6RXgd0tj4E51eK/X4HnVeg0ikvytSwT9OvZ+SAwYks1wWx3BdbjaHfK+cMNZ8Fe/+lXRjqP6diShl5j5jwE7CKi0sXRJ6mJcWPIT1NmOqLYZeX/h7/NU66aIV8f1hMLD9Nzx+nHauhdqozpOq+J6onmYVAJDEYsKvow3jn0TjbbjUuI+J/9zYf0OhhYUKYHxGZfFXJ8lUvD/tB1rkMcJozLh6FxOD5M+ySQXU9vRBiSOO1s5fkTaUhxoeEWOAZuWMlE1muh0xqB9B9XoNYgECcY0OBwdYrQmGjMl309n0iPny/Pldb0++LmrM+ikKtKf0cTl9DpmfbJ7SMDtdvldN783VLZu3YrTp09j9mxvIi6h6C57YFFgl81Jw9UahWF89mpTYweBYLg8Nik64STAXzNyyq/Eq6eJ5f1Oj03yUpW8omjA3wdFLKmmTtXvwpQz51+sccRxVVxPNA+TimC12sJhX5LH7L8Ubrn7KusuNNvLpdR1dPr5GKy46tvhbrEDBh3MRWfa3OgMeiRO8TYXZljOHzQiZ+R8susYtDlqEE0crrbgfQdV6jUIN0zA10PfmfzdLsu8RpNBbnpz8Juiw+UPRYer52cCrbsvulzsPLB79+6uDga8zZ07VxLAaUyFt0+dBwl6/321qNwfqw4CA50U8PV4F6vkxCvaem7DkxXV722qkm3YGYcClYHQDCaVUZgyCxMyL5fHG6r+LBVt4ZYSoLFkNvjvbTcYULxL5qJ0uQD6kjQt3/ueo/Vwtfp3/7NsPy9pilS77Kp9Ouh3UUGeCb55eV5DbKBJvCwFV2vfwVBR9kl/ej/6elzZg6y/yt/U2aLeFnW3etPhCiepqamYOnVqt1tycrLsCz4OJ5Igb0wVEVyTLqnrHGFHAVZ9qtVL0/ukIHryKuHE5mxGZdtOeTwyNXrhOIX8pKnSaJnitmzJMthCcblhHGv7i2YwqZAZOZ+QHlDMNVpf+cc+6QIFgs1lK9q2iyN/fOalGMzYyrz5Swkjz64oM2YnwVSYysk52vee9vt5zgxn5ngb81JioKEj8OAzfPhwEScsKhpYkj49Rx9W/FIGXCZ4x5vXwN8+GTbMmzPWXxRNJl5Eabz2FeptJc8vQt49C7puTPbuqcMVrzjddrQ6qkV89sKSH+OaMf/ANWP/ISEtNSv399aMnAnLO2ueRIu9CvHEiZb1klfGsTstYXjUv19R/SZU/R5sobjhYRprB8LgGDkGGVQBX1x4r/QIosjb/vpVA16nohLNaopUcwEGK9TYsZ9sksfmkf71byzT87vCcoFc19mWsShJXSRhj521TwbV29m4caPc95cWeyXeOvF/EoLdVfc0JmVehalZ13frO8jnavYa+NsnbW0D8xQYfZK/+5uAT08SQ7HMXZP7PlS7hYu1a9fid7/7XdjXa3M1SXUZE4072u3eDgI6o+rPkWDNyDlZYKUXCx9eLfsK3i//uTxXU4gpEMdaPoya9lJvYblTbeFN51BDKK41DGPtQNEMJpWSZi7EnPzb5fFAW6fYXa042rR20AtVEvupZk69oU82wZjr3/2bOCFHEnldDe2iyxQISj0wsbaybTuqrXv8vufIkSOitXPoUP8a99Kj9Obx+yS3jDls87LvhH1HPUa3nItrRv0dV5f8Xe75vGNHTVSVqvuLsk969nkciJeJYbl4uGhGC7fHDZvLe+FQFL1j2cU9HM3I+ZzSGewpWJDMhuwe0RVaU/4gXj/2dRxpfFu1VaKtjtOolTFah5K02DUyV5K9qfrNhryxQK/X47T1QNir4gY61oaD+M2uGwKwdUpV207pPM7WKZeM/GW/co9Km96TypR0c7HEuQczdiV/aaS3ssoferMRiRNzxcNk3VUtuU7+oCdubMaF8sNn1eLFJT+TvJHwVSy+ih01T0jLk5zE8Vg6/JtI1KXj9Mcbpbqr1WKU0vfmNrvoBTEHJ2nG4PUO+oPnu86pF08KXfwGqE9fJhZwEkRJAXqU4rFJ8VnNyA3J4nni8tykSTgvaZL02aQeWlnTGplQbK7+u3gtRqcvF08UpVHUluzNnnlJxqyYbQcnXWy4TIOJqt9jMpZH7budnWK77JGapR8lYrv1HWVxXRXXE83DpPrWKXcMqHUK858OdVakUKgy2pUb0cZ2LHD+ki8WJfn7UK2oPgeCs15WFXIAOtnZTmagUFhuQ9WfsL3m32IsMQn/guIfyWDHbelSpm53wllr7RJXFP2gANpCg5Vgyt9DFZHNcHWGnaVKThf/zcj9hBLTzMMxN//zuGrM3zAr9zMyDvJifKDhZbxy9B58eOpXOG3dF3RMjIaKOL+f+nbR1l7qPSwXvTwmV6fYrldXi7cvoN52FJOzr8FgQjOYBnnrlFOtm0W5mm5ulroOZlxtdjhPt50lWOkPJn4bsiyiHt1xoDbg+xKN6TITJsxlcnkUVaf+warHd0/+UJLJqaEzJ+9zmJ9/d5eXQJ9g7Krq6gmXB3ptMOOb/O0JQwFEvMOZvNNjhw66QVHt2lsokf/jxKyVWDnq9zhn+HdE4JcTjfLWjfJbWn382zjatKab6GVXayGzoyvPK1JQs40eML3OhOKUBYg1SpsU5n5FQwjUGURsl/m3ag2j9gfNYIqj1imErVOabOUhf1YRqhybcbEq5fIjoe5tzEvuVcWZnjZFYiCQJpPChKzLkWhIl4qk0sZ3u71mNBqlZJz3vcEchzePf1e8VSyZP6/o+1Kx6Ov1E/2g2QH0g2YXwlHRAmeTugegvuyTkNanT5ACCFH+DtAKZCiheNrY/3Cwis/6g/8ruxNcUHw/Lh35a6m8MujMUkLPaqyXjt6Fg/WviQf3jLcj8iriinepMHm2KgxYaTljzJI0DJb1DxZdLWOYx5X+oBlMg7h1Sl1HKWraD0j3dxpMgx1fde9QEBFLvQ6OyhY4agNXdDGplqE5QjViRUiRUFuHyc3Tp3vLeYPlkb178kfocDUi3VyCFSUPYVjyNP+l8HMKkbyoh37QomIkzy5E01tHUPfYdlh3VKo2CVrZJxMmTAi/l6mzyexQhfIKitFII36okpFQgvnDvoCrxvwVM3I+JW1BWEmZbMrz6+3g7zYSrYWonXai5eOYV8f5wgnYGRHLrYNGbHdqiGNtJNEMpjhrncILh9I6JVShyuLUxTFNRIwGNB66+sf1kr+kQC8U26WQ9l3BvUxMnkw1Fcjs/kD9y326wG2tfhSbqv4ij+myv2jET5Bi9nq3etKxvwZ1T+6CqSAFeV9cgNwvzvfqB80vkgo5vcUEj8OF5rdL0fDsXrhU7m0KF8xjSjUNk+pRnc4jx5sXq6EGjQKayfS4DXaPcSgw1YBNsq8Y/bCE66hDxETxaKmI17TvF6FIiocWSmWfOmCbFEKpkkhPrEwUTo1zsd1Q0QymQdo6hSWlJ5rXyeMJWYNbSoA4a9qkRxzlAsyFZ9qh9IZlemdD3n3+G/IqUBxweq43LHqg/pWukt39+/djxowZ2Lt3r1/l3zXlP5FjRaZl34QlhV/vKgPvCb+/9eMT0tqFuVhtHVbYdM4u/SBjeiKybpmG1PNHMU4F+/FG1D6+HdadVaryNin75PDhw2FdL0MtDbbjaLAfR4PtGNqdjUPKaJJkb6c3HDeUvUvBwnX0IAXzdticTShv2SLnTjjDccWpC1QlFupV/TZ3qn4fj9j3VLXtlpZb0RDbDTbWRgvNYBqkrVNYCu+GCzmWCchOHIPBjqLubS5O75OSM8N3+mSzVKLZjtQHfW9xykJkJ46T5pp0+cv32mw4evSo3PvS0HEcb574rnQOZ5XdssJvY2rO9UFlCZhL5WrsEJHFpDnD/SbE0t2ePHc4cj49SxLXPXYXmt86gobn9sLV3H0bYoWyT+z28OSM0CjiBa7d1SCl9LIMbnnO5awEHajByO/Q63XQ6dXrvWL5PXvrsceeGnJl4lFFnPttU/VfpJJr9bFvY1fN/1Bj3d+vbgosAFEqZ0fEoBVKMOh9HJY0LaJhubKm97G2/KcijcJrkj9drXCK7QYaa6OJpsMUp61TeCFusJVJ65Tzi3/QLfmT+U3sWq1ICQwFfPWX+oJOr4Nlah7aNpbDurtaRC0DvpctU3I/KblIpY3vBNy3HETXV/5Jki5ZCs1QQXpCcdDtYJitdf1JeZy8sNirSB3E3jBmWZB1y3RYt1ag5aPjEo6sfWwbUi8YBcvU/EEmH6FDR2cZfU+43GLMQJPtBA+Q5OvRG8jfA8Mv8liWeZf7M1gVg4zroiHGtdCDw/WGS3crnMneDMurabvUqCLOnKWeTMi8VNqtePOdmmX85G1v/QtygWc4j2G1YckzQkphaHaVQacziOc/L2ky1Aar5SgtwDYpU7KvC9t6PR6PVMDtrvP22cxIGAmjLrCu1mBCM5jiuHXKm8e+3dU6xfcHcazlI8l1oCR9Ucp8DHbcdpdX4Vs8RqHlL/XUZKLBRKPL1WKDITVwbgib8rIahh3BOTsFFnS78O6ue0YGEzIsabocJ+ZZ9IZ1eyXcrXbo0xKQNGNYyMZe8rzhkofV9MZhSV5vXn0EHQfrkL5ibND/I55gfy7Fs3T2a27xDtCAYKm9Cw7pE+gLDSAaS0o/OsWg0sMoshF2V5t4q3zXqTzvj9H0ox/9CA888EC3ZUyAH0goweV2wO62dkuA1wisIq7kLDEMR2OIRhSX8wJ+ycj/JyF1lt2zvybFgZlIT9kW3khGwghRGy9Mnileep4zCg5nByzJidA5S3Bl2sNotlWoslpRVL+rWfxzRCYEPJcHitvjxObqR7rkbSZlXSUTeOU3wrYler0JhiQjK1gw2Oj3NOX999/HFVdcgbFjx8rtyiuvxIcfeuO5ofLBBx/IOgoLmcipw6pVq86yZO+//34UFBTAYrGILHooeREPP/wwRo4cicTERCxYsACbNm3CUGmdwv1Y1qi0QblElT/kcOMob6J/XIwNQ6b//KBgGDMtMBWleRvy7gme/E1m5H4S6eYijEw7BwmJ3hkUtV5q2w91uegnZl6Bc4u+F5KxRLHK1o1eqYiUJSV9bg7LhsJZn5iOlHNGAgYd7GUN4m3i/6Km3Kb+Qg0yGj3+X/MaQylMCDcVikePHgSLIR2J+nQkG3PkWPE48D7RwIuGRyodORM26ExBvVf9FYWcMmUKKisru24ffeRVgu4vZ4Qqk+JS2TsWKuLXjHkkYENieoVGpZ+LJYX3yusXlfwEU7OvF5VsHnPm/XAiSm/yC0c+JyKZx5vXSR7dgYaXRKrg5aN3Y1XpXaJ1Fw29o75CL1lWwmg539neaaA4XFbp7UdjiRpgc/Nux8zcT501oYiXFj1RM5j+85//iPGSlJSEr3zlK3KjQbN8+XI8+WTgRqU9YXNOJnHRwPHH//t//w9/+MMf8Ne//lWa7iUnJ2PFihXo6AhcGfT000/j61//On74wx9i27Ztsn5+5vRp/53p4711yojUpdLCw+lqF6E2vdmO84q/h2WF3xGdkqGAr7p3f0NRvppMvRkZLGm+sOQnqLeVYr/hd/jOI0uxX/87VFp3YHnxjyVfaVbebSEbq22bT8HT4YQh2wLL5Lx+bT+9TSkLipBz2yyYhqWIIji9To0v7oOrNbox/9GjR+PFF1/EiBEjwrRGT8AkZ+9yjxgRJoNFquk4k04y5SDRmIbDjau71Id5X9r0thhXqcZholXDnmzBvFeBXusNasUMGzas65aTEzjU2xv0XCrNhzXvUnhUxH3h75RepGk5N2HFiJ+LobVw2JclL4mGNo1rimTSuBbJgvoekgX1z2Ff3YvieVIbiohlsAKhUGCu7Dsn70eVdScMugQsG/4djMtcgViMK3TQxAqdpx9T0EmTJuHOO+/E1772tW7Lf/Ob3+CRRx6RbPY+b4hOJzvj6qu97lRuFj1P3/jGN/DNb35TljU1NSE/Px+PP/44br75Zr/roUdp3rx5+NOf/tRl7RYXF+PLX/4yvvvd74a0Lc3NzUhPT5fvS0sL7wCldFpOSfG2exgoDlc73HCKQCXLaRUXNAURp2RdE7YYcri3O5zrr3l0K1x17ci4cqLfHKRQ1s0cotN/3iRJ1Jk3TkVCEKVwVuJQGE9J/PaFs1S6qUNNdKQ6ee0jW0RxPOOqiUgcnzPgfULxy7bN5VJxR8+bLtGItAtGI3FybpdB6XWd62XSE26U7abRUFZWhlGjRom3dyDQaLA6GtDmrPXJM0qDxZgeMC/pQMMrAY7RDZiYebl8juNMg+2EX8OI35GZUCLHsi+GOENyv/zlL2UM4f+9aNEiPPTQQxg+3JvIbzD0zetrc7ag1XkaBhiRnlDSbVs4eeQ+zsvLQ0JCQkR+n5H87at93Qz3NnQcRbV1n3js2fLDXxUex1x6qmicqWmfUCSXYrmUobh27GMysejr+ulte7/8Iam4SzCk49yi+wIWEqn9eA6Ufh1dZqozlNYThuW+973vhWO7ZBCoqqoST5YCByAaROvXr/drMLEqZ+vWrbjvvvu6lvGiwHXwM4Fg1r1v5j0NJt+LSjixWsMrvGdK0OFg0+tdeTNnZOmfE7fp+PSVcNg8qtvucK2feT80lhg5ceQY4ez8UfVn3YaxGXDuq0PL9lNwZAf+adCTpyjbNpxux7tPH8Xym0YjM88iyydnXdv14+4N20flYizp85LgKEjotv0D2udTMmEZlgjbmhNw17Sj6fVDaN1XBcsFI5CQZEFSYhLcNodIGTjtFEN0hC18x9/uv//9b9x+++0yYXG5XHIbKCZ9It49+f1e30cvzJWjHw6qPswQzctH7wmpP921ox/vU6XP3Llz8eijj2L8+PESjnvwwQexbNkybN++HampvYdoe6KEDM361LPCHdyvXEbDKRz7ONq//XhYdwIKMCqpqFfJAgo42h3mAR+HcO4TkycPifoMdLgbcbx+C/ISp/Vp/TUd+7Cl/k9wetqRYizAguyvIcGZG3B8i+TxVMaVL3zhC+K1DTehGGL9sgbosXn33e4tIsg777wjr4UDGkuEHiVf+Fx5rSe1tbVysvblM4SzPxpjyi1c/0M0MBrMXc11/V0Y+PpgxnXSG6qgwaFLGNjszjQpW+6dRxvhCdCQlwY0k2+VgbOxpgMvPLxf7rsGTrc1JEPb3WKHY69XFsK8oCDslW0S4rtmPMzzh4miOZodSLIkoWNrJWr+vBG1f96M0w9vRMe2SljMffOiBKO6uhq/+tWv5PcYTkK155in1OFsDnpx63A1d+YzhZ9LL70U119/vSgSMx3g1VdfRWNjI5577mxvV2+w0pIyFtI3ThrtasQCXld6kyzg65EyWvsLf9N5iTPkcXXHjj599qT1Y2ys+40YS1nm8ViS+z0kGXMRK5RxJdi1PNL06wrDMBnzlnbs2IHFixfLso8//lhCZb///e8Rb9AjxbwnXw8TjSZanJFy/4VrvR3OpuCzHnc7UlLCF1aMtDu0r+tvrPQmS1tGZ/f62d5e9yQnw5FTDmetFYYT7UiaVeD3fUzw5gAZyDXPgVOqRHqh6cND9PnDXJKOjIkF/d7uXjk3FY5JBXC3O9C2rQJtnfIFhLlObes65QzmF0FvGniRgBJ+4z0NR4ag+hqG8odenyTeHtLb+igpEOwYMX/p4hE/7Vqm6C4p4T6Hu6MzBJEKszFpQMYk+1/R21RaWtq1P0Kl3e6dyZv1yTAaz578cF1cJ/d1pEJyCkN93Q5HOyZkXCo5Sz3hcrfLGdb/I1zrGomFOGF9HzW23ZIH3Nv6u2QDGryyASWpS7Bw2Bf7lN4RieOpjCtMI4hVWK5fHqa7774bTz31FHbv3o17771Xbnv27JGEa7rLwoHicqNV6QufB3LHMbGSA0hfPkM40DBXyfcWL/Q+6xk8svT+cnVsxxv71D8uGLwoUmKAWHdX9ar1MhBlW2edFe17vYUIKcvClRwdGFNeMsxFabBuq/D7OvWcmDiuZnh8GBoL5RbKMfJ9P38neiTAAIs8Zq4Hc5zoLVTkCPoLwxc0lljt29f8GaVvXIJRU/aO9VjTvq4Kk7OvwdSs67sLNGZdL8tNxvAINIYb9iBlwnqbswZN9hNB38tzfVP1X7s0lpiPubjgK4NOT6m/9DtB55prrpFS2bq6Ornx8VVXXYVwwURRGjm+oT96flgtxyRKf5jNZsyZM6fbZxjf5/NAn4l3wnHxjlcc1a1SXaYzG2Aq6HtuiD+kSk2vg7O6TdYfTOuFycPGzjYnvO+Lsi3FJiljkDA2q0+tXAYC5QvoUfIHlwd6LR7xPUb9UR9m+IstbDzwwOrsW2iRRSqUXWGj0HXr1slYyYlcoEKV4H3jPCIKyKRdjdjBSlbrplNofrkUEzOulARvRbJgguUy2I96UwPUCFW/aTQRilgOVDZgKNOvkNzmzZvFEGECti80ZjgwMOkx1JnXkSNHuiV1McyXlZWFkpIS8Vz95Cc/wbhx48SA+sEPfiCVc0olHaGUAQekL33J22ONobVPf/rTsg3z58/H7373O5Ev+OxnP4uhKtQ26NW9R2SEzTvCtiSJ47LRcbBWJAZM+SlBtV4s02Zi+y1JuHb6TzAyqzik/e2oaoHtkDd3KWVp5L1LCvoEI3QJBr+GEZfzFg4yMjJw0003ST6gw+FArFCO0eTsa+ViQM9RqOrD9GZR+LXZflJy1ihuGWo7kvLyctxyyy0ykczNzcXSpUuxYcMGedynvnFdyt6sBFS3928w4zjdilZOcHgsRmfCZLLItctgMItIbMvrh2HMSULimCzVHif22aPYbkXrVoxIuNivbMD7px6SijjKBiwp/BqGdzbwVQsZneNKZubAowlRNZjuuecefPvb3z7LYDp16hR+8YtfiOEUClu2bMH555/f9VzJI6LBw3wofgeNHUoYMGmSA8/q1au7lSjT1e2bXModWlNTI4KXTA6bOXOmfKZnIvhgouvCMMhl6QP1j6P+UjhhWE4Mpv01SD1vVEAhSRqrw/IL8c9/PNan8vyWD7yDL8v8TbnJUQ0rJM0p7MpZ8oXL+Xo4dE4pGvuPf/yjS1YgliieJIOx04vXh7Jvo94sieHtrkbxMtHjFMpsm+kK/uhLQjBzD9mrjPlUZoOW7B0rPE43ml7z5hrSG6yE7JXjmTQ2G62mUsl7dJxqhrlInaFTdicgtR2HxRD31fPqi2xALFHGlbiTFdi3bx9mz/YeAF9mzZolr4XKeeedF7SUmdb6j3/8Y7kFgm7vntDbpHichgq8MAx2Wfqe4SVHRXO/+sf1Bj1W+tQEuFts6DhcB8ukwJ4BlnNzosDWF6FoDdlONMLOvCsKTS6JnneJMKE7ZUFxV84SPU30KiXNLkTyvPAkfPvuEw5w8Q4Voe2uVkn0ZzuNJJO3kjLSnPEupUKvhURiRsuHx8UYouc57eKxZ3mQ6LVNnJgr3mjrzirVGkw8bzMTRknvvDrbfhSleFNUqtp246OKX4qBnmouxHnDv4cUszqdCx19HGsjQb9+iUyS7plYTag5wlmlRuwYzLL0vthPNEkOkCEzEcaM8P54lIa8hANhMA4cOCBezFAmCpwctHZ6l9gvLtzbHQr0lrEaLu+eBcj94nzkfXGBhB0bnt8Ltz08+W7KPvENt8cr9CgpRhL1kKLRAoN945TqPk3ZO3ZwcmPdckoep7E3Y7J/j73S+5FeaVaiqpXR6edJF4LROUuhMzvkXKa2FCtGcy2TpD2MWo2lvo61qjKYLr74YinFpxK2AkNmFK286KKLwrl9Ghp+sXXmLyWE2bukYJnqHTjoDXI2haflge1IvTTI1Zn0SF4YO60vepLa2q2w6bwGUsvaMjjKm9G2wSvRoNEd5gSyhxsTsEVpPML9+ehd4jcwBMiwoEZsPNhNr3v7llqm5yNxbGDPonFYCox5yaKq375HvS24RqdfIO2cqFa+qvR2vFh6pzy/qOSnOL/o+yH1vRzq9MtgonjUyZMnpVcUc5B4Y1I2c4Z+/etfh38rNTR6YO/sH2cOc/6SAr0/1EcKxcsUCswPUhJHGQIzpJhV4Y2kxyn1/FHyvG3LKTgb2mO9WapDSQBn5RBDF/YAumfhQOsbpw6a3ymVkLwhPRGp57OBbS/nR6eXiWE5NTa8Vto5UV/Jtw8en7OtVn97Jg41+mUwsSfSrl27pDnu5MmTpZSfgpXUZYonlWyN+IQXdVdjh+QBKUZNJLBM9w6CnDXS4BkIHftrJBeCOUMMiamJhDFZXsPT5UHLmvAnaavxAtJXqMukKINbHbXStDcSsCLPDRf0MIhYZaj7Vq3VWfEIQ2sd+2qk3VL6yvHQm3vP7ZM+jSYDXA3tsJ88E3lRCxRyDdYqiK9r9E6/9xIVQ1m9pqERK++SqTAVenPkfuiJY7PQnGCQmSZDc/0Vx2S/ttaPvd6l5AVF0Ceqa3DixZbNeWsf3w5baT1sZQ1hEQL17fFosXj1quIZizFDhCRZvdburEey6exGzwPF5mzq8i6FYgRx35Jw97zsSaTXrxZcrTY0veXNvUteUAzz8NC8fByHaDS176ySW0JJZDzf/YV97oL3wbOeqSTVCEi/Ru5//etfoqq9cuVKec7y/7///e/ibfrf//4noToNjYjnL4Xxou4PzhgpZGndXilhOX/fxyTElpaWoKWu7buq4WqySaVN0qxCqBFjdpKECpnk2vzeUeR8ZhZ0hv5dJJV9wknViRMnRObDZDKF5aKrlOaHo9VKf9atd6Wi3VkDB+rhMZn7lGPU2/qdbjvaHG10bCDRZEaHq6PXkCr3LSUtIrE/5DscLiRbkuDucIrhT09ruKop1Qa9dU1vHBYxXGN+MlIW9y1awrAcjaWOQ3VwtdkDJonHsiNE4HZO6u8IMTOEsVaVBtPPfvYz/OUvf5HH69evx5/+9CcRiGSTya997Wt44YUXwr2dGhoCB22pkIuA/pI/qLtCg6njSJ1UwOgtpj593m13oXW9tx1B8qLikNz7sYIXiI59p+Gqb5cWKpQaGAj0kLAdCLWYjh/3etjCVQUaCY9HqOtmY182xTXo6pBozAjb+pm7xFwTCgc2GEPTbOK6KPJLT1O49wk1iNo2lsu50CVBMadQpCkCaZPFM/ydi/faqEfGygl9njCw2tRUkAJHZauE8VMWFKmuI8SeumcDd4TQwnK90q89xITvsWPHyuNVq1ZJZ26G55YsWSLaShoakYJVZh67CzqLEcYAKtzhhIMgK2Ccp9vQvu80kucM7/b6oUOHcNddd+GJJ54QfZCeWLdXwN3mgCE9oSsxVK1QUyblnJFoXn0YretOInFSXr+S03vuEyr1K6GjgUIhW+LbRDRchLpuq6MB75f/DC7YMSPnkyhOnT/g9Ttc7Xj3xF/gNNiwIP8e5CZ5E/F7g+2gmHtmCrMXiJ4lGkuRbtSsFtjbseV9r6Zf6rkjxePaHywzhsFReUQ8Tcnzh6smt2wwdIQ41MtYq1qDiS4xyv5zZvPWW291KXRTTKq9Xauy0Ygcts78pQS2Q4nSYEQvU8u7RyW0xrCV7/darVZpFaRcDH3hBYwXHUKRyv6GuKIJ9afad1TCUdWK1g+PIf3S8X1eR899Qs9HuITmnE6vFEIkhOtCXXdiYgEm5C3Hztr/YnfTvzAia3ZIatzB1n+y4X206ytFPLAoc1rI5za9QK0heIFoRDHUxHNSDKsOh89jn+XsN+j2IPPKiUEbNafEUBYj3NDIbHz9EGOiIlqbNKtvTZJ9SZyQi5b3yuBq6vDmPUZI9mQodoSwBhlrVW0wUWvp9ttvF2VvWn2XXeZt/rp3795Boe6rEQf946I4EDGPiVpFrHJzVrfCNCw0vZK2TeVyEZM+U0HUwtUEL9Spy8eg/r87JaxgmVkAc5gaGw8mJmStRFnzWjTbT2FX7VOYm397SJ/zFzZj7szhxjfl8biMFSEbS0G9QB7AXJyOptXenBx6ZUOF56urzdFro2ZdkvonAKHQuv4knFWt0CUakX7puAFNxBhyt0zx5j1ad1SpymAaih0hwk2/zviHH34YixYtkoTD559/HtnZXlGvrVu3StNJDY1IwBwi5gdEK39JgVVtieO9FVHWXaFpMrla7V0zdDbYDVdz4GhgLkxF4hSv0nnLu6WDQhYg3Bh0JszNv0MeH258C3UdpUHf73C4YLEkwaMzwuVyy3OFmvb9aLKflNylUWnn9vrdPB6O6lbwuh7QC7StAqaCVHgcrm7Gks5sgD4tQcLMlORIGJ8twowMHzEcy/YfKctGSCg2UDPmcDZqjjX2Cgq2eg3OtIvGwJCaMOB1MixHbEfqZBxQI0OlI0S4Mfa3azATvXvywAMPhGObNDT8YmMPts4ZcDgGtj435N1fI7e080dJBV0wOAh7HG65aLFpZ7yRes5I2A7XeRNY955GUqfyucYZ8pOmYETqMhxv+RBbqh8RxWS9n+7FTpcbm/dUYfuB07DZXUgwGzBrYh7mTy+A0aDv8i6NTFsKsyE5cLFDebMcExYgMN8s45rJwb1ADheybpwmoTka/fSghGq403sVsFHz7PA1ao4lLMiQxroeiAfYMjE8XmA21KbkiaOiRaprUxYNnvDlUCdkg4lClVOnThWXMh8HY/r06eHYNo1+MJj1UiKt7h0MzsaZuE15AJYN0+1OmMf3yCOPdAtFOxs7RPGXpJwzQjWJn305V+hh4EDPRNjW948hcVy2XKRDwd8+GazMyrsVFW1bUN9RitKmdzEu4+Jur9OTRGNpw67KrmU0mpTn0yYm4mTLxq5wXM8Lur2sQQwk6mN1M450gCHZJJ4ef0YTl9NI6m9pe9BGzbMLpfhCbVpDfYVhdgrg6lPNSLtwTFjXnTSzAE0VLbDuqhLttXjyMKuVEhWMK8a+aCCw9UleXp485kXAn6ueyxW9EY3oMdj1UniuRbp/XDB4XrO/XOvHJ2DdXdVlMGVlZeHmm2/upg3Suu4E4PZIAqkaLypKeKjD7pTwkNvtgcnPuUIPA0OQVC9mnkfaeaFVbvnbJ4MVizET03JuxrbTj2FXzZMoTlmAROMZ9Xm9XieeJXlvghHJFhPa2h1otzlleWrREXjgQk7ieGQmjhL9HhEPpZHECYLrzBhLHS96KxPGZkvRA38TAb1AcwbuBVIaNTPBm+MKDTDH6TbU/W+XiLlm3TJdqkjjEdvReqlkIyxsCLeYbOL4bDS/Z4S72SZ5lwmj++ZlHswT3/6ihnEl5LOEWiq5ubldjwMRywz2ocpQ0EuhNpC7xc7kEZiL0mJWQUaDyXGyWdqzGDMtksf34osv4tZbb5Xfh6O2DR17vRfI1HPUJ+DaW3jIF1b1pV0wCg3P7xMvQ9L0fBizei+37rlPBjv0DB1tWoNG2zHsqPkvFhZ8ses17mMaSSsXj0RxYRocVgdMSSacqGjG+9tP4kjTO/K+4oZ5qPt4Fxynmrut25CRiIRx2dL8lWEeX08FH/n1AoXxt89JlzdJWI8kgxmmvGTxPvL32PDCPmR/akbUw+MDxW11iEAl4b6i8RkR0Vsmf2+tEG9zqAZTqJOZoUiNCsaVkA0mX/Vuf0reNptNksHZX46eKI3oMFT0UhTvkrkovdf8oUhhSEuUcCBDg+17qpG6bCROnTqFb3zjG6I/xh9x64degUZe5EKtposWvYWH5k0ddtbgzIE+YXQmbEcb0PxeGTKvm9xriLHnPhnsMG9pXv7tePvE91HWvAZj0i9AbtJEeY0G6S0rJsC2tQK1Lx3oMmqyZxfivGWtWF9bD5PNgtR3M+Bwe40l47AUMZASxmWJHlCw/e3PC+RxecI+UVKShGlEZ1w1CXVP7oSrzms00dOkZkHWs9S83zwsRhP3LXP1IgV112gw0WPoarbBkJYQtsnMUOSUCsaVPh0FGkX33Xcf5s6di8WLF4toJXnssccwatQo/Pa3vxWlb43owRlnML2UwRI7t5V16i/FIH/Jl6QgDXntFS2wHamXqX/qMvV5l3zDQz3hcr7uj9QLRkujY+bT0HDSOJscywSMTr9AHm+ufgRuT2dagtMNO70M60925Rrxns8PV7wmzwtOToGlOAepy0cj9wvzkHPrTMkfM+Ukh5T/xglRW7sVNp1TDJpIGy80yjKvnSIhQgq6Nr1yYMDNqaMFCxjkN6rXSWPdSHrgaZCZitMkqZxh/N4mM5t2VcrkhcaS72SGy32rKjViR5/Olvvvv19aojDp6tixY7jhhhtE4ZuG0m9+8xtZ9p3vfCdyW6txFm4KzfWilzIYQo5KB3BzhPvH9UbCmCxRGXe32qVJrS8UeiR0xfdXKTiScABWBmO/rwUYlBl6TJ7rVThvee+oHA+Ns5mZ80mY9Slosp/AoYY3ZD/pDXq/ExprcgNqzYcksDb93NuQdeNUSabuzQuhllJxY0YiMq6ZJG1EaES3rDkKtcNiDArQkpSlJVHJv0qa4RXBpOhtMKOyv5MZDRUbTM8++yz+/e9/47nnnhOFbyZ3U712586dkowVqQaQGoFh5dJg10uxM6+DF59ks0gKxBLOSClkSVgy7Otdkh53Bh1SFpdAjdDFz1vA14KEOpMXFcn+Z1VR29ZTEdzK+CXBmIbpmV4dul1VT6Hi+XWiw+Nv0nJq5G65L0ycidSU/itLxxJzYRoyLvMqwVu3VaJtq39PtxqgsdL0xiHRpDINTxtwn8RQYXVp1wSrtD7skxkNFRtM5eXlmDNnjjymxEBCQoKE4NRaNj3Y4YyJF2mW+vpDqZQZPOre0WuH0psmE+EAmGyyYPny5TCUtnTlLRjSw9+2Ixy5GzUN7Zg50Wvs9YS5EkwwDYTebJQeW4T5cq5WW8D3soqF+yQ1VV05XJH08rLPYMOq/Uh5Ihlp9cPgMthwYNhq6DtL/31xGRyoKt4nj8f2kBKINxIn5IjgJaGXiRIIaqRt8yk4ypsl/zH9svFRS1XgBEvRMFOkRsI9mRkqpKhgXOlTLSU9StLsUfmw0TgkSofVCMt7G57bA12CEdmf8OpedauSmz14quS6+sfFOH/JV5iOZcOJk/OQPyoDb656DTqzEfYTjVLJpEZjac2mkzhR2YwbL5kg1VW+iaU0oub6SfjuSeLkXFjZZ66iRfSZ2NHdH2zMzfzGeBwbQi3npuq86CMdqvMKqnaW/3PfTixbgU2Z/8bpYQdx+PRWFMwulJwlhdOFh+A022BxZcHVPBr2JBfMcXxBpEq4q7Fdwk5Nrx6EQUVyAzyejppWtH7kLcZIXT5KwonRhMrfNNiYA+hs6oDRz4SKkxVOWnwLMhT4+zxR2QKDQYeSgthUCKuBsWPH4uWXX0ZSUlJ8GEwceD/zmc+IZ4l0dHRI9+Ce3bdfeOGF8G6lRjfs5U1SnSJ9yiwm8SJRHI2JoqyUYfsDVnJ1HK2HpbOlR7xCXRomlhLqGqmFtEvGySBY/9p+tLW0ITk1Galzi1XXO4q/2Y+2ncKOzvyIitOtUg23YHqBGEy8UB+raMJL7x3B1cvHwmQMfOGmdy9t+WjUPbETHftqYGefueFpfidWlBexWCxxE6YPRceM4TVR2j5U682p83HIGbIs0j6HhnR+XjIaTlfjcONqbK1/DFfP/jWSOyc09EadGu0V/h2TvQLvrT+FEYUtOH++OsO4oSDnxYVjRNSVDWcpQyFyAwPIxwrn8dRnGJBx5UTYjjeIllq0YQ4gxy7um/ZdVVJd2xNOVlgNx1NqR48quVmT8vH06gOob+rA/GnDsHjm8AHnNEVS50kfgXXzeCaaE9BS1wSz0QS9Th+T6u8+GUyf/vSnuz3/1Kc+hUjDBPPjx72zA1+++MUvioxBTx5//HF89rOf7baMBh6Nu8EAZ7WNrxyUnB7G4jOvndwluqbopbh31aL1vaMw0hPCGLoKwlgDVfc25if3W7U4IlIOm09JaGpP+UGs+MPtePMr/8B0h9fFoCYph427KqVUmSxfWIKxJZndzhUP9OJ9ammzY9OuKiyZ7U3uDgSlEhiSZP5W87tH5cLYM7yxe/duLFu2THpLzp49G/GsY+bucKDjQK2ou/fUSDIqnsbxOWfl1k3PuRnHGtfBYa7FyzufwI3zb5cJTU3zQbScPg29zoRUz0LUN1XIhXDiqCwU5KrDK9MfvHIDE1H/311w1lnR8MJeZH2CcgNGdRzP2YVIO3dUzMZChurFYGKrlMUlsr964nS6kZ+dhDuvnw67kwaC0Rsm1wHD81LkPNm0uwrlVS247JzRSEtJUJXAsTtC61aO54aX1uDiX30Wb33zMSy8+vyYRFD6dDZTPiDabN68uZty+J49e3DRRRdJhV4g0tLScPDgwa7n8Www+GLdU43m1YdlZstqrYwrJpylScRKmaTJuWj94BicNW0St2fX8ngllure/ZVyoCaOGti6twrrdni389y5RZgxIe+sc4UepfPmFeOVtaXYsrcKk8dmIzMteMiCzVk7DtbCWd0qelSK1MKg0zHzQEJLLWvOCPWaClKQMM7rSaLnIBDsCWdqugyO9KfgyXwfVt01QHsSym1bkWBIQ0HyLIwcVohJo23Yf7QOb607jk9dPgmGONbbkf52101G/X92wlljRdMrB6XfXTSlTQIeTz6P4WSGCu2UYXC3OUTWgLlfPTlyohFvrTuGwtwkXHneSBgMZigO2osWj0RJYRreXnccFTVteOKVfbh48UiMG5GpCoFjT4TW7Xs8lSbSvI+VzmD0zf8+0lOg6uc//znGjBmDc88N3NWbBtKwYfE7iPujbVO55I0QdpJPv2RcwIFIbzFJJRfdv6xciVeDieGkWPaPG4iUgy4pthe+XQdr8P6Wcnm8eGYh5kwJ/HsYW5KBEYVpOF7RjDWbTuCa5eOCTjLo6UtZUiKGRMsHx8TDEu7WEqowfrdVIPeu+TCPyUTCiEzx1oYaZqII4ckjo5Ayrhi5OW60OxuQlZSJ8eaLMT3vethdVnnfefOKcOxUE+oa28VgXTDdfwFHvMD8nIxrJ6P+qd1euYF3jyL1wtFRm7SqdTJDj5Jlej7aNpRL8rc/g+nQcW8VHQ0mfxIRE0ZmYVh2Ml774CiqattkkjNjQi7OmVsMUy9GSX8FjuklYhNnNhL3ON0+j733jHQY85JF3yrQpIO/G06s+FiKkNhSjbFHj6fz+dmP2VoKJgMyLh2nquMZV6Oc3W7Hf/7zH3z9618P+gNkuIFq5DzpGBL42c9+hilTpgQV5ORNobm5uVvYIpxYrd6Bsk9Gw/oKOHbWyHPTjFwYFhWgzdoWfN2T0lnbLD2pmivqoB9gPkFftzsc63fVtosiL7Ve7Ol6OFpbw7bugUC3c7Cmp7zx3Bko/d3uQ8ebsHaLN3l0xvgsTBmdetb29Fz3gqk5OFnZjGOnmrH3UBVGDg+evO4ZlwbdjgR4GmxoWHsECUvPlGkr4W9+Rzj2Q7DtHgj8bSd4jMGNX+ZOXDJKxpJ2OIBWxl175xhlJhxuJDdfj+WzpuJQ4+t4v/whONxtMOmTMSHzMkzKuhpulwMLp+dizeZKbNhZieG5CcjoR6uRSP4++7zuVB0Sl5eg481jUiTgTNLBPCMv8tvd4oAl2RL0eDJcRIHPgWpW9We7PWNSgQ2Q0FzzqTro088cZ+YssV0OKcg2BVy/QQdcvqwIm/fWYOeheuw8WCO/2+ULCpEZZIznmBXM8KDBVPPkDpE/gNPTZQyJ4RIEncWI3DvnBZ10cN3t+2vgaXeiLzDM7WpzROV4klCKVOLK/8vKm8bGRkk8D8SECRPw6KOP4qWXXhLjijuSquSURAjEQw89hPT09K5bcbE6Qiq0uG1rTnQZS+aFhUhYPDyk2RqTUA1FKWKxO/bUIh5xnfQOIIbhKX5j/rHCaXeKu9kfXM7XY8XR8ma832ksTRmTiflTc0M6XzJSzZg+Plser9tVLfkUwdAZdEhY4jWSeH656+MvR5BjAz1jwXTM+Hp/BuOj5V6ZiXNmTcKhxjewt+55MZYI7/fUPYv99atgNANji9NQlJ8Ml9uDD7dV+W1qHm8YR2fAvMj7G7Gvq4CzzCs8GwlcNVa0v1mGtucPQpd4toxDOI5nOOCk1VDsnYg49nWXXzhe2Sq2SWaaGekppuDr0euwYFoeLltaDEuCAfXNNrzw3jEcKGv0e+5IXivzioJNDKwO6GxueJrs8LQ5AIa/ehpLRj10/L2kmqDLTIA+1wLjyHR4OoIbNR6bEwlzhsE0Jx+mufkwzxsG8/wCmBcWyDliXlwI85LhMC8djoRlRUg4twgJ5xXDOCtX+haq6XjqPHH061yxYoXIGrzyyishf8bhcGDSpEm45ZZb8OCDD4bsYaLR1NTUJPlQ4USZcfdmzXJm2/jKAdhKGyT2nrZiHJI69X9CXXdHaT0aX9gnJxZDCwNpmRDqdodz/fVP7xadKbaMoApyONc9UOiebt14Ek2bTogRn5GRgfT5JWFNROzrdh8tb8TL75XC7fFgytgcXLx4REBjyd+62X7h8Zf2SgI4q+iWzAqeAE4aXtwnORnmknRk3jhVvq+hoUH2SVFREUym4IN/rI+ly+qQWbBvOEEheXFxv3IkHE43/vr0Dun/deeNU/Bi6R1dxpIv9DRdM/YfMOiMaGq14V8v7RVD9cJFIzB9fK5qfp/9XTcvLc1vl6J9ZxV0Jj2ybp4O07CUsG03BW3bNpzs1q6HieZU4A/n8fRHf7e743AdGlftF89M3l3zu8aKVe8extHyJiycUYDpY9NDXndbuwOrPyzD8Urv5HLCyEw5fxJ6JNszCfv0wxsDesXzvrhA9icnpjxWcjMaOu/1XmNJ538s6XXd9yzo94RXQombyiW853A50dTegnRLKkwGY1iP56ALybFS7p133umzZAEH7FmzZuHIkSMB38MqOkUqQQ1wNkDZAKnKMeoluZvNOPsKm6ay2znVmTv2nkbSrPhRFHbbXV6FbxXpLwVqeloQwaanoUKNpVfWeI0l5jpctCiwsRQIljafO68YrzIBfE8VJo/pPQE89fzRcoGiYcuSe+Yz8TfH3MNwG0vhxtViE/XnjMu9jXLDlbB6vKJJjCZWvTncVr/GEuFyh8sKgzEN6SkJWDKzUPLOPtxSjtFF6UhJUkdV6MDlBjokF5GVc165gf7rIEmKwokmMZREWV++CEicmIvkhUXSf080oHTeUFO4k5sHCot19ClmCX3ReLJMypVwHPMHyfgRWTwzQ15fssWEay8aJ5WwH28/hYPHGiS/iVV0StUlqxadTTapFPRnSIrAsceDhH7KtnjcHlmHkg911rrdHuj6adPQGOJxIzyeOQZjTI+neuIcIVTo5eXlYeXKlX36HCvsWOZcUBAfxgK1Xur/t0uMJZ4YWTdM6ZexpAxYigp4Gy8G8eNMhKO8ScQAxY0dpBoplvDHvHvvHlx54zU4eqwsZh3bT51uwar3jkhIZ0xxBi5ZNrLfOi3jmABekCbrWrvpZK/nDEUAlTYTLWvLxDN69OhR3HjjjSgtLYVaYW5c/bN7YD/ehMbXDiJ5TqHMhHO/OF/u+T/1dzDmRYsU5ibDxGo5fXedOgUuNxnOyBFQb4dl5WyDQamHwQCTsKmBxHwUVohRo4lFE32F5yE95vVP7kLDM3u8xpJeJxIXOZ+fg4zLJ4ix5DuZCdfxDPf+UDoFWHdWdnmG+Xvj5CS7H6KaHOfnTyvATZdORFqKGU2tdjz9xkExouynWyUBnyrsPMfplVFCXLzncxoeA/HS6DuNmkis2/d4tlySgzvW/lzuY3U8Y38GhQBjlDSYqANFdXFfbrvtNtx3331dz3/84x9LnzsO2tu2bROtKHqnbr/9dqgdZ0M76p/cCWetVVoq0IVtLhpYhZtlap4IWbrq27sqzuJN3VvNshAM377++usSvo0F1XVtePGdIxLKYaXbynNHwzCAQgXu6/MXlIjBVXaqCUc7mx4Hg6KpnDVTuLBtyynZJ2+88UbM9klv8IJd/9weuOraoU81I+3isVJZ2tZulQRShg/6a/zSs3T0pPfcHVWUDo/HKQne/uByvq7Afc5ScZ7uh4834MiJ7s2d41luIPO6yTKmcWxrfPlAyC2bxFA6WIu6f++Q9AKqzDPzmd7y3DvmSLWwP3kHXqTDcTwjgchw6ADHyWbx/vBYk/EjMgc01hXmpuBTV0yW9dDTvGfDCVT/Z6dMDhTjosuQvCe8hqQuwkYqj2fV6Wq8+vpraG5tidnxjAuDiaG4EydO4HOf+9xZr3F5ZeUZOXnmT9xxxx2St3TZZZfJ4L1u3TpMnjwZasZR3SqzJ150GEbL+sQMmPL8z0z7OlgpMxo1N8eMB/0ltVHb0I7n3z4Eu8OF4fkpuPL8MZI3M1Cy0hMxZ7L3nFmz+YQYAcHg4JV63ih53LqhvM/VMNGEHjB6OZzVbaKLk3XD1G6tKgaaQEqJAO6v1GQzhuUkw6hPxOSsqzE1+4YuTxPv+ZzL+bovuVlJmNspAfHexhMBG7LGGwzDUWRXKl6PNaL5ndIu76W/SmQaVCxVr31smxhYVPtnPk3yvOFSlcVQXyihvVgleAeD0hQJoxl6A1q2V8rEhIwLw1hHsUtOmi6ZkIfljXaYXB7Um/VoO3ekTAp4NnGP2PQ6uXeFcS6qV7GROqRymC6++OKAoYG1a9d2e/7b3/5WbvGE7UQjGl/cL4Jc1LTIvH5KWFWtORtj/Fd6GdVZYcyOXS+eUHA122T2z1mYmtqhqImGpg4899ZBdNhccmGmdlKwtiZ9ZeH0AhFUbG61Y/OeSmnHEIzEiTnSjJj6MkkNR7uSQZm0qRbVc25Pw0sHusLd/J2F+7dw6JhXS2f8yDPeAoPejElZV2Jy1jWS08QwHT1LXO6PhTMKceh4A5pabPhoWzmWLxyBwQBV4hk6Y9IzW8s469qRnNldGZr7TDR9NpZL7hNRlLoZUuJFfzDA/nL8vYg+UYYJGWmJyA1T6gHFirM5cfEA9RYD3kk2Im3HKdxSmIqte6u79ZFk6xW2ZAnHREvNRuqQ8jANNnxnVOxL1fDcXjGWKDCZdfO0sLcAocuayYbEuu3s5o5q9S5xgI1XQcRIwoqqZ986CGuHUwbZay8cF/bmrUwApwI42by7Co3NHb0n+K4Y6/WUPrtXltU/s0cqXFhRGGt4MW589aBMGuipyLx2StgbxDqcLpQy965TZNAXepLarTa47SapiuvpWfKFIoRM2ifU2WGO2mCBIoZpl45D9i3T0XGgRqqrav68Se5pJNEDyLAujSVWkqWcMwK5X5iH1KUjBo2xRBJGZUp+pt7hRnGHWxS7w5F6wAKMel5PHG6ZbI79/BxMnpiHpbOHY8veamnuq3gtec/nm3ZVSoWsRu9oBlMUUXrtiFieyw1nvRUt7KLt8iBhXLbMeBlCiwSKblD73mqZ0amZLnXvUer3LhUWFoow6vDhvZfghwOW/D/35iG0Wh0SOrvuovFIjNA5w0G8pCDVmwC++WTISsLDLFn44eX3yD0rZyi/wNdjhZS3v3kYtkN1kv+ScdUkmIvC3/W9rLxJcsmYeMvk7YHMvtmVfkpnsQfbYVA5fLDASkoWoUi7i85SdKV9CdMGUs8fJTeG3iRpOELnd6yTvxOmesU8x3Y4xSM5UJgUT5kPCk6yQpohULPFLDIDI4endzXg7gk9TgNt5jsYx1p/aAZTlFB67fjOqNr31SD75ulIXlQklSSRzPqnTg4rVTjzaN/tbcaqRkSs83hj3OQvsXLzy1/+MvLzI98F3drukJwlephYhk5jKSmCs27OeC/oTACnRoySzNxbS4rc1Czcdc7Nci/bvbUiqv3EehpLbOHSvue0hHgZEuLsPhIc6vSMjh+ZFRZvAVteJCUapekqvXyDBYqeBlOGZnl78tzhgzIHxpeabIvkEeU5PMhyDayCmYnxDHUqk++Mqyd1u57Y7a6A+XBczspMtZMXxbE2EJrBFAU4u27dcNL/jEqk44sjfkHxlRiwbq8MuUol2jCk4+lwSt6CqSB4ew41wCKDF198Ue4jGb5ttznFWOLFMyXJhOtXjJfE4kiTlW7BbCUBfFPgBHDf/nqN1ha8smuN3Pu2MIgFrR+fEIONsKKK3o1IwJAGjUpFPDAcWBKMOH9+iTzeuLtS+s0NBkLpxTgUOHi6FeUJnb/vXdX9Xk/7vtMickxl7sRJud7Jd4+cJOYr8eYPeU0leYaxHGtDQTOYVNDgkzOuaGCZnCvS9qzEY485NWLvnKWbSzLCakSGuyegAiUrKG1RVnamo324LsAWSxI8OiNcLjdq6q0SGqPH4YaLJ4iHKVowAZxGGvVdKGjpD4ZNFA2WE/UVuPM/98t9V389swFtu6qiaqi3bT7VJdRHtXjL1MjNTI+eapKwGY9LXlb4EskZqqE8gdvtwdvrjsWVllogfM+VQL0YBzs8V+ixPZJo6DJ6KNbbV6y7q9D02iFpgUUJmfTLxvsdN3n+MMHbH1zO19XO8QiNtX1BM5iG0IxKZzIgaYa3ZJmeLTViKzujvxQJwyMekhs5mFJ07q/P7MTfntkl9yerWnDTJRNw0yUTkelTBh8NzJ0K4GTTnkqp3gqk9usPejaZl9by5hHU/WcnHFXhbcjrD+uuKhHSJClLRwyotU7fwnHhSd5V4LqWLyiRRPCKmjbsOujtKxnPBD1XOpWhBzvHTzWLt7YtMxGG9ES5BnT08dgyUtC82tvBwjJzGNIuGRdwkskiDlbDcfKjeJp4zxZI86YNk9c1ekczmIbYjCppZkGXaBrDX2qClYKOzhYB5jCENfwZHnyu5gRaGnSsWulZzbJxVyW27z8tnp5YQDG84mGpcLn8J4B3U/vtHJB5L2q/C4sld47nubO6FXX/2YHmd0v7pfgcCu0HatD8pvdCQt0etsyIJNTBolqzv+q4cJCWkiBVTuTDbeWS+B/PRFoZOh6gbIRSWEGJAcKee33xnlLLSjEyqUvVm6FO6YB5U4fhrhtnyO3OG2ZIccKbHx+DaxBLAYQTzWAaYjMqiqYpeRyBwoSxwnWqRVzLhsxEabkRCcND7WW0TLBm1Yraqlm6EsB1OpSebOwyEPyp/WbdOFWe815R+2U4OOdzcyTHgseY8ha1j26TZNVwhplYKSQhik6tm5RzqZwd2X3G3CUakhmpCcjNikwbnxkT8kRvy+5wi6BlvIfm1Ny+JNJwwsbfkCJWyVAa27w4KltDmsS2rj/Z5T3lZIAVhaGe4/QktbdbqeAKm80pxhK9o5yQafTO4D87VYDaZlRdEgP7a0Q2Xy24ylvDUh3H2VK0DI/ExETMmDEDFkt4LpQ2FVezZGcwAdybB7Fm40m/njqeyx4dZJ8kpSR3q3QypJilSi3zhimiZs8GpFRxZssLZ2NwnadQoBgi16ckv4Yy646UWGW44fl60eIRXQbr4RPx0+ZoKCtDB2qUTa8kG+eynQl19xLHeyUkrEG8TFLx+dFxtFKKRkLNJUhd1r8JAeUtUpLNuLBTFJUGU8VpdUUcIj3W9ofBJ3ChUny727tj3N3eVJgK47AUOKtapQFkyiJvJU6sUPKM2k56q6oMxaFp5PCC3dhsk+qhuqZ21DV2oL6xXS4uV54/tlfDIykM6rYTJ07ERx99hJSU8IggKtUs/rZdDdUsVKHef7RepA2YAM7nfd0nNIhzPjvbWzm6qRy2ow2wndiGlMXFUk7es8InFByVLdLyRDRoxmQh/dLA+RzhhBc+6i9FKhznS25mkoRUWDG3ZuMJ0chiK4x4ZzArQ/vjcGe+m69YJb2hHQdq0bGvBklzc7vC2t2MpbXHYN1ySp6nnjtSricDZcKoLPEW8zf9xodluPXKyWEXwQ0X4R5r+0P8/9ribEbV2toqFVtJBjN0MTov+SNlEmzT64dg3V4lP7z+XKTCgZJndGhPFS5psokuya7mDsxzubvk+vketgKpbWxHfWNHl3HU2NIh8v/+yrFZTaZmwyMQVpsTMyfm+XWRK9UshhhuupIA/voHR+XCPWlMdr8q9jhRoHqzZVIumt8uFe9Q6wfH5YKRdtGYPjWddtS0daobu0RvzF9ZdaSgt8fbaT4BOWFqbRGMBTMKcOh4PRqabfhwazkuWjQy4t+pET5YeHJECceNOONJZ5cHQ6YFroZ2OI80wDQ5p7ux9M5RWHdUdlV8hrOIgaH28upWmQRROmTFEm9fSI2z0UJyQ3RGxd5f7B7ubrNLHkks8M0zGub0iLBmfZoJ6/dVy3K2hHj0hd3443+34YlX9skMiBfpIyca0dDsNZZo+BTkJmPquBycO7dI2oSwYzeJRhntzp07kZ2dje3btw94Xc2tNry2thSzJuVJ9YpvNQurW1jlooZqFuoMdSWAbzo5oH3CXm6ZN02Vcmg2w2U3+/r/7UbT6sNwt/ceLnY2tKPh2T2i3UXdroxrugv2RZpwi1X2BicRipG0+1CtVE9qxA88XpzEcUI3PC+lu05eZ/K380hT17nE/FYWMCjGEtsPhbviM8FsxKVLvUbS3iN1XQnpamNnGMfa/qJ5mIYonIGzYk6E/bZVwNKZmxJNGDo7VtGEa88bg5LCNLjbHMhMNiG5ohnr91RK+IGDixhGZgNyMizIykhEdroF2bzPsEgeQKALFQ0M4ttskt4bCjHqw6R9xdmf3W4fcBIuQzsvvXcENQ3tordzydJRYiQp200DL5wNMgcC9zcFFf/zyj7xsDAkRa2g/u4Trs8yJU/aObR8cExE/Np3V6PjSB1Szxslr/keY0Oni83VYhNjiecNje3M6yZDH8UQFY/Nsc5O8+FobREqRcNSMW1cDnYfrsU764/h1iunRFRrTCN8KMbI2JLMs/IoLdPypOCFGnQeu7chMZPA7aeapbI5/dLx8luI1DnF8Zbefp5ThbnJSEmKvDBuLMbagaAZTEMYxs2ZR8LqDHtFM8yF4e+v1ZuRcN0F42DbWoGalw6IFgmT4bNnF8pyu9OFq5ePlbJqzsj6OoNXymgX+BgevMA99cYBFOalSIPTaHgFeoMDwOqPysRY4v9JY4SzPiV8azCYYhqG8wfDT/SEbd1XLW784oIpAzbo2Fw1fcU4WKbko/ntI+Jtan7jsHR0p0q3zmKSXoxKd3tnnRUw6CWBPPOGqVFvzqqE49jTj8Z8NFk2t0iq83j+0tualZaEDrtTQj40rtXgidToDo8LveOBDGyd0SAaZUyVUMZCapixUTENp0i19FFYPLMQxyuacbreijc/OoZrLxqnivFRTWgG0xBGqjMm5qJj72lpHxFtg8ms16Ft0ylYO9WYCQcK5XnK/OFIzh1Ygh8vHL6GBxOBeYFhixGWgc+f5vVCxZL1OytkIOWM84rzx4iBqKbwbSAWzSzEgbJ6NLbYsHVvFRZMD0+ogI1xs2+bibYtFWhdd0I8SPQcUXuG3tBuF5NPTJc+jazAizbRqI4LBJO9VywZibzsJNHnYmNVZVLAkDO9q2rxSGp4Ka9uQYfNKTmWRfmpAZtXKyjts0jygshqiRGDQY/LzhmF/7yyH8crm+W8UtoiaXjRflFDnOROiYGOQ3US4ogWh4/VQ6fXoz2AFhSXhzNxVzE8RhdldPXn+mjbKRzsvOjFCn7/hp3e/AR6vIbnqb9/nm8C+DlzvQP5xl1VkoMVLnjsUxYUIedzsyVvI1h3e8SgHJ3eHM7GyfgRka2OCwRzYHhR2xhnWmNDFSXfbWxJxlnhuF7bZ0VJf429I5XfNIsKahsGR//CcKEZTEMcU34KTEVpol2jJBZGmr1HarGeA7rVHpOWMZLHNMmbC7D6w7IB6Y9MmDABmzZtwqRJk/r82eq6NnF9kzmT8zFlbGQaw0aSiaOyUJSfIpWMigL4QPZJT4zpiTAXpAa9mOhjIM1xtDMcl81wXBSq4/zBiy49S2oTOdUIFI47Iyeg1vZZZMaEXIwani7n9+sfHlVNZ4QJYRxX+otmMGl0VV1QNI2l2ZFk16EaUZfVtdhgYsJ2jFrGnDO3GGOKM2RQYLI1w0r9gSJq/AH3VUyt1WqX7+VgNHJ4GpbNibzLPXIK4MwFg4QVmSPW333iS1u7A4ePN2DP4VpvzlKQi0mkWqwE46BPdVysULPIqUZ3Tp1uhbXDKSHT4oJUVbfP4m/64iUjYUk0iofp421e7adYE45xZaBoBpMGEsZlQ5+WAE+7U9S/IwXDB++sP44Mhxvn13RIQ1bmocSiZQxn35ctGyWd5dttTqx697DkF/SVEydO4J577pFO2qFCI+nlNaVotTokYXjlOaPj2hvgTQD35jq8t+kEjh07ji996Ush7xMmvdc3tWM3jemPykRK4m/P7MQra0uxeU+liLwGu5jwYhNNeJ50heOiWB0XSOQ04Gta4rdqoPGvhOMMfqoZ1dQ+i7D6+OJO+QoWdlCdPNb0Z6wNN5rBpCHx8eRZ3uRnJn9Homxzy94qqabKcbixosUJo8ON9r3VkqcSq5YxTAhnFR4b2jIJnBdoVhn1hfr6evz73/9GXV1dSO/nvqVsQFVtm1zUrrpgrFTExTuLZhRKTs05c4pgtbbjX//6F06frvGbR0ODkWFQljDTy/aXp3fi8VV78fb649hbWtfl7aMhVlKQBgd1awIZ1rML4Xa6o14dxxALZS14ixXchmhojWkMDP7mFYPJXzhOje2zyJiSDEzr7DvKKt6OGHhyBzLWRoL4H6k1woJl+jCpSGIpN1WXE0oywrZuJqV+vP0U8u0unN/ihN7lgWl4muiK6EyGmLaModbINcvHidQAReXoAaM7OlJVTzQS2IaAq7/ivDHITBtYk2G1QOPvmgvHyf/3yjve5rfPv30IDmOBVCJW1rbi2KlmMZRoLDIU6ovBoENBTrIkvVPyoSAvuVvbD9PCYrnvWSXH5qPuKFeoKYUCFPCMJTT4A2mNzZ06TJMWUAkVNa0SYqbHjxOAeGifpXDe3GIZF9mC6p0Nx8UbPpSlBjSDKQaoUWCOP87EyXlo31klXqZwGEycWbFknlVgw20unNPsgM4DmEdmIOOqSV3NNmPdMiY3KwmXnzdGwnL0cGSkJYStRL6nZ4KVeYSVesEGz3iDniT2lqNxbHd4PT68Z8UWTaP87CQxphSYH0GPFI0j3jM0yrLmQPCikTRvOFIWFUvOEsNwVqsDL609KmFNtmuJBgzfnqhoiXk4LpDWGCsXKQb79BsHcemyUTFLSNc4u3fc6OKMXqUeYj0W9oRG92XLRuN/r++XKr/RRfWYPMbbKHgoor4rtw8/+tGPxJr1vbEBXzCeffZZeQ87G0+bNg2vv/461ILSZNajM0roR21lv4rEgO1I/YC7x9NYonFAY2lkxxljiflSmddQkfnskSCWmkOsCrmgU27g4+0Voi8UTpg8yf5rZPr4XKlEGUwwB4teDn+wkmtEYZp4Pi5ePBKfvXoq7rpxhjRInjtlGArYsT0ECQlDglG629t1LpEdqG5sR9mpJsmxOF7hVdyONKUnGuH2eMQQYQm2GuBFrb3dCngc4qnbeaAGNQ1WvPZ+qerGmKEGx0FF3Xt8gHCcP9SkvzYsJ1lC7uS9jSek59xQRdUGE5kyZQoqKyu7buxWHIh169bhlltuwec//3npN3P11VfLbc+ePYg1SpPZvz6zE397Zpfc87laSjaVvl70/pBAZdyhDhIsMef/N7bdiUWdxlLilDxvY9QYupiDMWNinpT3EyYfs5ddb+Tl5eHrX/868vMDC7y1dzjw0nuH4XC6pQXB+QuKB51b27diKzU9Cxes/LTcK6/xf2eTT/b8y0xPHND/73K5umbsiuG5+qNjsp+HSjgu0EWW+/WSZaMkabeuqUOS8IcysfbmV9a2SXGHyajHiOHx61FmWL0wN1m6M1CKJRb5cRxrv/GNbwQdayONOq9cPhiNRgwbNqzrlpMTWKvm97//PS655BJ861vfkvLDBx98ELNnz8af/vQnxBLfJrNqF5hTvEzs5eW2O/tlLHEWwoq4SW1OzG9xsg0SkmYVIP3ScVETYOsvLO8/IzdQKqrgwSgsLMQDDzyA4cOH+32dnkQmkze12pGekoArzh3jt0om3vGt2ErPzMPKG74k912vRSifhiJ7DMkxR4RJ45HsM9Xe4eyqFoqVWGUo0FhiOI42KZup7iuNXZLsUPfm9yUcp3YP8iXLRsNs0otEAot4ogmP35gxY/HAgz/DsGEFMTueqs9hOnz4sFyUGGJbtGgRHnroIZSUeEMnPVm/fr3M9n1ZsWIFVq1aFfQ7bDab3BSam72DohJLHij84QYKV3A58w/4XQPFarUOeB2eXBN06QnwNNnQuPUkzNNyQ143QxUfbqvCwbJGTG9zYqrVe1KbZudDNz8PbW1tEd32cK37nNl5aG7tQE1DB154+xCuOn8EEgOUb58+fVq6aC9cuBCpqd31VXjx/nB7NcqrW2WGedGiQricHQj1UKtpn/SGwWiWyixOAjra21B+7ACKRk5EoiVZltsdTrja7RHZ7vPmDsOq946JDtTWPacwcVRGRPbJgbJGaQSdnZ4Ak8HZ599sNI9nVqoesyfmYOt+b4PeNAskNy8c6w4n4V43PWzmhETxbvsmwvMcnDdtGOy2jrAY1aFsN7/n4DGvsVqSbwn5fInk/h7I+o06YPGMfKzd4i3iyc0wITczMWrHc/32MpQe2osx46dg0axRYT2eJCWl9zZcqjZ5FyxYgMcffxyrV6/GX/7yF5SVlWHZsmVoafEfKqmqqjrLXcfnXB4MGmHp6eldt+Li8CWQ0uBiG4VgAnMUNKtvsqmiDJgnqGma14vn2F0b8snIbecPicbS3NYzxpJ5YQESFhTEVQiKxs2KRUVIthjFM/T2+vKzqroUjh49imuvvRalpaVnvba3tFEusuSC+YXI6ucFKx5wuxwygC2cXoDm+lP4yy/ukns+53K+HilyMhIxb4rXsF+3sxqNLQM3zPxRWu6dSI2mMn4cMGtSNgpzk+B0efDOxgpVhf8VOC4YwtRZWsYqvRGbd1f59eZzud4QvQbNtY0daLU6YTToUJyfjMHAuJI0jBqeKhOH9zZVwBlhSQ8eL+V4njp5TMYV3sfieKrew3TppZd2PZ4+fboYUCNGjMAzzzwjeUrh4r777uvmmaKHiUYTLc5QrM7eoEuYsxx/RhOX03vx2ocnZUBjU8aSAt7SJLG0P4bGQLfZPScRNZuqxMtkrnEgYXRW0HW73G688UEZSo83YWGLA6M7vD+itAvHSCgumtsernXzrddeNB5Pv3EAlbXtWL+rVpqd9jwe9HySpKSkbuunsOH6XdXyeNmc4ZgyblhUtjvW62bFlsk5Hr/4P+C6i8ZjJp8bDTAZkyO63YtnJ6OitkNKoN/fWoWbL5vY79Cnv31i7XCgosY7e546Ph8pKYlxcTyvOH8cnnh5L+qbbdi8rx4XdYoRhmPd4QqbcUJJCQlOunqTQuAYyZ6FTS12ST5uarF571ttsNnd+PSVk3v15hsSw9eoOdg+2X6wsat/ZUZGmqrOk4Gs/5KlY/Dvl/fKZHLrgQYsXzgibOvueV2hYRbN4xnXBlNPMjIyMH78eBw5csTv68xxqq72XqQU+JzLg5GQkCC3SAvM0SruCZfXNLRL6TUTY1n1wxthV2vK6JcMS5P7jNSEXg2ocIQQ2RneMi1f5AXY3NTXYPI3gL32/lGUnWjA0mYHim1uMGmJGkuWKf5F9eKF3MwkXH7uGLz47mHJA+H+X9hZLRIM5j29+n6p/Ngnjc6WSrChAi94Nps374uVb9HSApJk56WjZCCvrrNi/Y4KLJ0dvnYzDPfxeFL+IJ60s7z5TKNFE2v3oVoUD0uT/n9qKYLpGTajrpTN5kRD8xlDiMYRjSQKmjJXLRA5GRbx1vfWLiYpCrlEvtVx41RYIDAQLIlGXLJ0JJ5/+zB2HqzBqKJ0MQrDgcPpEr02/t4aWzpE0kANxzMuDSbGgBn6uPXWW/2+zhynd999F/fee2/XsrfffluWq1FgThkgmAx4900zxHBiUilvp6pbRfOF2hdKl+vUZHOX96l4WKqILvqbrdGjFcpsLRgUBaTBxPYlzjorkOB/0HtlTSlOlDfi3CYHCuxuwKBDxhUTkThucGh1jByeLjMoClqu21GB9NQEMYICwf2/6t0jcowLcpNx0eIRcRWOjGf4+7ho8Ui8urYUm3ZXYWRhulQlhoNDndVxA9VeikXVFiUdOBOnRhZV5qmJFUujj2MVjSXfCaQSNlM0u9g6KFjInL9DFlF4781yzwkNVfuDefOj1S6GYzm9X5R5oGTJYGNEYbo0MN+2/zTe+vgYbrtyCpIs/QuPUUH8aHmTNCemsaSEjukwSLIYVXE848Jg+uY3v4krrrhCwnAVFRX44Q9/KPFuSgeQ2267TaqTmINEvvrVr+Lcc8/Fr3/9a6xcuRJPPfUUtmzZgr///e+qE5jjwaZRo1RO8KLK2Stv9EjQ6KEi8onKFjGgWJ7a0maXqhfeCDulTxiVhdmT80U0MJAx1q/tzUhEwtgs0WSil8mweNhZMwG2tag81YwLmhzIdbihM+mRcfVkJHRKEwwWqJvU2NyBLXurZXDghZmhU2IymaQogfc8nvS20cPEgZs6Q/FcGdNffPdJtKHWzZSx2fIbeeOjMtx65eRuiuH9wdrukFDfQJrtehw2JFsSgQ4rPC4nk76gM0Uvp406OuVVLVLhRO/nLZdNitm52Ztm153XT0d+VhISEgw+RlEC0lLMYhQlslFtgEkIjbFA3nzqgNGLH4rmV7iq42gsUUx0MLJ0ThGOV7agrrEdb607Jm2eQp0UsPk4hXyPHG+U3xYLhhR4nMeVZErfPS5WjqfBYJTKW977tv8JUwpc/BtM5eXlYhyxd0xubi6WLl2KDRs2yGOlGZ/vwVm8eDGefPJJfP/738f3vvc9jBs3Tirkpk6dCjVAj49SeWcwmIIeaP6oh+enym3RzEIZCDjYeT1QLThdbxWdFeY5cbbG2WPP2VpXTkk/f7D0MtFg6th3GklzcmCweD1a1OKgKnZNZQsubLIj0+GRVhWZ102BOY61RnqTG2BIgK5izn5vuWyizNKpE8ZKTuYwUXuKuUu8EHHwYDhkKMJ9cvDgwYjnYASCKuqsTOQM/931J3DZOaMG5OU7fKJBBm56PnjB7isepwOezW/As/1dwEZvbRJ0sy4E5l8GnTE654g0mz5nNP7zyj7U1Lfj/c0n/eaeRIMOH82unohml8uNT14xOeztYmZNypN+lmx9FElpD284rj5o77jBgNGglwbmT762X8ZGTirTUgJHOfg6x096kipquldMsycjDSTur9weubtdx9NswP2/fS0sDoFBaTDRQxSMtWvXnrXshhtukJua6Y+KK088hod4UzRh2KNoREEa3vz4mN/PcMCgwcQTmu5NxW3tex/shDOXpMOYkyT95XTH2oApyfJDqK5rg6vVjosa7UhzeqBPMiHz+ikw5cfmAhkN+AOmts0zqw9KjgwFAVcuG90VBvUm7Kfg2KkmLJ5ZiPzswVEVE49wRs+BnP0BKTTJHIuBtHNQQuL98S7RsyTG0oZXziy0WeHZ8LL38bxLouZpomeUopYvvuPNPWFYv78es/5ytLxRvjeSYRZ/3nwaafy/+dvl+RFJY7GusUNysAx6Xdhye9RKblYSLlxYglHFGaK9t8OPlMPew3XYdbhGuh34wpQFGkljSzKDhoh7i85EE1UbTBrBE+8osMhwQVDJAptTSj/Lav23jmDoSDGgvEZUYpcxRSPLsrAYBqNeFMDtVgdg0CPVoMdFLh2cNJZSzci6YaqohA92WO119fJxeOODo7h06ShpyfHaWx/jz7/4Mr74nT9i5cVLxPOUMMAQULyzd+9ekVqgHAjbE8UCtlthGIp5ZxRSZb86ntN9hUnG5dUD6B2nN3g9S37wbH8HugUrEU0YIuLFh17pt9YdlxSAjCjkM/ECR+0efu+V548Rj4+vV1whXGGWnt78ZItezodV7x0RY5EJ4lT2jwSKd4mTW0XMdTAzfmQWNgWIcig5aTSW6DSisUwDidcuGvB9OZ4bN26M+bgytEf2QaSwHGi2lmIx4YKFJahv6hC3KcMUrD7gPZujUrafNyaZ9+SGFeNRMDoT7ZtPoemNQ926xKddMRENrx5AxopxMKTHT9VQWKqOzhktsykOEB0ddjQ1nJZ7PtcNMAw6GHA4HJJzyPtYt3M4VtGMitOtks9044oJEprqC4ePe8Nx7KfFPJq+4GmhZ8rjDcP5g8tt7UBSeBLTQ2XxrEKcqm6RsMhrHxzFTZdOjOhsnUYn+ygqeWDMeVkwrUB+K+HMu+zNm0+17aWzh0uPyzWbTiIrwyIX8HDDc2awh+N84W+KnqWAOWk3zBCP74jh6TIJj+dxRTOY4pzeJAv4OhOUlSRl3zg7qxMk9txlSJ255+cKM5PQtvkUrOtPnvmczYW2zucZl0+EIWno5elQN2tHL9ogGuoYyBlGfeLlfWI0bdpdGZIsxECr4zytDfBsfA2eI9ug/9xDkrPk12ji8oToN/Bl/s7Kc8fgiVe8Egwfbi2XvK9IwH6Mr649KkYTq9vYfJmFKiQWYRZ+JyvYDpbVS8uiT66c1C/PYyBoDDIkx3NvdPHgq47rrY+kv9dYIDQxSGVxPKEZTHFOKJIFgXJyLIkmuTF80ROe5HqdDu0BmvCyOW/KovApog+mASLa2iAagaFXaPnCErzxYRnW76xASWEaCv2c74EqeZg8HmqneY+1BZ7Nr8OzYw2gKJtXH4du1vLuOUydcDmr5dBZ9RNNJJ9pySgJUdFbyglVOD0inJBxvR9sKZcKKPb7u+K8MZLc258imHDBcY9GGxOQaSy+tOYIbr50Ytgq2RTvEnNLB1qdOViiHAmDyNs+NI7oICcSSXHM13G12cWj5A8ud9tcMCQNPcNgKA0QgwHqZlHnhV4FGk63XjE5pAvk4eONXcmpaUHCcR5KBWxdDc+2dwBHZ0/KwrHQL7kGuqLxwLBRvFRLzlJXldzMC6Cbc3FUpQV6whDVnMn5kovHsvC87KQ+hx39wSpaym8owo0TRmaKPlagfd6fIpiBQE8XJT/+++o+ya1Z/VGZGHPh0EsbauG4UKMc0Sz9jySawTRIiMRsTZ9olJwlf0YTl+sTBsmvYAADRE5+Me7+zl/lfjAOEP1hzJgxeP3110XWQy3Qy8SwHEPOLC1fsYRGTIjhuAAXP4+9Q4wgz5Y3z4Tc8kaIoYSRU7suwCIdwGo4JnjzfWYLcGw33P/7GfTn3QzdyNjJniydM1zkSqj5Rg2xmy6ZMCCdIoakKLtBLTJ6qM+dVyQJ3moTb6WHjUbTs28elFJ3eh8Xzxzep3X01Bvi/8xwH//vMSWDuzouHFGOeBxXNINpkBHO2ZrH7UHSnEK0rTuTw6TA5XxdNwQNg54DROKkOTHVBlEbqamp0iQ7VjpM/mB4hPlMvEBS1JLVYsFK6ikSS0OC9Hyfx2GHZ9caeDa9DrR3FktkF0K/+Bpg7Cy/xgE9Sd4JjRFJRhPcx/cB9ZVwv/EP6G/9EXQpsbnAevOZvPpMNJqYEH3uvP6F2g8crcPb64+LOCSrb9lWqDBPPedAT7htlBegd23DzkrkZCaFFnoNIEKqeJfYxmogyc3xiDEKpf9qGFeG9siuERS9yYCUBcVIXlwsHiXCez7ncr4+VFEGiCuW5KBizzNyz+dD3Vgiiir/qVOnoCaYp8NjRHhhp1EUTKySFOYmd5U/8+Lo3rkG7kfvg+f9Z7zGUkYedJfeAf2tD0A3bnavnhRlQqM79yYgpwhob4F79T/giXJYyheG4dhYmjA8d/SkNxQZKtRmo3TD6x+WibHEyrNPXT5Z1caSwtRxOdLigzA0V1MfoKKxhwip+69fg/tvX5N7z+bVslzR6xpK4bieE8n2distyoj0kVTDuKKN7hpB0Rn1SJ5fhLx7FiD3nvlynzyvSJYPdTggnDhxHL/+1S9RW1szpKUEfDl9+jR+85vfnNUIWw1QNZ+6MJwF8wLJ5GR/YRZfsUqP2wX33o/gfuz/4Hn3P0BbI5CaBd1Fn4H+0w9CP2khdH1UjmaYTn/5XYDRDJzYLxfhWEJtHCphk9UflwU1Jn3h+55582BX1SjlAq67aHy/+4rFgnPmFkuSNvXq2O7J2uEILEK66TVvAr8Sgu0UIW38+E3pvkB7mWKMQxl3hIx/NYwr2lVPo1foSWprt8IGJ3QGPfRDQIxNQ70MpIEtQ1BsEWI06kUXiP0BfcMsFo8Tzc1WyXciY53H4P7XD+B58zGguRZITofugk9C/9mfQT9tGXQDqHDTZRVAt/yT3u9ftwqeU4cRS86ZUyTGZIfNhdfeL4Wrlwsf2wAxlFdZ0yYhmKsvGIsls4f3Wesq1nB7GZakYG9zm13kBug164sI6eGD5V1ezKTE+DEWNfqGZjBphEy0q1k0NHzxNWoYHuPz/sA2DOd35ulQfbr6dFO3MMuhpx6X1wpzLEje9grQUA0kpkB3zg2iq6RnhVuYesDpJi+BbtJCJgzC/frf4VFyomIAwyjUZ2I1G0Ut122v8Guk0iu3cVcFnn/7ENptTlEL/+Tlk6XqLl5hQ1/2fzSb9CLiy9ZHPb2PzFkKJEJ6WO89n8a27Ib7zUfh3vY2PCcPSgVltCcFGpFjaGWmaWhoxCXhbmDL3JWyU01SIfX6O/twS9UbMMEprx3We0Ucx6MC+nNugOf0CehmXwgdq9vCjOQ8Lf8UPJVlQGM13G89Bv2VX4pZVRm9LGxO++raUukmP2NCLpI7+yXS68KeiRS63HWotms/XrCgZFDk7lEjit7HVe8ewe5DtcjNTJIKP09bEzw710A371K/IqTN+hRUm/Ll8ZiazfCc8O6bLnMrLQfILYYurxi63BIgrxhIzfZ7jAMllGuoA81g0tAYAFlZWbjtttuQnT04lGwHCgf8osICfO7TtyIrI12eD3TAD97A1gPMuABoqgEcHQBL/e3e+243R4/ljg5coEtEpWUl2BP0w+RFuMC9Ha0pBWg0FQEdDow5/jZwyc+gHz0DkYSGmH7lF+B+6mdA6Q54drznFbWMEawUWzSjQHqt9WyoSgNi8azh4oGaPSlfDKbBBJvlKu1T1m46gcyjH6Po8JsiRKrLGyH6WZ6Nr3b7zBHzaLkfnmtB6vib4Dl9Ep6aE0DNSaC5zhvKba6Fp3T7GSOKhpcYUSXe+4LRYliFc1Iw2MhSwVirGUwaGgOgpKQEDz/8sKpK6GPtBSre/i7+Pt0EvPE7eAIM+HxvVy81ubfC03nvDX10Lve4oTvvliANbN+Vmb/7pT+cKfEPEUvOcKyYlYW1e5sx6vyr4Cn4FAwddtyemICqUzVIWWuOWq83Xf4I6JbdAM/a/8HzwTPwDB8rF+hYMWeKt0Fvz4aqyvPrLhyP5EHaFmluiRE1+5twsD0dr1Xn4GZPItILSoDEZOgWXA7o9N1ESI9kzwU6gPGjcqAbmw/d2Nld6/J0tInh5KHxdPqE976uwvvZ8oPwlB+U9+mu/BI8+zd0N8a6JgXs6XLJkPc0lahgrNUMJo2Q0eLqZ9Pe3o5jx45h6tSpsFii3xdMLfh6gdodThyta8HobCcsHPA9bqBkEtysMFMMIqV1SG/kDIfO2hS8gW17C5A/EmhtBMyJctPx3uR97L1Zzn4tIQkjcgpwS1E+thyoxZsfHzsjujchFwU3fQ8wh95RfaBIC5WT+8XL5H71b9B/6gcRCQOGgqGXhqoLB2G/RE9DtWhrefavx4VuoCH9apw25uGVoltx85UzkKC0OvERIW11GVH5wr6uSsOe6BKTgeKJ0BVP7D5ZqK/0eqHojaIHasRkeN581P92bX/H+31DnHYVjLWawaTRK1pcPTAHDx4UMbWtW7di9uwzM8uhZKTKOSGzbq8XaH91I+b/9mVs+tqVmF2U4w0xzb/Ma9h08wLpvM1nlSa0cp8EXWLSmWXJ6UByRvAGtskZMFz7tX5tu8PuwNYDNdi4q6prGY2mDburZPPmTclHtNQimNOiv/izcD/xI8ln8rz7X+guvR2xYCj1S/TQeNn4KjwHNjKjXZYZR0zGlTNG43/bbKhrc2D1R8dw5fne9im+IqRHylvO0uvqDfG25pV4w3FTOrfB2hx8UkBPFX8LQ5iDER5rQ0EzmGJAPFwEI5VsqxEaNpcTiUkWWJ12ON0uuDweJMSgSWsgPPQanToMz8FN8NSegv6Szwcf8O0d0F9zr7fRrGIc0duj6/23IHlQsy48E57wQc7FATSw1RsM2H6gxu9rXL5geiGiic6S4s1neuYX4ulwl0yCfsoSRJuh0C/RU1PuNZQObTmToj1qOvQLLoeucAzSAFyR3opnVx+UBPie7VNYNaz0ywumGh8SnZOFgJMCcyLc7z0pnibdEDecYol6RuAhQLx5aoIn22px9UjhcLvw5sl92FRTBpPeCIfbifl5o3Bp8RSY9LG7UEmZdfVxeA5uhOfgZqDVe7GAJQVISgs+4DP/o58DvZxj9FB1hid8DXfdAA13NXpSdMPHQbfoKq8207v/gadgDHRZXoXyaDFYGqr6m5x6qo/DzTGtdPuZhWNnew2l/O55Y4W5Kbhw0QgJ10r7lAxLl3Fk7XCKBIF8fKBilbwWBJoUzFwOHN8Hz4534dn3MXQLr5Tw7UA0wDT6h7bHo0RcemqCCLVpcfXIeZY+rirF2OR0XFZ0KZztrTBaUnCovhIfVh7BkmFjou5p8tRVwHNgk3iTGCrqwmzxtgOZMF9CGZHyAvltYEsjjBeZAf521OpJ0c1fCc/JA8DJA3C/+hfoP/H9qI4T0WqoGs3JKfW03B+/AJTt7nyXDrrxcyWRW5dbFHBdU8bmoLahXdrGrP74GDLSEpFkBqrrOqRnXHpqAtJSBjZx7G1SgIYqIH8UUF3mLQrY/YG3cfOoaRgq46I50buP6XHn81h43DWDKQrEraeGcfNgYZYoVRCpGeY0mM3msOnmGHQ6LM4phnHLW9Dt+BVMnQPn+FnLMXrOxfJ6NELDnqZab7iNeR21XhVjwWiGbvQM6CbOB0ZO634R7xzwdS//D2aDXhKWZTYcpklBtwa2HCzDMGCq1ZPCViv6S+/w5jPVlkvvOkUVfDA1VI3a5JRiozTcm2r5o4Vu4gIxSnXZoYVcl80pQm1ju7SCsbY7kJ2eihHDTZg4OhdNIbaRGdCkILcY+k98D5696+D56HkxoNwv/g4YPQP6c2+CLtOrAzWYPe5P71kDvcmI3+9Zg5tyE2Licdd5zpIz1WhubkZ6ejqampqQlsZI9sCQpp1//VrAcIX+rt+Gxb3KiwkZaNmlp6pMmozqL/gk3H//ZuDtvvPXgLUZuvQc1Wx7vK/bSSN0y5vQbfQxrjvxLLgCmHsxjBxIB4AoZHOgYbUaE6w7Q8Mi0Hdws4TcUHn0zAf43pFTxZOkGzPTW2XW27p9B/wwTgYicSwpxrhpV2XEPSn92XZP2W7vhZGH4YovQjduTtjWHSpeI1WPpKSkiKw7nNvtd3LaiXiSxsz0GlD9MDBsdifY7GDb/upu2lThPld629+U3+D/JwZhp+dWN+dirwEY5Lfpu/54GQ9tLqcYS6+d3HPWaytLpmJF0eSoepo0D1M0UPRlAr3W3iLdynVp2TFLKBe7+dgeuNkEtFMbBGNm+RVqI1yO43vhfu2vXrcxByMm82oMCIPRBPcO/2FQ3Y53oZ9/KVz/ul9mycwd0tHDl5gKJKUAllTvss577y21mzHuPzS8HJh9EdzP/cqrEeP9NqB4gncmPna2JCPHygsUaTw6D0aOTcHcacNgtdmRlGBGTXurLI81DLno5l4Cz5bVcL/1OPTUa6JydJSJm7ZIwdIIWK258Ip+T071Oh227j9bm0rxTtIbF64G3MH2t46/2XNvgmfqMrjXPiXjsMgh7F0n7XvkNxsjpfhwQ4/6msrO61EP1lQcxGXFnWWGUULVo9lDDz2EF154AQcOHBDdhcWLF+MXv/gFJkyYEPAzjz/+OD772c92W5aQkICOjg7EjN4qIBKS4P7Ht4Hs4dBNXSazSJ3JHJWqKunJxdDL5tVA3SnvQr1BfnTILoBu5NSzhNrEQJp3CdxrngT4+S2r4dn7MXRLrvFufxxVAQ4Unpu33347/ve//2HSpEn9Xg8N1v17PsCkEVOCG9fWFrFllDCZv0v6Wcuo5WNJhf7iT8NzYr8fcbxXJAdJv+RauDe/7vUkjZ8HXUpGTPdJNPCdwaaYEpBmSkSzowOtDltMZrD+4O/KU34IqDoK92t/h/7Gb2sJvz0Q7+jhrdCNmh6xNAI26aUX0h9cztBlNGE4UU85jaM7vYZTUw08bzwibVz053/irAT2eKTd6YCVulUAGo6dwnsP/hkX/OCLyBw5XJa3uxxIjWJYTtW/uvfffx/33HMP5s2bB6fTie9973u4+OKLsW/fPiQnJwf8HMNo1GxQiLm1HawCgrP76uNAe1uX8qtnzX+9s4SpywDK8fey/UqMl5Y4T6IkownnF04IGuP12NslcdCz9e0z1U4s8552rrdvVqpPmay/uLopAfqLPiPVJe73n5aESs87/5ZZnP68m6ArmYyhAA3xnTt3iqhaf6Bn0X14Kxo/fBYTGM6auDCoce1OTsM705Ziefow6BXRxk59I4+1U+eoo9VrWPGenkN7OzurAsNGwfPyw4Fn33f9FoaxsxDrfRKrGSyNJN5iOYP1B40j/co74f7PA0BlKTzrXoJu2XWx3ixV4GF+19a34TmwwTt+UYIh6OTUMrgqKnltGDMT+hFT4Nn6lncyVHEE7v8+CN20c7yTWD8GYrxI21iMJrme8brmstlRd/iY3BMutxiiWzClaoNp9erVZ3mP8vLyRLjqnHPOCXoSDRsW3TLcgZZF62//BTz71sGz5yNv36Gda+UmfYbotaEB5Scs4i/Gy5PrtRPe5z1nyJ7WRnFZe3at8c62SHK6d1umn+cVDQwxzCI/ViYd8se6cw08618Wz4f7uV93JiPeCF2meo6DmvC4XZJQ7d74GnQNVaAvp4OevdpyJFLx2U8OBmYtx8H6SrzQWou9BgO+MGkZkoN4IkUriXlKNKJoCCjtRvwxRJP4fWewPYnFDDYQuvRcmaCwYs6z+XV4GC6l93cIIuf1sb1wb3tLyu27SM8D2pq9iun+cpgGWK2p1opKwmsIJ7WeyYvg+fA5GVs8u9+H59Bm6BZfDd2M86BjuDLOpG1aHDacVzABr/vJYaJTgJGUaBoxqjaYesIkbKUJXzB4cR8xYoTEgakI+rOf/QxTpgSeKdpsNrn5Jn0r6wmXJU7jImHWRTDwpO6wimHistths9nh6WCibAIw9XxgyrnQVxyG4cAGGI7tgo59iNY8KV4c18jpcE1cCPfw8d4wGZiza+maIfcMKSgzZP4fusZqGHetgeHQJug4aNDxlZEP5/Tz4Ro3zzuION38p/1uv9VqDR5bH78IKJkO07bVMOz9CLqjO+Eq2w3XlGVwzLnEO7sLgrL+SBDJdSuhXn6HkvAYFJdTjoFxxzvQt9RJdM1qMOL9/GJkzVmJGWnDoJtX7A2r+eQZ0VjSz7sMrvoqJOgNONhUjZ9vX43bxyxAdkJgb6tgTpGbDJS9zL5D+h/CvU9ieCwtSZauGWxPlBlsuP6HAW974USYJi2Bcf/HcL3xCDqu+45X/yqOfz99WrfTDsPhLTDuXgt9p7yFR6eDa9QMuKadB3f+KBlnk+Zd5vf3w56DVrsDHluIbXl6YDCag1ZU2h1OuNrtsd3fOjNwziegH7cApnXPQ193Sq4fHIuNl98F95bVfscV2S9hqP+yhvFccXnc+M+xrfjMxEUyTj5delKWJxqNWFk8FZcUTYajwwaHJzzpNqEkqseNwcQL9b333oslS5ZIL5lAML/p0UcfxfTp08XA+tWvfiW5T3v37kVRUVHAXKkHHngAkcZu0MOs06HDZEaiTifPZcbji04P9/AJcnN0tMFwZCsMBzfAUHcKxqPb5daSmIwd+SXYXTgat8y6GGkmC+4YOx/jMwu66fY8fWI3bCcPwrz1beiP7YauM7vFlT8KzhnL4Wa+TAhKyyGTmAzH4uvgnLwUpg2rYDixD8Y978NweDMccy6Fa/ISbwXVUISD/f51MO16D7o2r+HfZjLj7fxibMwfiVvGL8K41FwZtDh4Jcy6GIYFl3czrrl8VHIWvjRuKf5xdCNO21rxh0Mf4nOj52NEcu9Kw1yHhIADeK/4+lCjscMacAbL5Xw9UYZrdeBYdDX01Uehr6+Eec0TsF92d3h/w2rE2gzj3g/FUNRR6oSGkikBzomL4Jp6DjypZ4plevv9DMQocLscmDfN6zHvWVHJ5XZbDPNke+AuGAPbNd+E4cB6mDa/BuP0c6XYAz3yFzkWcArM/dXhin2Rgy/vny7FnsZK/GnP+/jS5GUYNvUCPAngq1MvwNTC8WIsRbvIP25kBe6++2688cYb+OijjwIaPv5wOBySeHrLLbfgwQcfDNnDVFxcHDZZAdkOtwtvnNgbNM/I7XGjpqMVldZmVFqbfG7NGNbSgMW1FZhXV40kulL5fv6ZshSec2+EfuvbUkWlzBw8My+AfvaF8Dz9C2n0KDDWPfcSURKOSkk0q+6Y36RUXmUVeDVD/IitxVPpsi8nT57E2rVrcfnllyMz8+zmmx5buzdcufUtb64RDZekNLyeX4R3MvOQbEnBl6eeh6LkzD7tkwabFQ/vfR8n2xrk/Pns+EWYk1vS6/ZKlRwrasKsmN2XfaKWY7n3/7d3HvBRVdkfP5l0kgAJCUlIgFADoQcIvUsRBBFRsWGDtYCKXWzsX10VXNvKih1dAUFXpQhSxEWa9BYpoddAAoQQQkLavP/nd4Y3TkKS6TPvJef7+QyZxsnNfe/ee+65p1xIpx+P7KBJbfrTb6f20yqLsQllqX9cc3o/9Tca1ag9tQqvp520H+fT2UcFSrhPz1FkSBnm9vHjTtm+vr7lFlNVYF2HXw5ygakby5qRJh/LVj2tRuW6q91FRSXsAG6Zm8pV0XFuSbWAI3n/ADJ+8pRuUtucu5JLf9+6mNfNe5p3pe7RjXlegV/zsGHDXD6vVCmFaeLEibRgwQJavXo1NWrUyO7/f8stt5Cfnx9H7XgjD1OluSTqt6bWEfVo9sFNdCYvh4pxPl8Ofj4GiqlRk+IDQ6jdhbPU+Pg+CjtzhAwjJpKScbT80P8uN3AV951bllBMz9EUG19xdKG7BgL76sC5fP38vwqvJrQ2KU5Xk8ZVlBfIVXgjRw0mKfYVUxUTUDOSMlr1oH+W5NFlxUj1atRiZSmigiM1a+2+UlJEX+xbT7uyTNGNNyW0Y581a0ECesyV5GrZu86fok/2ruHx1iemGStFfgYD+zTB0bTYaKQfjmyn1WcO8tiDv1jbOnGaaDsw/rmGlOVfESFS6uYnTSkl3DB+3Dk2S1BfEIv01fvQWFJMBvjkIfcUNhjIdK5SrykZkgcSNe3Avji2ILmp/gLFfTkXYAUYHphKxj8WcLJZikZh4Ia8wbVXicp1Qb9AJfn3nt8pNSudmteqS0+2GcBzmjuvp61o+kgOHffoo4/STz/9xDtWR5SlkpISSk1NpaFDTU7XmsslcTqNBtdPouzCfJ68YS2ICa5J9UJqUWwN9VGTIoNCybeM6R3ZmCmkJinLvqww8okefIdmnTtMl49so34Fl2hEw7YU7GdfygJnwOTm064fKYldSNl4NdkaLE/H9piyQHcarL+SMRaLSW7ORZr9n6/pzrH3UHRUJFFRoSnNws7/mRytQXgMO2RuiahLXx3cwmfzmAgeTupNNZy4FkG+/vRwUi/6/vB2+i09jX46upMy83PpzqadybcS3zt350rKzMykefPm0f3330/R0drLQLzj3An6dN86vg4d6tSnW5skk5/B12TtMBjIL8CXX9/WpCM7nW4/f4I+3ruGxrXoQcmR9UkLwMJC50+zXw6Uch7rLh4/7iznBNmE3FKW/jSomZZ8HRlXf2+yivsYyKd5R/JJHkQ+sY1Ja+gmN5UtqW0Q7HFkl8kapaYmwbwQGUc+sFwj/1dUA6Ko+AoVZlc5lG8/f5KVJax3dzTtbN4AamFe0bTChJQCc+bMYetSWFgYnTlzht+H9Uc14Y4dO5bi4uLYDwm8+uqr1LVrV2ratCllZ2fT22+/TceOHeO8MJqNxCkupAdb9KTwwBCqE1SDDDb6JCDDNnYOlUU+GQqvUNe6jejXU/vot/T9tOXscbq5UQfqUjfBo+kW4EfAydba9jVNiIe2c/0mZdPicvICabxkjMVicmLht/T01O+od/ZOqjv8dlOEzuGdJmUpMp4MXW8gpUkyLU/fRz8d2MT/t2NkA7ovsZtL0vrjXsHCHhUUSt8d3kbrMg7R+YJctohYU8bcNeGnp6dzCpDBgwdrTmHaevY4fZ62joyKwtfhgcTupZRLyz6B0jS+ZQ+amfYHbT57jD7bu5buT+xGnesmkLfhsdt1uEk5d8P4saWcEy+o6C9FfShXXyum15afWbxvDAohwoaijGzChooUTr5IJ9JMBWZdkMxXsCG1TWEBz8+UeZyUzONEZ4+bomZRbBtpb2DRJL7xTJYnVqIakE9UQ1amcC+4Qrm+UlxE8w5t4eeD4luywUBL84qmFaYZM2bwz759+5Z6f+bMmXTvvffy8+PHj5eKZLtw4QKNHz+elSucc3bs2JHWr19PSUlJmsglURa8j+i22o6Wu7AhKeYtjZOpVXgszT20hTLyL9HM/X/QmjMHWXuPC3GyyradoCSB740TSTl5gAdchdYxDRf3LbWYFF519Cy8whY07M0M/e9CjROiRm15AZh7aCv9fvoAf+26uBassCJrsCvpH5dIUcGh9NnedbQvO4Om7VhOE1v3ZcukYGJT5lH6Mu0PviYpUQl0b2LXa6y2ZcHnUJJwLPdH5hH6Iu0PtgR3i9aAxcPP32RZqmj8dL6eSub/y1QTkpUWpbQCgyWwPKUmMJiL/VZaeBuJaz958q9jdlsJDiXDuGkmy1J5spHHDdm4G7ezT67gdGobn6TuRHiolR9wgpF5jBUoJfMYK1NwwIdPKvzoaN8GVqLKdQtxUHFfeGwXn7Zg3tJCDjRdKUy2uFfhqM6S9957jx9aArki4OCt5kZyaS6JSncOf+UdSQqPpZeTh9LKU/u4HQdzztLr236hfnHNaXgDHNN59vjLJ76ZVeuYZvMC2Vh+obCkmL5IW087zp/kOKvRjZNZYXIXbSLi6Jl2A2n67lV0Oj+H3tqxnCYk9aZGXiiloTX+yDhMX+/fyMoSlJ2xzVJstuTie2Obd2VL1Nozh+jr/Rv4OK9nTFPSdMkljK+cc0TnrmbwtxX4Klkbm0iMGlKrcoUJ/YvNLH5ig4DnyMuG/1vpuM8zp0sQXEelxX3LfhfXq3YUP3yadyqVx4/MStRxopzzRA2TKt/4pgwlpajQavWK47lZfAoC7mjaiQI0mM1eey2qgiBxJKLhAHIj2ZqN21U7BxX8niH1W/Hu+vvD22jb+RO08lQabc48xlaozlHWs4q7FKvWMY3WprO2UBXkU55/IH24exUdvnSOrRP3J3a3KYrNWeqHhtPz7QebI+jeSV1pcwRdVWXtmYM068Am3g33jGlCdzaFsmTffY7v4//5+fjSqtP76ZsDm6jIaKR+9ZqT17A2fkJqkaHHTXDktFBcDGWe+/yl0KifGfyIUBanMtmhtclwy7NlZKiyfcinAmU0PTebYpGA14pVXHAPzvov+uC+CK1dygKoXLaiXF++SMZF/ybyDyIfJFyNb0EU27iUAoUIcdMYVahTZAOXRKW6A1GYPASUFUQwwcyoRuLAsuQKPxZ7dg4gIiiEHkzqRX9mpfN5ceaVXLaE4Jju9iadqJ6njukqs46huG9xoeaKt3L5Ef+/EkDWCgqgG5Lq809LRe9fqSvpyKXzrBg/ktSHmiELsYcID6xBT7e7jj7ft46dJz/dt5ZGXWnPPgGeUIgRWXr99dezr6G3+T39AM05tJmf941tRrc16eTwcSj+35gmHcnfYKAVp/bxETfqNg6M91K9PGvWZcVIPk06OHzsbM1ybWtBZoBEuguO7uQ5ZlrHGyikknxgxcWF5K+xcV/VcKn/YpANDuWXskzlm07tJ4UWmeb1mMZmBWoNldCx3CwOZLm1Scdy78eYulE0fOj1VDM0xHR/esG/VRdpBTyNq9MKWKK1fCnIc7Hi5F5acmI3P8eiMKBeC7qhQWsKslC43NXucvMCte/Pk7Jx2Zdk6DuG/Z40kf8m4ygZF/6bC1tWlMoBjrgHm3ekd/euoYjAGvRoq34c8eiNdmPXBkuiauaGdeWOJqYIOr2FRTsiG8fPcIQHA+olshW1MoXRVtmYMhcc20W/nNjNr0cmtDNbkF3VdltxZ14tV8jGPbjm9CGaf2wnFwYHoxLa06DYZmTctPjarNMpQ+mT/RuoV2xTp60MWrkPtSTbHfIV9ulcWr5yjUhoBAigJBfSRKBWKn5eTd6rUuzjQ0dCa1FAgyRq1LJHKQuU6T5cfI1DuStzx9mKKExeUJi0ONCQKAyLK/xtQO2AYPa5gXm00FjCqREw4SHyCpYxV1ZwvyYvUH4uGZd8yoOLk6oNf4R8GrT0ap8b924w5b0pKTLlkRr+CE8ShVuWcTRm7dq1yb/TICrqOIjeTP2Nc/o82qqv4878LrxXfjuVxooDzN1IAHdr42S2bLrreiLwAn2CBLP+/q6d0Gztk+Un93IeJQDLGhZpa9Y1e/ob0yZ8ARcdT+XXwxq0puEN2rhEIbMXd+bVckb2wYuZHPCAo2EQH1KbLXxIqVFeHqaSkiJadCqNlp7cQwby4aAUKE5Vba61Rba7NjOqfG8q7gpUjuwMUk6kcTRk7tFdFKLWNVW5aoEy9L+TlANbOMCmqMRI2fkFVDs4kPx9DWZlzJOWJrF7CgyiEpAXKDXrFM07tJUzjv98LJWSasewn1NlGcpdfq4O/4ihf2NrDp05TMYf3iWf/neQoV0/8jSceBPFLJFIDzRqS4ah47nNxk6Dabd/LHVK6UJbNm2kZkmJ9PWBTXwkhrB+TzvSVxZBh+u76NguTtC4/OS+UlmtXX09UYaoV69eXCQbtRw9DSw/84/u5Oc4AkfuMVcfRULeDQ3bcOqBn47uYOUJyS6RPNSjfoBuzqvliOzsgjz64cgO2nT2KL/GPTaiYTvqHdu0VFSib0DQ1UzfqNnnR36+fjS8YRvKLsyjDZlHadbBTXSuIJdubNjO5VGlWgVJjlEfFJsZHPe6ejOjGYfy8BguzP5nfDP6MCyEogvy6bHa9Sgi8yQpJ69aoLLS2elcDbBJPZ1FKe8tpE1PjKDk+EivRFJr/0oIHgWRVi1qx9Dyk3uofkg4/XoqrVSdLSyyarQffLJcOZgtz9XhXGi49Vm26igIX105i4znTpEPjug8NIEgiZtxySfmiugYnD7dRpKPwWAqdZO+nxbsW8uffbRvLY2ICqIHWnSnAIMp8aGWQJbqhmERXALEU9fT02Dn+vPxP+nnq1afEQ3b0LAG15bhcSVD6iexNRHW2WUn9/AiZ+3oT4+JFG2Rjb99ZXoa309Y+NEDPWKa0MiG7SgsIKjS5MIqGDf3Nu9GdYJCWc7SE3vo/JXLXB7DVQq9VsGcgooQ7tycuhMfO5VrRBF/i5xLPj7UunEHirzqu2S2QJ09aUqJoaFIav3OjoLbwODEQoMJEDmbygPRfu7Ok8G7k+vHcbZZZe2PpppsF86QYdhDdjmcOgIGq3HhdKKLZ4n8A8kw+H5zeK1lqZvsq6Zk/IQignUSiocWB1aIXwBblrx1Pd1JWb8iWHoQEeoJkCrC38eXncuhMCBP0xgnnMv1COryzTu0jTLyc/h1o7A63AcJFoVxbQXKJqyCsIp+c2AjJw1F7cRHknpTiEYT2bqjfJZeNzNGGxV3+M3CFSQ8oAZf7/IsUJwxXEOR1FW8zLXg1gzl8OdxMxg8cAQ1jJjAigsd30vGb/9BilpQ2A0o+7eQce4bJmWpViQZxrxQKhdJpaVu0tP4cz1eTySMQ1ZrTNJHLp1jh129KEs/Ht1hVpZGN+rgMWVJpU+9ZnR3sy5sVUGSUoRI66X/nAEL3kd7VtO//lzFylKYfxBbg55tN8ghZckS+Ns91qofR04hb9zUnSvorL2JMnWCXucUR0m/fJH9DAEqFVgGGJUXCVoe5jyDHkQfKqugyQzlwb6e89HxadqBDGMmk3HBh0TZmaw0GYY+SD6NXHfkoihGLhKsbFxseqNBy1LWLKTt33z2KLUMj7WqSIZp0IRu7XpisfvzQjrlZhZwxl04hLesHcMPJD6tg5IWGlSW4NCOWnoAYf84xvAGiELE8dxXaRu4RE2xYqq0bi2buB6wrKagHqfAORtWEVjU4KRtSoLbxqW1KluGx9Cz7QZyTjMoZFN3LqMJSX00kYy1bJ/Yw+WiAjqee4FD6S8VXaH+9Zrrck5xdMzOObiZk7+2jYij9nXibcozSAvnmH4GBJkcvr0QJScKk+BQhvK+sYl0KOcsRQfXdCoSzB58oupzyQZ2Bk8/SMb5H3D9I47GcHIHphTkkfGXz4lQBw6/q+Mg8uk1mosHXykpolXp+9lZGr8mpW4js+IR0bQh3fvLZ+QXFOQVRdKVGecLjcV0Y8O2tOfCGdqXfYYdT7eeO84PEB0cRi1rx1JSeAwl1ooud1eIo4XOXVLoxNkzFFUrnF+7+ihBXahQDw65kNSyMyg63Du2GXkT1G1EotIv9q2njZlH2RHcsl6dM4usNpyQjXQo5xwflWVdPSZpUTuabmuM/G3uybuF8k3PtxtE0y2SsaJPO3ipELK9jtnIQYUs1ngcu/rzHHxzroLSWDiSqmwzE2jw47x52Ljo/ah3fcZhOpCTyb6eOLa1NnerDuUdOg2h7EnvUEhElCnPqheCakRhEuzPUB6byLvJf+78lSeNh5J6UZOaUR5pk0+NmmQY/TQpK78hZfc6UlbNNZV+GHCXw87gStYZk+XqwhkiX3/yGXgPGZK68cS46uQeWn5iL+WiNtxVpSGnMN+seBh8DRQQUsN1pW68nHEeCgceWBiPXjrPytPe7NN0JOc81yHEA5muMWk3DovkCRwKVMPQCP673em0WnahOnk5m9KyM/gYDMdhcDDWAp2iGrLS9Om+daxshvkH0k0J7XUX/VSeEzI2Sv3jmlOAwY/zjI1ulEzJkfXd7uRe+2oyVtRKhBX0k71r3F5qyBHH7NyiK6wUHbt0wawknS/4SzmyBD5aGDcNQiPY4lTZ5nTPhdM0Y+8aqlejFv8uZO7Xo+Uyt+gKR1ACRJnaarWGpelKbi7514wgvwDv+bFJHqZyqI55mKwtVDhDt8xQjgEOM3l63kUeuKj940xtLXvbjttW2baclNXfmwqGxjUnw4hHyCc4zC7ZyuGdZFzyGVFhPlFoOBlunEhFkfFstVh2ci+by0HdoFB2hO9ctyH/vRwld2I3/bhxFa385+c04OlxNKpLX5dGtHjyelpbvPOLC1k52ZN9hidvpJ2wZGKrPnQ45zw7vl88cYbWvf8V9Zh0L9WqH8M5ipx1WuX+Pr673MUbFo/KzPre6m+k6PjpyE56om1/jk50ZyoHV7e9PCdklaH1W1PHyPpUNzjM6Xpf9rYbivzcg1to9ZmD/BpHWYhKLK8uoKf7pEnNSJ4TywPzBxQjy0dImdpq6pxSdjMzJD6JVp8+wDm/rsAJmoiigkJ5THWNbmT3PeTNNejr/RvYwhRXoza92GGI2fJqCzt27KCnn36aZsyYQc2aeceSrO0tjqAJsNBxvhSDgfwCfPmmwXvPtR9EX6dt4Jp0qK2FM3kkRfRESD12tD4dB5MSHmsK/T+1n4yzXyfDyEfJJzLeNoVr48+krF9gqtoe14xKrv8brbqUSUs3L6Scq4oSdoFY8LvUTSi1o1NL3cScLaCvNz9OjzTuRu3ik3QR/lve9bQG/FLaR9bnB4DzLSxPsECdyM2i5rWi6cu09fxZUV4+ndycyj8BFgBM+rAOwBEa90eAry/3lfqAeb70az/z85gaNWnN6YPXRBBxVCIiiOonkVZTdGBh0GMqh8qckKH4DWvQyiupM0ybs84UGRxKPx7ZwVnszxfk8RGdu/vRWp8gxQSO1+D7p1qO8BP1HfGeo+WzoJReF9+Susc0YdcApHrBhgV5qpBCA6V5esU01eR9ZMn+i5msLIE7m5kqDtgD5qyVK1fSpUuXyFtou4cFTYeLInrlby178q4ITsKwypy6nM1JG2tWknfFlfg0bkuG218k4/x/cVSb8ds3yDDswVLFIcuiFF7hsit0YKvpddu+tDaxIy3Z+ztdhKWJiOoEhtDQBq2pW91GFQ5sTFCFV0xHdVg8tD5huTJvT1RwKEUF/3V8Bz+NypxWoYCm52WzRdIesAC90fnGiiOITqfR0AbaTYeAcaCXVA4I3d95/iQfdWLx16oTMjZLUCwiA0NZSUeb3931K01o1YdqBrguzBybqtN5F2n3hdN0Ji+Hrm/QqtI+ga/jPzqNqDjiy8nNDJQuzEkD4lpwTT6UtEJkK3KALTm+mwbEJVLf2ObXWK60QLGxhOYc2MTPodx5yoXD1ehrhhc0ByYvDOL4kHAu4Ivw3zd2LKWHW/bmRIkeaUOdeiZn8EUfcTkV4/wPTQ7bnQabfSt8fU2Tu4IIuwXTic6fIsXgSwc7DqKvAvzowlHTuTqydMO83j26keaST2oV7PqR46kyp9VaAcFsZcJCi6MHPFByR31e6r2SYioyGqnIWEy1A2qw34NWF29nUzlcLLzCEX6xNWqyQ70nIxGhEEA5gsKxM+skW4hVJRXHXFqJkK0I+PHgvkJag6O5WfTWjuX0aOu+FFvjL+dze53s4Wqw9+qxMxQlKCRqn6AobGV9gjHgqjmjss0MlCr4bvWJbUYbM49wck9YnLBpRcLhPrHN6bq4xEqVR08HHyw/uY9Oc9oJkz+fXhGFSXBZJunJ7QfRR3vWcPjv27tW0N3NUqhL3UYe+f0I/Tfc/CQp/5tDyq7fSVnzPdGVXDKmDKOQ4CBOfKYU+5nyNylGKgwKoZnN29NOKiQqLOTkafAp6R7TWBfHanqLwENEW5foRg7vTrW+eDuaygEL8YbMI2yhszUS0ZlFEH154OJZrhm5K+ukOdINYGvRuGYktYuI57QBlV1PrQQ2NK0VRc+1H0jT/1xFmVdyadrO5fR4q34UG1LbJid7HBEf4eAGk4J09FIW11xUwVyA2ncIbtBan6Bt8BvtFt2Ytp09Tr+c2EOn8rI54zyU8B7RjWlQfFIpJdwbpVfO5l8yH0nDUV+LFjBb0cI9L1QRYmrUYqUJlqbUrHT6Mu0P3rWifpknIjo4Sm7A3UR14kjZtcrk47RlKRl3/PZXQcj2/clw2/P07d61tPNyFhcZxvEDJh5HFKW4uDh65513qH5974Q4awXLCLzFl/Kpx6R7KLKeyeHbWedma8qYVhZvR9oOZ3oco1QUidgkLIpzEamRiOU5N1tbBPE+QtJ3ZZ3in5YJZ3FdoAy0i4hjnyvLo3RrEZVaAalN4E/5792r+W+tExxaaSQbjh6hHEFJgjUJ/8cSRKKhT1qFx1LTmlGlHNu12CeYWzvXTaCOUQ050AAuElACV50+wM7x2LQOq9+KIw09XXpFURQufwLrMdJPdIlKcFiWFuZaiZIrB4mSc042rAkwD6uZl5H4cHyLHpWWNXB1240550lJXU208edrP+w6nPLa96dNF9L5PN2ZSB+t9LmeI/BsoaIIIi1Hmtnb9ryrkYh7K4hEVBOJQnlSj+/Kix5UI6u2nTvB1qu0ixk8JlWQoBQJA9vViWN5ld3/7rqe7uhzWIBwxIjNmqWTvcqw+q2pWa269P6fv5V6H31msuqZLHsRgZUfi2q9T7Ckw8Ea9xzuJYDC6scuZZXfLy6IYq2o7VvOHqPP9q3jNBuvJA+l6Bo1NTkf2opWN2aCjsHOeGRCOy7eizBSDNo3dizjWlBIQucJfEJqkQLLUnlsX0mhXW5g50lnycrKouXLl9OoUaMoIsIzPltaBpPu8ePHacWKFXTTTTe5rE8qiiDSkqXD2bZDIUIyRjUhI44y1DQO+7IzrkkkOql1P9p/8Wy5EXjQjxqGhpsXzNjgmtSuTjwfnTcKi7Q5+aEjEZXeAopfg9Bw+nD3/8r9HEolIiqhMEYGhbAFCUoSSrjYYwHXep/AbzOxdjQ/UOJoVfoBVoy/9nBd0PziQpp3yBRYAyu+M8qSVuZarV1roQoBp0yEhH+053euOTV1x3K6N7ErJUc2cMvvQ4QbjhzgJDwwor6VKtd5RE4OYADlYPz48ZScnCwKk0WfjBs3jjp06ODSPtH6QuXqtkcFh1EfPMpJJIq0Do1rRtGn+9aW+38RmTc15Sa6vUknPtLDsZW3Iiq15GSPSLZXO95ANVzgR6OHPoFy3CgxkufGyvrlcnEhhfoF2h3qXxnzj+7i6Fjk63JFbUctzLV6mnMEHQKL0gvth7BZFrvdT/au5aMIlAJwNsU/HDbhpIlze2T/VaN84Dg7qF4iKZVWufZMORfB9ehhoXJ122EBQSg2HsMbtmHFwJpyUGAspr71mlN1wpqTvSsj2fSEtShWpIh5ecsizhml+m8hB52jHL10nn4/vZ+f39Gksy4swbagi9zq//73vykhIYGCgoKoS5cutGmTKZ9DRXz//ffUokUL/n6bNm1oyZIlHmurcC3wXUK478CrR2A4W4fVCSZbe6N8EE20KfMo1+p6esNPNHXnclpyYrdZWUoIjaDOUQ2pGLI7DChfSIcBZLyaMVcQ9KoYhPqbFsHy0Hr0oLud7MtDDRCojlTaL7GJtD87g0u4IHoShXFf3LyQXtmyiGs1YkMKvy1bUXyIk4qip1OiEtjCWVXQvIVp3rx59OSTT9LHH3/MytL7779PgwcPprS0NKpbt+4131+/fj3dfvvt9Oabb9INN9xAc+bMoZEjR9K2bduodevWXvkbBNMOGSGl8aHhNOvAJnbMfBN5U1r15ciciqJ84MCIgpv4Po7bEP1hGfaLRQE7ojYR9XhXZJl7REkZRryf377SHCUHZcmQMswrhRsFwZXoOXrQm/USqyPW+gXz8+T2g83pFQ7nnDNHbP4vfT87bTetFWW2PiGDfdn6gWq05qWiAk4iigCGxmF1qCqh+fH07rvv8rnlfffdx6+hOC1evJi+/PJLev7556/5/gcffEBDhgyhZ555hl+/9tpr7IA6ffp0/r8Ceb2ae2xwLZqxdzXnfQny8ys31HVQfEtadmI3rcs4Ys6+rRIfUptah9ej1hH1OG9MRQ6brBR1GkKGLjeYFSZYllypLNWoUYM6d+5MISGeSziodaRPPIMoB1UvQMCb/QLndzyQiBjWfwQaqAoUrE/7sjP4AesR0rG0hPLEUZv1uNTRNfN4bKJLrUtamFc0nVagsLCQO+m///0vW4lU7rnnHsrOzqYFC1AHrDQNGjRgi9SkSZPM702ZMoXmz59PO3futOn3SloB98vOKbxCZ/Iu0t7sjHJDXZFtG1E+qNAdaPCjFuExrCTBkoRs3Pa2HZm+g4NdVzbBUrZe+lxke0+2O+VrPczdm7JxzI81xB2y9dgnjvQLVARYmvZcVZ6QpgLpLFS8lbLAG2jawnTu3DkqKSmh6OjoUu/j9b59+8r9P2fOnCn3+3i/IgoKCvhhqTBZ3liuJC+vgsitaiYbvQrrECxNlUX5TGjWgxrUqP2Xo2YR6paVzk9ja9txL1XnPhfZ3pPtbvk5+fk8V/kEmnKdle8KXr36XJXtjiABvfaJo/0SSgZKqRXHDyhLR3KzKO1SJh3Py7YpZYGq7Lii3e7CFkVMF07f7gb+TrAoqY/qnrXZE2Byh89SpVE+JcWcaVfLUS27du1ihXzHDlMtOkH6xBvACuCODYEglMUf5WIQrRnXih5N7EVXrERrwvLpCsODFuYVTVuYIiMj+SglIyOj1Pt4HRNT/tko3rfn+2Dy5Ml8jGdpYYLSBI3TXeY/d5oV9SLbao0wP3/OWaPlfkEkJoB5W+4VE9In3pMvskW2p+UXe2ge98S8omsLU0BAAHXs2JFWrlxpfg9mRLzu1q1buf8H71t+H8Dpu6Lvg8DAQPZVsnwI7kdCgAVBEPRNSTWaxzVtYQKw/MDJu1OnTpSSksJpBS5fvmyOmhs7diwX5cOxGnj88cepT58+XKRv2LBhNHfuXNqyZQt9+umnXv5LhLJIlI8gCIK+CaxG87jmFabbbruNzp49S6+88go7brdv356WLl1qduxGunTL89Hu3btz7qWXXnqJXnjhBWrWrBlHyEkOJm0iIcCCIAj6xr+azOOaTivgLSStgGdl6zkEGJGcp06dosTERPMZe3W/ntInnpcvskW2FuTnunEed+e8UiV8mITqhR5rhGHgNmnSxGsDWItInwhC9cXopnlcC/OKKEyC4ARHjx6lcePG0ZEjR7zdFM0gfSIIQlWcV0RhEgQnQMZ51Du8cMFU/FeQPhEEoWrOK6IwCYIgCIIgWEEUJkEQBEEQBL2nFfAGauCgWlPOHREK7nCM06tsd8t3p2zkBFN/h6vvF+mTqtMn7pYvskW2FuTn6nReUQkLCyMfH58KP5e0AuVw8uRJqScnCIIgCNWIi1ZSCYnCVA7QjtPT061qm46g1qk7ceKEy3M86VW2u+WLbJHtbdnuli+yRbYW5OfoVLaKtTVfjuTKAYm34uPj3fo73FmzTq+y3S1fZItsb8t2t3yRLbK1IL+mTmVbQ5y+BUEQBEEQrCAKkyAIgiAIghVEYfIwgYGBNGXKFP4psj0jX2SLbG/Ldrd8kS2ytSA/UKeybUWcvgVBEARBEKwgFiZBEARBEAQriMIkCIIgCIJgBVGYBEEQBEEQrCAKkyAIgiAIghVEYRKEcpBYCEEQXI3MK/pGFCZBdwO5qKjIbbKzs7P5p6tL4oBz585RXl4euYtjx47Rd9995zb5gvfQ0/jUa7tlXrkWmVNKIwpTNR3AGGRpaWm0bt06lw/kU6dO0a+//krffPONuXq1q0Cbn332Wdq+fTu5mp07d1Lfvn35p6tJTU2lnj170ty5cyk/P98t8pOSkmjatGkul33o0CF6++23ud8XL15MV65ccZls1GzcsmULLVq0iPuluLhYF+OnbP9MnTqVXnzxRV5c1KrqriArK8s8Pl2tfKAm19dff03vv/8+/fbbby6RKfNK1ZlXZE4pB+RhErTHn3/+qYwYMULZvXu3y2WnpqYqnTp1Ulq0aKEEBwcro0aNcpnsXbt2KU2bNlU6d+6s+Pr6Kt26dVPy8vJcIjs/P1/p37+/4uPjozz++OP8d7iKHTt2KIGBgcpzzz1nfs9oNLpE9t69e5WIiAjliSeeUE6dOqW4GrQ9JCREufHGG5XY2Fjlyy+/dOn1jIqKYtlNmjTh+2bt2rUukb1z506lQYMGSo8ePZSaNWsqycnJyrRp05RLly5pevxYgnuwdu3aSu/evZWePXvyPX/LLbcoy5cvd1o22u7n58f3uqvvSVzXhg0bKt27d1datmyp+Pv7K7Nnz3ZKpswrVWdekTmlfERh0iBHjhxRGjduzAO4ffv2Slpamstk79u3j2/WF154QdmwYYOyZs0aJTw8nF+7YgBHRkYqL7/8snL69GklIyODJ4uff/5ZcRUTJ07kya1+/frK/fffzwPbWTBBBgUFKa+88or5vezsbOXgwYNOy8bkOG7cOGXs2LHm1//73/94Atq2bZuSm5vr9ASBxenFF19UCgoKlMGDByt33nknf1ZSUuKUbFxDLKa4nqCwsJAXwxkzZijOcvLkSaV58+bKlClTlMzMTF60brrpJr4ODz74IPe/FsePJViwhw4dyvekysaNG5WOHTsqAwcOVObPn++wbCyAKSkpPOFj4Zo0aZLLFtzDhw+zsoRFHP2O/se9j9915swZh+TLvFJ15hWZUypGFCaNceXKFeXvf/87X+jNmzfzpIkbzBWTPrTsW2+9VZkwYUKpSfH5559Xhg0b5tRkjJvx5ptvVh577DGWocrBgvLFF18o7733nrJ161a+iR1BHagYDDNnzuQJOT4+Xvnb3/6mpKenK2+99ZaSlZVlt9zz58/zopqYmGh+D5MQFg/sUK677jqeiIqKihRH6du3r3n3DitE165dldDQUKVdu3bKmDFjHGq3upBAKXjppZfM7+H34D3cO86yevVqvvewwKrcddddypNPPsmLygcffOBw25csWcLWgrNnz5r7Fm2Ojo7mvoeCgLGgpfFTHrB0vPrqq6XuUVi3YHG6/vrrefGxF4ydWbNmsaVq3bp1ypw5c1hBgCXB8juOgL7G/TJy5MhSFpqlS5eyJQEKk73IvFJ15hWZUypHfJg0hr+/P7Vp04buuOMO6tSpEy1btozCwsJo5MiRtH//fqdkGwwGKikpodatW5fyLWjVqhUdPHiQCgsL+XNHCA4OpsGDB9PYsWNZNh6vv/46LV26lL7//nv66KOP6O6776ZZs2Y53HaQnJxMy5cv53P7jz/+mPsH/gFvvPEG5eTk2C23Ro0aNHDgQIqJiaEnn3ySunfvTufPn6eHHnqIfvjhB7p48SJNmjSJdu3aRY6C64cz+5dffplCQkJo3rx57D8yYcIEOnnyJPeTI/0eHR1N7777Lr322mv8GhugESNGUK9evejTTz+lgoICcgbcD/At2LhxI8t+66236NtvvyWj0UgZGRnsN4G+ccT/AH4GkBEaGkp+fn78Hnx/4DPRuXNnvq4HDhzQ1PixBP0BP5qAgADKzMzk99AvuI4YT9OnT2efFfgI2QvGTu/evemuu+7i+/H222+nL7/8ksfQE0884ZRPE/q6bdu23McYsypdunThz+CDZC8yr1SdeUXmFCtYUagEL1BcXFzq9blz58w75f379/N70KDXr19vs8as7sxgzi67u/ruu+94V1L2d9qKKtuy3WhbvXr1lIULF7JZFwwfPlzp06ePU2bdX3/9VWnTpo35Nczo8POARcFeK4LaDuy0YTZv1KiRMmjQIDYbq6Cfcc4O87ejPPXUU0q/fv14F/7JJ5+U+gxmbxzh2LtDrmxnCpk4x8cuFzja37AcDBkyhP9+7IgDAgKURYsWmT/HbrBZs2bKgQMHHDKf48jm4YcfVrZv3873C3bHU6dO5c8TEhKU//u//9PM+KmIuXPn8u57wYIF5r7GMQP45ptv+G88fvy44iz4m8pamvA3wBJlr8+N5b2mjl1caxxH4VqobNq0yaosmVeqzrwic4p1RGHSMJZmbJgZ1UkfJv+HHnqIX9szAVliecP/+OOPSqtWrcyvn3nmGeW2225zajHBGfLRo0dLDcS3336bHfwcNZ+DCxcu8AQJ7r77bjafv//+++yzgjbv2bPH4ckNcuAXofa72m6c38NB0VEwyWCCwML69NNPl/ps2bJlSlJSEl9fZ1HbnZOTw/1heYRjL2q/YIKDX85PP/2ktG3bttT9BkdNLAYw4zsiG8dAMJdjAYTzKhYAFfgAle0rb48fVRFSZeOBxRz+L/CT+OWXX0p9H/cSrq26yNgquyJwP1oqTTimgrP2sWPHnJINuVjMcSSnKgc4TsP9au99KfNK1ZpXZE4pjShMGqTseb/6GjcWfCYMBgM75TlyplyeLwF2axgMAE6a0PpxQ7uq3SoPPPCAct999zl0bq/KgjMjdk5xcXFKTEwM+y+AH374QWndujX7HdiL2h78LLu4YCBil4kdVnl/kzXUXTAWafQxJuL//ve/5t+JAQxfBEedNMvrc/wNiPZBBBQWAkex7Av4dqDfLR0nn332WVY6bFEIKgLysBu0dLLFgorJ7cMPPzT/Td4eP5VF3cHJHPc2xs3nn3/OfkD4G+BUDQuLNZ8MeyL6oKDBcoVFErtpa3+DLbLRP+gbLDJQRrALx87cFguTpYyyyLyiz3lF5pSKEYXJy5S9cKr5+eLFi+XemJgY6tSpY9PkaqtsaPpYSGA+xqSmThauajc+w8QAzd+WnUNFsrHwYKcDEysmgy1btpT6ni2hoxXJRpvLRlFgUsNEj523epTjqGwM2EOHDvGuD1YORHNgd4lFz9aIHHv6HDtiLKr/+c9/nJaNSRcTWK1atZQBAwawpQBOsWi75RGOrbLVSR0yy14zXANYN3CvoL+sUfZowJXjx56oO1ho4PwNiw92/VCUENmFiCVnZZf9e6EgwHHYmtXDHtmwhEAxwNER5oCyY6tsG9w1r9hzPe2dVyqS7Yp5pSLZrphXKpPt7LxiT3/vsXNOqUy2s3NKWdmunFMqQxQmL6HePOqFx6KiXnRMdNjtwetfBZ//61//4hvW2iRsr2zsTCAXC0llE6UjsuHbgYgc7ICcbTcmmJUrV3LItWU0j7ogV7ZrsLfdOE5AJA52m67ob/WcHpMF/F4wgBHhY4t/hL1tx/fwHUSeWFtIbJENSwFAODR8RRABhmMKa0qHve3GBA+Tvy19bnnUoP4e9aez48eZqDvI/vbbb/noDO1wpWyAvwlHFtYsS/bIRt/gWA99g+O+iiL77O1ze+YVe2XbM69Yk+3MvGJvu+2ZV2yR7ei8Ym+77ZlTztog29E5xd522zOn2IIoTF4ANzNCHJHYDeZvyxBLOIhiZwpnQMuBqubZsOYM54hsfAc7YiQUc7Vs7Lyxm7I2gG2RjbBTR5wNHWk3Jk/8H2uTgy2yYRGAbE+1vazZ3hWy1bZD4cFza34ojrQb7cUCYE3RgOywsDBl/Pjx5vfUSdPZ8VMW/K04lvn+++/5NXbdFSkf9pr57ZFteV9aOg+7UjZ8gSpasBzpc3vmFXtl2zOvWJPtzLxib7vtmVesyXZ0XnGk3fbMKWE2ynZkTrG33bbOKbYiCpOHweSBHdc999zDOyTkzvjHP/5hPifGGSsGlCNnrI7IVm9aaw6TjshWn1sb0FrrEy20W8v3ijtk2/M34Kinbt26LBdmfMvJcfr06byjLBsp5wy2Rt0hZ5K9Ds32yLbXqdke2bgulV0De/vc1nnFEdm2jk9HZNtDdWm3O2WX2KHsOdrfrkQUJg+C81Nk2FUd/QB2CYh2scSRm1VkVx3Zem67u/sFwOQOXw0kFUQoOLL4qpw4cULRY9SqN2Ujwsyak607+1xki2wtj3tLTNmdBLeDBGIrVqygAQMG0FNPPcVJu5CEDYnZ/vzzT+rTpw81bNiQE5shyZn6uciuXrL13HZ394sKElN27NiRxo0bx4kjv/rqK04OiGSAKSkpdP/993MCS1ehtlNtK15HRkbSkiVLaPjw4ZwIMjAwkFavXk116tTRpeyIiAiv9bnIFtlaHPfl4hG1TDCf6WNXpwLfDuRveeONNziSBE5viGqx9PcQ2dVPtp7b7u5+AZcvX+b8LYimwfNPP/2UjwDhYKz6yzhqwXJn1J1eZbu7z0W2yPa2bFsRhcnDqOZx+DogWsKygCTyUuCM1tFK5yK76sjWc9vdKRu+NpgUEf4OWQBKGMLskSG47NGfrbgz6k6vst3d5yJbZGtBtj3IkZwbQW2bbdu2cf0cHEXAnAjzOI4uYApftGgR1zJCHR38hFkctXysmcdFdtWSree2e0p2QkIC1/tSTe74PahThvpWOFLC70lNTeXaVKgj9c4775CtoMYc6s6NGTOG5fn6+nL78RO1uVCHCrXohgwZcs0RAf5v06ZNq4xsd/a5yBbZfl6W7TQeUcuqITAR4ugBDpYId4RjpRriW5EXP3JoqNWWRXb1kK3ntntTNnIMwUqCnERqQkQcPX300Ud2J6fTUtSQN2W7s89Ftsj+yMuyXYEoTG4AybiQUA1p3pFlFEnbEGKNfB+YwMouIkgah0ynyHJaUdI4kV31ZOu57d6SbVlu4pFHHjGX77AnZLuqRPa4UrY7+1xki2xvy3YVojC5GOzukA0VFaQtk3x98cUX7KBWNjQYWXhxAyDBm7VU9iK76sjWc9u1JNsVQLm4/fbbWfa7777LjqWwzmCi/vjjj20qjKtn2e7sc5Etsm3BG+PeEcSHycXAVyM+Pp5atmzJoY9qaC/CqENDQ6moqKjU9+GDkJ+fTy+99BLFxsaK7GoiW89t15Js9f/AP8pR4E+1e/du9vt58MEH+fdMnjyZsrKyaNKkSew/ofoGVUXZ7uxzkS2yDV6W7VI8rqJVAyxDplWTIVL5N23alFO4q1irrySyq7ZsPbddC7JdURtKr5E9rpbtzj4X2SJba+PeUTysnlVNTp8+TZs2baKlS5ey1tuoUSN+H7s7NWkckmtduHDB/H9eeeUVGjhwIJ0/f561aZFd9WXrue1alI0Embb0uWX0zc8//0w//vgjR+EAWGFggVGjb8aOHWuOvnn88cf5u0jCWdVku7PPRbbIHuBl2W7Da6paFQEOrCgFAefLWrVqKS1atOBK5WqpAVVTRuHAqKgoJSsrS3nttdeU4OBgq7tvkV11ZOu57XqVXRUie9whW6/XU2SL7GA7x72rEYXJCTIzM/lCo2o2JidUooZZHHWapkyZwp+rZGRkKB06dODPAwICrF50kV11ZOu57XqVXRUie9whW6/XU2SL7AA7x707EIXJCVBWICEh4ZqL+Nxzz3GY77Rp0ziFO9izZw/vBKEhI7W7yK4+svXcdr3K1ntkj7tk6/V6imyRvd2Oce8uRGFyAoRIYwe4evVqfp2Xl2f+DE6XMJOrOWfgvDZhwgRl7969IruaydZz2/UqWyU/P59D7j/77LNSFhjIwZEA5JbF1pwuepSt1+spskW2FhCFyUmQtbhfv37m16ifpQJ/gzFjxpSaBEV29ZSt57brVbbeI3vcJVuv11Nki2xvI1FydnD58mW6dOkS5eTkmN/75JNPOBfKHXfcwa9RP6u4uJif9+7dm/+PSlBQkMiuBrL13Ha9yq4KkT3ukK3X6ymyRba9494jeFtj0ws4d0XOEzigoQL4rFmzzNrvt99+yxEso0eP5vwoqmn8rrvuYk0ZjpllS0WI7KopW89t16vsqhDZ4w7Zer2eIltkj7Fz3HsKUZhsABcdjpYoOzB79mx2xvT39zebwuGgtnDhQj6XxUQ3cuRIdtYMCQlRUlNTRXY1ka3ntutVdlWI7HGHbL1eT5EtskPsHPeeRBQmK2CHBw25bObcvn37Ko8++mip93JycjgEeNy4ccrEiRP5hhHZ1UO2ntuuV9lVJbLH1bL1ej1Ftsie6MC49yRSS84KqGGTnZ1No0ePLlW/Bv4FqNkEriqeFBYWRlOnTi31PZFdPWTrue16lV3e74IfRF5eHr9G/brg4GB66623+PmMGTNo8ODB1LZtWwoPD6dHHnmEJk6cSC1atKhSsvV6PUW2yDZ6oz6cHWi3ZRohOjqaZs2aRb169TI7YIK4uDjzhYVDJp5bOrWpTpoiu3rI1nPb9Sq7LO3atePivlOmTOHXUDoKCgr4+QcffEB16tShN998k1/HxMTQP//5T5sUGr3J1uv1FNki28eBce9JRGGygWbNmpm1X9RwAtCMMzMzzd/BhPb555+bPf1tvfAiu+rI1nPb9Shbr5E9noga0uP1FNki20cUpqoDtGHL0F1VU0Zo74svvsjhvX5+jp1yiuyqI1vPbdeL7D179tCoUaOoT58+1LJlS5o9eza/j+ewyqxYsYJuueUWPhpQfw8m6pCQEJ6cKwvv16tsPV9PkS2y9YA+WqkhcOGhBeMC169fn83j06ZNoy1btrBpXWSLbL23XeuyoXTA6jJ27Fjq1KkTbd26le677z5KSkqiDh060IgRI1jBgK8P/H5wfBUQEECLFy+mDRs2VDo561W2u/tcZItsLc+1HsPbXud65fXXX+doFeRM2bx5s8gW2V6RX91k6zWyRwtRQ1q8niJbZOsJUZgcBBcbF94dIZAiu+rIdrf86ib7zJkzSkpKirkOlZrs7r777lPuvPNOfo5kd2XrqtlSZ02vsvV8PUW2yNYTPvjH21YuvQJHTJjQRbbI9qb86ib7wIEDZodS+PrAofTll1+mY8eO0X/+8x/z9+BUXbNmzVJHAlVVtp6vp8gW2XpBnL6dwJ0XXWRXHdnull/dZOs1skcLUUNavJ4iW2TrBXH6FgRBl6jRN6pSYRl98/rrr9P27dudjuzRm2xBENyHWJgEQdAtqkeBuyJ79ChbEAT3INsYQRB0i2qdwRHXZ599xr4/a9eupeTk5GorWxAE9yAWJkEQdA9qrYH169dzjiORLQiCq5EoOUEQqgR6jezRc9SQIFQnRGESBEEQBEGwghzJCYIgCIIgWEEUJkEQBEEQBCuIwiQIgiAIgmAFUZgEQRAEQRCsIAqTIAiCIAiCFURhEgSh2pORkUGvvvoqZWVlebspgiBoFFGYBEGo1qDQ7a233kpBQUEUERHhkIxVq1Zxbbjs7GyXt08QBG0gCpMgCLrh3nvvZcUEj4CAAGratClbhqD0OMozzzzD9dueffZZl7ZVEISqhdSSEwRBVwwZMoRmzpxJBQUFtGTJEpowYQLXZJs8ebJdckpKSljxeu+999zWVkEQqg5iYRIEQVcEBgZSTEwMNWzYkB5++GG67rrraOHChaxAPf300xQXF8elRrp06cJHZSpfffUV1a5dm7+blJTEco4fP85Wq5EjR5q/BzmPPfYY1a1bl4/pevbsSZs3by7VBihqzZs3p+DgYOrXrx8dPXr0mnb+8MMP1KpVK/49CQkJ9M4777i5ZwRBcCeiMAmCoGugtBQWFtLEiRPpjz/+oLlz59KuXbvolltuYWvUgQMHzN/Ny8ujqVOn0ueff067d+9mpagsOJqDsvP111/Ttm3b+NgPRXJVh/ATJ07QqFGjaPjw4bRjxw4aN24cPf/886VkbN26lf2ixowZQ6mpqfT3v/+dXn75ZVbaBEHQKaglJwiCoAfuuece5cYbb+TnRqNRWbFihRIYGKjce++9iq+vr3Lq1KlS3x8wYIAyefJkfj5z5kzUzVR27NhRoczc3FzF399fmT17tvnzwsJCpV69esq0adP4NeQlJSWVkvHcc8+x7AsXLvDrO+64Qxk4cGCp7zzzzDPX/D9BEPSDWJgEQdAVP//8M4WGhvJx2fXXX0+33XYbjR49mn2ScEyGz9TH77//TocOHTL/XziKt23btkLZ+G5RURH16NHD/B78o1JSUmjv3r38Gj9x3GdJt27dSr3GdyxlALyGtQvtFARBf4jTtyAIugI+QzNmzGDlp169euTn50fz5s0jX19fPgrDT0ugOFke38HRWxAEwV5EYRIEQVfAoRt+RZZ06NCBLTeZmZnUq1cvh2U3adKEFbF169axUzmAxQlO35MmTeLXLVu2ZMdxSzZs2FDqNb4DGZbgNSxgZRU6QRD0gRzJCYKge6CI3HnnnTR27Fj68ccf6ciRI7Rp0yZ68803afHixXYpY4i8Q26mpUuX0p49e2j8+PHsLP7AAw/wdx566CE+WsN30tLSaM6cOdc4cz/11FO0cuVKeu2112j//v3sQD59+nSO4hMEQZ+IwiQIQpUAuZmgMEFZSUxM5FQBsAw1aNDALjlvvfUW3XzzzXT33XdTcnIyHTx4kJYtW0bh4eH8OeQhim7+/Pmc8PLjjz+mN954o5QM/L/vvvuOI/Zat25Nr7zyCifYRAoDQRD0iQ88v73dCEEQBEEQBC0jFiZBEARBEAQriMIkCIIgCIJgBVGYBEEQBEEQrCAKkyAIgiAIghVEYRIEQRAEQbCCKEyCIAiCIAhWEIVJEARBEATBCqIwCYIgCIIgWEEUJkEQBEEQBCuIwiQIgiAIgmAFUZgEQRAEQRCsIAqTIAiCIAgCVc7/A7RdPxcLAiaMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ Visualizar com gr√°fico de linhas multiplas\n",
    "# Vamos focar no modelo_a com faixas fixas:\n",
    "\n",
    "# converter para Pandas para visualiza√ß√£o\n",
    "df_fixas_plot = spkdf_faixas_score.filter(\n",
    "    (F.col(\"model\") == \"modelo_a\")\n",
    ").toPandas()\n",
    "\n",
    "end_dev = df_fixas_plot.query(\"env=='DEV'\")[\"periodo\"].max()\n",
    "end_prd = df_fixas_plot.query(\"env=='PRD'\")[\"periodo\"].max()\n",
    "end_oot  = df_fixas_plot.query(\"env=='OOT'\")[\"periodo\"].max()\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.lineplot(\n",
    "    data=df_fixas_plot,\n",
    "    x=\"periodo\",\n",
    "    y=\"risco_faixa\",\n",
    "    hue=\"faixa_score\",\n",
    "    palette=\"Set2\",\n",
    "    marker=\"o\",\n",
    "    ax=ax,\n",
    ")\n",
    "# Adicionando as linhas verticais\n",
    "ax.axvline(x=end_dev, color='black', linestyle='--', linewidth=1)\n",
    "ax.axvline(x=end_prd, color='black', linestyle='--', linewidth=1)\n",
    "ax.axvline(x=end_oot, color='black', linestyle='--', linewidth=1)\n",
    "ax.set_title(\"Risco por faixa de score\")\n",
    "ax.set_xlabel(\"Per√≠odo\")\n",
    "ax.set_ylabel(\"Risco\")\n",
    "# Ajustando a est√©tica\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.grid(True, linestyle='-', linewidth=0.2)\n",
    "ax.xaxis.grid(True, linestyle='-', linewidth=0.2)\n",
    "\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "19e810bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ Visualizar com gr√°fico de linhas multiplas\n",
    "# Vamos focar no modelo_a com faixas fixas:\n",
    "\n",
    "# converter para Pandas para visualiza√ß√£o\n",
    "df_fixas_plot = spkdf_faixas_score.filter(\n",
    "    (F.col(\"model\") == \"modelo_b\")\n",
    ").toPandas()\n",
    "\n",
    "end_dev = df_fixas_plot.query(\"env=='DEV'\")[\"periodo\"].max()\n",
    "end_prd = df_fixas_plot.query(\"env=='PRD'\")[\"periodo\"].max()\n",
    "end_oot  = df_fixas_plot.query(\"env=='OOT'\")[\"periodo\"].max()\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.lineplot(\n",
    "    data=df_fixas_plot,\n",
    "    x=\"periodo\",\n",
    "    y=\"risco_faixa\",\n",
    "    hue=\"faixa_score\",\n",
    "    palette=\"Set2\",\n",
    "    marker=\"o\",\n",
    "    ax=ax,\n",
    ")\n",
    "# Adicionando as linhas verticais\n",
    "ax.axvline(x=end_dev, color='black', linestyle='--', linewidth=1)\n",
    "ax.axvline(x=end_prd, color='black', linestyle='--', linewidth=1)\n",
    "ax.axvline(x=end_oot, color='black', linestyle='--', linewidth=1)\n",
    "ax.set_title(\"Risco por faixa de score\")\n",
    "ax.set_xlabel(\"Per√≠odo\")\n",
    "ax.set_ylabel(\"Risco\")\n",
    "# Ajustando a est√©tica\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.grid(True, linestyle='-', linewidth=0.2)\n",
    "ax.xaxis.grid(True, linestyle='-', linewidth=0.2)\n",
    "\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d09bf9",
   "metadata": {},
   "source": [
    "üîç Interpreta√ß√£o\n",
    "\n",
    "*\tEssa abordagem permite ver se as mesmas faixas de score (definidas no DEV) mant√™m a mesma taxa de eventos ao longo do tempo.\n",
    "*\tSe a faixa 5 (alta probabilidade de evento) come√ßa a ter menos eventos, pode ser um sinal de descalibra√ß√£o ou mudan√ßa no perfil dos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146dbcef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8675d5",
   "metadata": {},
   "source": [
    "## 8. Exemplo Aplicado\n",
    "\n",
    "### 8.1. C√°lculo do PSI (Population Stability Index)\n",
    "\n",
    "\n",
    "**O que √© o PSI?**\n",
    "\n",
    "O Population Stability Index (PSI) √© uma m√©trica usada para medir mudan√ßas na distribui√ß√£o de uma vari√°vel entre dois conjuntos de dados ‚Äî tipicamente entre:\n",
    "\n",
    "*\tTreinamento (ex: ambiente DEV).\n",
    "*\tProdu√ß√£o (PRD) ou fora da amostra (OOT).\n",
    "\n",
    "Se a distribui√ß√£o muda significativamente, o modelo pode estar descalibrado ou n√£o generalizando bem.\n",
    "\n",
    "\n",
    "**F√≥rmula do PSI**\n",
    "\n",
    "Para cada faixa de score:\n",
    "\n",
    "$$PSI_i = (p_i - q_i) \\cdot \\ln \\left(\\frac{p_i}{q_i} \\right)$$\n",
    "\n",
    "*\t$p_i$: propor√ß√£o na refer√™ncia (ex: DEV).\n",
    "*\t$q_i$: propor√ß√£o no conjunto atual (ex: PRD).\n",
    "*\t$PSI$ final: soma de todos os $PSI_i$.\n",
    "\n",
    "\n",
    "Etapas para o c√°lculo no PySpark:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b61484d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+---------+\n",
      "|model   |year|month|psi_total|\n",
      "+--------+----+-----+---------+\n",
      "|modelo_a|2023|7    |0.0082   |\n",
      "|modelo_a|2023|8    |0.0025   |\n",
      "|modelo_a|2023|9    |0.0026   |\n",
      "|modelo_a|2024|1    |0.0019   |\n",
      "|modelo_a|2024|2    |0.0042   |\n",
      "|modelo_a|2024|3    |0.0017   |\n",
      "|modelo_a|2024|4    |0.0022   |\n",
      "|modelo_a|2024|5    |0.0053   |\n",
      "|modelo_a|2024|6    |0.0046   |\n",
      "|modelo_a|2024|7    |0.0053   |\n",
      "|modelo_a|2024|8    |0.0088   |\n",
      "|modelo_a|2024|9    |3.0E-4   |\n",
      "|modelo_a|2024|10   |0.0067   |\n",
      "|modelo_a|2024|11   |0.0065   |\n",
      "|modelo_a|2024|12   |0.0028   |\n",
      "|modelo_b|2023|7    |0.0504   |\n",
      "|modelo_b|2023|8    |0.0531   |\n",
      "|modelo_b|2023|9    |0.0658   |\n",
      "|modelo_b|2024|1    |0.1138   |\n",
      "|modelo_b|2024|2    |0.5564   |\n",
      "+--------+----+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# üìå N√∫mero de faixas desejadas\n",
    "n_faixas_score = 5\n",
    "\n",
    "# 1Ô∏è‚É£ Gerar pontos de corte com base nos percentis do DEV\n",
    "# Exemplo: [0.2, 0.4, 0.6, 0.8] se n_faixas_score = 5\n",
    "quantiles = [i / n_faixas_score for i in range(1, n_faixas_score)]\n",
    "cuts = spkdf.filter(F.col(\"env\") == \"DEV\").approxQuantile(\"score\", quantiles, 0.001)\n",
    "\n",
    "# 2Ô∏è‚É£ Criar coluna de faixa de score dinamicamente\n",
    "cond = when(F.col(\"score\") <= cuts[0], 1)\n",
    "for i in range(1, len(cuts)):\n",
    "    cond = cond.when((F.col(\"score\") > cuts[i - 1]) & (F.col(\"score\") <= cuts[i]), i + 1)\n",
    "cond = cond.otherwise(n_faixas_score)\n",
    "\n",
    "spkdf = spkdf.withColumn(\"faixa_score\", cond)\n",
    "\n",
    "# 3Ô∏è‚É£ Distribui√ß√£o em DEV (refer√™ncia)\n",
    "base_ref = (\n",
    "    spkdf.filter(F.col(\"env\") == \"DEV\")\n",
    "    .groupBy(\"model\", \"faixa_score\")\n",
    "    .agg(F.count(\"*\").alias(\"total_dev\"))\n",
    ")\n",
    "\n",
    "total_dev = (\n",
    "    spkdf.filter(F.col(\"env\") == \"DEV\")\n",
    "    .groupBy(\"model\")\n",
    "    .agg(F.count(\"*\").alias(\"total_dev_model\"))\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Distribui√ß√£o mensal fora do DEV\n",
    "base_cmp = (\n",
    "    spkdf.filter(F.col(\"env\") != \"DEV\")\n",
    "    .groupBy(\"model\", \"year\", \"month\", \"faixa_score\")\n",
    "    .agg(F.count(\"*\").alias(\"total_mes\"))\n",
    ")\n",
    "\n",
    "total_mes = (\n",
    "    spkdf.filter(F.col(\"env\") != \"DEV\")\n",
    "    .groupBy(\"model\", \"year\", \"month\")\n",
    "    .agg(F.count(\"*\").alias(\"total_mes_model\"))\n",
    ")\n",
    "\n",
    "# 5Ô∏è‚É£ Juntar tudo\n",
    "psi_df = (\n",
    "    base_cmp\n",
    "    .join(base_ref, on=[\"model\", \"faixa_score\"], how=\"left\")\n",
    "    .join(total_dev, on=\"model\", how=\"left\")\n",
    "    .join(total_mes, on=[\"model\", \"year\", \"month\"], how=\"left\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# 6Ô∏è‚É£ Calcular propor√ß√µes e evitar divis√£o por zero\n",
    "psi_df = psi_df.withColumn(\"p_dev\", F.col(\"total_dev\") / F.col(\"total_dev_model\"))\n",
    "psi_df = psi_df.withColumn(\"p_mes\", F.col(\"total_mes\") / F.col(\"total_mes_model\"))\n",
    "psi_df = psi_df.withColumn(\"p_dev\", F.when(F.col(\"p_dev\") == 0, 1e-6).otherwise(F.col(\"p_dev\")))\n",
    "psi_df = psi_df.withColumn(\"p_mes\", F.when(F.col(\"p_mes\") == 0, 1e-6).otherwise(F.col(\"p_mes\")))\n",
    "\n",
    "# 7Ô∏è‚É£ Calcular PSI\n",
    "psi_df = psi_df.withColumn(\n",
    "    \"psi_faixa\",\n",
    "    (F.col(\"p_mes\") - F.col(\"p_dev\")) * F.log(F.col(\"p_mes\") / F.col(\"p_dev\"))\n",
    ")\n",
    "\n",
    "# 8Ô∏è‚É£ Agrupar PSI por m√™s\n",
    "psi_mensal = (\n",
    "    psi_df.groupBy(\"model\", \"year\", \"month\")\n",
    "    .agg(F.round(F.sum(\"psi_faixa\"), 4).alias(\"psi_total\"))\n",
    "    .orderBy(\"model\", \"year\", \"month\")\n",
    ")\n",
    "\n",
    "psi_mensal.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62e59d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+---------+----------+\n",
      "|   model|year|month|psi_total|   periodo|\n",
      "+--------+----+-----+---------+----------+\n",
      "|modelo_a|2023|    7|   0.0082|2023-07-01|\n",
      "|modelo_a|2023|    8|   0.0025|2023-08-01|\n",
      "|modelo_a|2023|    9|   0.0026|2023-09-01|\n",
      "|modelo_a|2024|    1|   0.0019|2024-01-01|\n",
      "|modelo_a|2024|    2|   0.0042|2024-02-01|\n",
      "|modelo_a|2024|    3|   0.0017|2024-03-01|\n",
      "|modelo_a|2024|    4|   0.0022|2024-04-01|\n",
      "|modelo_a|2024|    5|   0.0053|2024-05-01|\n",
      "|modelo_a|2024|    6|   0.0046|2024-06-01|\n",
      "|modelo_a|2024|    7|   0.0053|2024-07-01|\n",
      "+--------+----+-----+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "psi_mensal = psi_mensal.withColumn(\n",
    "    \"periodo\",\n",
    "    to_date(concat_ws(\"-\", \n",
    "                    col(\"year\").cast(\"string\"), \n",
    "                    lpad(col(\"month\").cast(\"string\"), 2, \"0\")), \n",
    "            \"yyyy-MM\")\n",
    ")\n",
    "psi_mensal.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40e519d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.lineplot(\n",
    "    data=psi_mensal.toPandas(),\n",
    "    x=\"periodo\",\n",
    "    y=\"psi_total\",\n",
    "    hue=\"model\",\n",
    "    palette=\"Dark2\",\n",
    "    ax=ax,\n",
    ")\n",
    "# Adicionando as linhas verticais\n",
    "ax.axhline(y=0.1, color='orange', linestyle='-.', linewidth=0.7)\n",
    "ax.axhline(y=0.25, color='red', linestyle='-.', linewidth=0.7)\n",
    "ax.set_title(\"Population Stability Index (PSI)\")\n",
    "ax.set_xlabel(\"Per√≠odo\")\n",
    "ax.set_ylabel(\"psi\")\n",
    "# Ajustando a est√©tica\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.grid(True, linestyle='-', linewidth=0.2)\n",
    "ax.xaxis.grid(True, linestyle='-', linewidth=0.2)\n",
    "\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9293a",
   "metadata": {},
   "source": [
    "**Interpreta√ß√£o dos valores**\n",
    "\n",
    "PSI\tInterpreta√ß√£o\n",
    "*\t< 0.1\tEst√°vel\n",
    "*\t0.1 ‚Äì 0.25\tPequena mudan√ßa\n",
    "*\t\\> 0.25\tMudan√ßa significativa\n",
    "\n",
    "\n",
    "\n",
    "**Coment√°rios sobre performance e escalabilidade**\n",
    "\n",
    "* PySpark permite escalar o PSI para bilh√µes de registros, com uso eficiente de .groupBy(), .agg() e joins.\n",
    "* Evite collect() ou .toPandas() para c√°lculos pesados ‚Äî apenas na visualiza√ß√£o.\n",
    "* UDFs n√£o s√£o necess√°rias para o c√°lculo do PSI ‚Äî use fun√ß√µes nativas sempre que poss√≠vel.\n",
    "* A defini√ß√£o das faixas √© um ponto cr√≠tico. Voc√™ pode testar:\n",
    "* Faixas fixas com percentis (approxQuantile)\n",
    "* Faixas customizadas (Bucketizer, QuantileDiscretizer)\n",
    "* Faixas din√¢micas com ntile (menos recomendado para PSI)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bfd1f5",
   "metadata": {},
   "source": [
    "### 8.2. C√°lculo do KS Test (Kolmogorov-Smirnov)\n",
    "\n",
    "Objetivo: comparar a distribui√ß√£o do score entre eventos (vr=1) e n√£o-eventos (vr=0) dentro de cada m√™s, medindo o poder discriminativo do modelo ao longo do tempo.\n",
    "\n",
    "Passos:\n",
    "\n",
    "* 1.\tCriar a coluna periodo (caso ainda n√£o tenha).\n",
    "* 2.\tPara cada m√™s (periodo), calcular a distribui√ß√£o cumulativa dos scores para vr=1 e vr=0.\n",
    "* 3.\tCalcular a diferen√ßa m√°xima entre essas duas distribui√ß√µes ‚Äî o KS.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f6057c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "spkdf = spkdf.withColumn(\n",
    "    \"periodo\",\n",
    "    to_date(concat_ws(\"-\", \n",
    "                    col(\"year\").cast(\"string\"), \n",
    "                    lpad(col(\"month\").cast(\"string\"), 2, \"0\")), \n",
    "            \"yyyy-MM\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d50dcd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------------------+---+---------------+---------------+---------------+----------------+-----------+----------+\n",
      "|   model|env|year|month|              score| vr|categoria_score|faixa_percentil|score_categoria|evento_relevante|faixa_score|   periodo|\n",
      "+--------+---+----+-----+-------------------+---+---------------+---------------+---------------+----------------+-----------+----------+\n",
      "|modelo_a|DEV|2023|    1|0.06523585398772157|  0|          baixo|             Q3|          baixo|           false|          4|2023-01-01|\n",
      "|modelo_a|DEV|2023|    1|               0.01|  0|          baixo|             Q1|          baixo|           false|          1|2023-01-01|\n",
      "|modelo_a|DEV|2023|    1|0.08752255979032286|  0|          baixo|             Q3|          baixo|           false|          4|2023-01-01|\n",
      "+--------+---+----+-----+-------------------+---+---------------+---------------+---------------+----------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spkdf.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "985d69b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------------+\n",
      "|   model|   periodo|       ks_statistic|\n",
      "+--------+----------+-------------------+\n",
      "|modelo_a|2023-01-01| 0.3023571654480847|\n",
      "|modelo_a|2023-02-01| 0.2919188861985472|\n",
      "|modelo_a|2023-03-01|0.34169100941252833|\n",
      "|modelo_a|2023-04-01| 0.4454285899682045|\n",
      "|modelo_a|2023-05-01| 0.4059580913910628|\n",
      "|modelo_a|2023-06-01| 0.3368421052631579|\n",
      "|modelo_a|2023-07-01| 0.2808305738190078|\n",
      "|modelo_a|2023-08-01| 0.3476154340085226|\n",
      "|modelo_a|2023-09-01|0.36725427350427353|\n",
      "|modelo_a|2024-01-01|0.34201557935735155|\n",
      "|modelo_a|2024-02-01| 0.4633635363745875|\n",
      "|modelo_a|2024-03-01| 0.3195129590478428|\n",
      "|modelo_a|2024-04-01| 0.3427687730013312|\n",
      "|modelo_a|2024-05-01|0.35411434205875236|\n",
      "|modelo_a|2024-06-01|0.32900041135335256|\n",
      "|modelo_a|2024-07-01| 0.3359564638634406|\n",
      "|modelo_a|2024-08-01|0.41110324255885317|\n",
      "|modelo_a|2024-09-01|0.33404255319148934|\n",
      "|modelo_a|2024-10-01| 0.2822336561743341|\n",
      "|modelo_a|2024-11-01|0.25443247567487115|\n",
      "+--------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Criar colunas para evento e n√£o evento\n",
    "df = spkdf.withColumn(\"event\", F.when(F.col(\"vr\") == 1, 1).otherwise(0)) \\\n",
    "        .withColumn(\"non_event\", F.when(F.col(\"vr\") == 0, 1).otherwise(0))\n",
    "\n",
    "# 2. Janelas para agrupamento por model, periodo e ordena√ß√£o pelo score decrescente\n",
    "w_group = Window.partitionBy(\"model\", \"periodo\")\n",
    "w_order = w_group.orderBy(F.desc(\"score\")).rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "# 3. Total de eventos e n√£o eventos por grupo\n",
    "totals = df.groupBy(\"model\", \"periodo\").agg(\n",
    "    F.sum(\"event\").alias(\"total_events\"),\n",
    "    F.sum(\"non_event\").alias(\"total_non_events\"),\n",
    ")\n",
    "\n",
    "df = df.join(totals, on=[\"model\", \"periodo\"], how=\"left\")\n",
    "\n",
    "# 4. C√°lculo acumulado (CDF) eventos e n√£o eventos por score decrescente\n",
    "df = df.withColumn(\"cum_events\", F.sum(\"event\").over(w_order)) \\\n",
    "    .withColumn(\"cum_non_events\", F.sum(\"non_event\").over(w_order))\n",
    "\n",
    "# 5. Distribui√ß√£o acumulada normalizada (CDF)\n",
    "df = df.withColumn(\"cdf_events\", F.col(\"cum_events\") / F.col(\"total_events\")) \\\n",
    "    .withColumn(\"cdf_non_events\", F.col(\"cum_non_events\") / F.col(\"total_non_events\"))\n",
    "\n",
    "# 6. Diferen√ßa absoluta entre as duas CDFs\n",
    "df = df.withColumn(\"diff_cdf\", F.abs(F.col(\"cdf_events\") - F.col(\"cdf_non_events\")))\n",
    "\n",
    "# 7. KS por grupo √© o m√°ximo da diferen√ßa das CDFs\n",
    "ks_df = df.groupBy(\"model\", \"periodo\").agg(\n",
    "    F.max(\"diff_cdf\").alias(\"ks_statistic\")\n",
    ").orderBy(\"model\", \"periodo\")\n",
    "\n",
    "ks_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc84a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------------+\n",
      "|   model|   periodo|                 ks|\n",
      "+--------+----------+-------------------+\n",
      "|modelo_a|2023-01-01|0.30235716544808466|\n",
      "|modelo_a|2023-02-01| 0.2919188861985472|\n",
      "|modelo_a|2023-03-01| 0.3416910094125284|\n",
      "|modelo_a|2023-04-01| 0.4454285899682045|\n",
      "|modelo_a|2023-05-01|0.40595809139106287|\n",
      "|modelo_a|2023-06-01| 0.3368421052631579|\n",
      "|modelo_a|2023-07-01|0.28083057381900783|\n",
      "|modelo_a|2023-08-01| 0.3476154340085226|\n",
      "|modelo_a|2023-09-01|0.36725427350427353|\n",
      "|modelo_a|2024-01-01| 0.3420155793573515|\n",
      "|modelo_a|2024-02-01|0.46336353637458755|\n",
      "|modelo_a|2024-03-01|0.31951295904784277|\n",
      "|modelo_a|2024-04-01|0.34276877300133113|\n",
      "|modelo_a|2024-05-01| 0.3541143420587524|\n",
      "|modelo_a|2024-06-01| 0.3290004113533525|\n",
      "|modelo_a|2024-07-01|0.33595646386344064|\n",
      "|modelo_a|2024-08-01| 0.4111032425588532|\n",
      "|modelo_a|2024-09-01|0.33404255319148934|\n",
      "|modelo_a|2024-10-01|0.28223365617433416|\n",
      "|modelo_a|2024-11-01|0.25443247567487115|\n",
      "+--------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/09 20:02:06 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1066980 ms exceeds timeout 120000 ms\n",
      "25/06/09 20:02:06 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/06/09 20:17:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 20:17:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 20:51:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 20:51:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 20:57:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 20:57:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 21:30:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 21:30:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 21:38:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 21:38:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 21:58:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 21:58:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 22:30:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 22:30:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 22:59:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 22:59:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:15:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:15:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:27:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:27:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:27:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:27:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:28:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:28:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:28:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:28:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:28:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:28:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:28:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:28:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:28:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:28:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:28:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:28:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:29:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:29:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:29:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:29:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:29:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:29:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:29:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:29:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:29:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:29:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:29:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:29:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:30:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:30:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:30:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:31:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:32:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:32:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:32:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:32:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:32:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:32:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:32:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:32:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:32:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:32:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:32:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:32:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:33:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:33:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:33:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/09 23:34:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:34:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:35:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:36:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:36:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@mac:64208\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/09 23:36:08 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, DateType\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Coletar os dados agrupados\n",
    "grouped_data = spkdf.select(\"model\", \"periodo\", \"vr\", \"score\").groupBy(\"model\", \"periodo\").agg(\n",
    "    F.collect_list(\"vr\").alias(\"vr_list\"),\n",
    "    F.collect_list(\"score\").alias(\"score_list\")\n",
    ").collect()\n",
    "\n",
    "ks_results = []\n",
    "for row in grouped_data:\n",
    "    vr_list = row[\"vr_list\"]\n",
    "    score_list = row[\"score_list\"]\n",
    "    \n",
    "    score_0 = [s for v, s in zip(vr_list, score_list) if v == 0]\n",
    "    score_1 = [s for v, s in zip(vr_list, score_list) if v == 1]\n",
    "    \n",
    "    if len(score_0) == 0 or len(score_1) == 0:\n",
    "        ks_value = None\n",
    "    else:\n",
    "        ks_value, _ = ks_2samp(score_0, score_1)\n",
    "        ks_value = float(ks_value)  # üëà convers√£o importante aqui\n",
    "\n",
    "    ks_results.append((row[\"model\"], row[\"periodo\"], ks_value))\n",
    "\n",
    "# Criar DataFrame com schema\n",
    "schema = StructType([\n",
    "    StructField(\"model\", StringType(), True),\n",
    "    StructField(\"periodo\", DateType(), True),\n",
    "    StructField(\"ks\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "ks_df = spark.createDataFrame(ks_results, schema=schema)\n",
    "ks_df.orderBy(\"model\", \"periodo\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892c445",
   "metadata": {},
   "source": [
    "**Compara√ß√£o entre as duas abordagens**\n",
    "\n",
    "‚úÖ Abordagem 1: `ks_2samp` com `collect()`\n",
    "\n",
    "* Como funciona: \n",
    "    Agrupa os dados, coleta para o driver, e calcula o KS no Python puro com ks_2samp.\n",
    "* Pr√≥s:\n",
    "    * F√°cil de implementar e entender.\n",
    "    * Usa a fun√ß√£o estat√≠stica real da scipy, precisa e testada.\n",
    "* Contras:\n",
    "    * üö® Coleta dados para o driver: isso quebra a paraleliza√ß√£o do Spark.\n",
    "    * üö® Limite de mem√≥ria no driver para grandes volumes.\n",
    "    * Lenta e n√£o escal√°vel para milh√µes de registros.\n",
    "\n",
    "\n",
    "\n",
    "‚úÖ Abordagem 2: 100% PySpark com janelas e CDFs\n",
    "\n",
    "* Como funciona: \n",
    "    Usa fun√ß√µes de janela para calcular as CDFs acumuladas diretamente no Spark.\n",
    "* Pr√≥s:\n",
    "    * ‚ö° Totalmente distribu√≠da e paralelizada.\n",
    "    * Escal√°vel para grandes volumes de dados.\n",
    "    * Evita collect(), mantendo o processamento nos workers.\n",
    "    * Mais eficiente para grandes bases com muitos grupos.\n",
    "* Contras:\n",
    "    * Ligeiramente mais complexa de implementar.\n",
    "    * Pode consumir mais mem√≥ria nos workers dependendo do tamanho dos grupos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a4a7d",
   "metadata": {},
   "source": [
    "### 8.3. CSI (Characteristic Stability Index)\n",
    "\n",
    "Objetivo: verificar a estabilidade de vari√°veis explicativas (features) ao longo do tempo. Por exemplo, se a distribui√ß√£o de score mudou m√™s a m√™s comparado a um per√≠odo de refer√™ncia (como o DEV).\n",
    "\n",
    "Passos:\n",
    "\n",
    "* Definir o ambiente de refer√™ncia (ex: DEV).\n",
    "* Criar faixas (bins) para a vari√°vel (score), baseadas no DEV.\n",
    "* Para cada m√™s:\n",
    "    * Calcular a propor√ß√£o de registros em cada faixa.\n",
    "    * Comparar com a propor√ß√£o da base de refer√™ncia usando a f√≥rmula do CSI:\n",
    "        $$CSI = \\sum \\left( (P_i - Q_i) \\cdot \\log\\left(\\frac{P_i}{Q_i}\\right) \\right)$$\n",
    "onde:\n",
    "\n",
    "* $P_i$: propor√ß√£o da faixa no m√™s atual\n",
    "* $Q_i$: propor√ß√£o da faixa na base de refer√™ncia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ffd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------+\n",
      "|   model|periodo|   csi|\n",
      "+--------+-------+------+\n",
      "|modelo_a|2023-07|0.0059|\n",
      "|modelo_b|2023-07| 0.049|\n",
      "|modelo_a|2023-08|0.0024|\n",
      "|modelo_b|2023-08|0.0492|\n",
      "|modelo_a|2023-09|0.0026|\n",
      "|modelo_b|2023-09|0.0631|\n",
      "|modelo_a|2024-01|7.0E-4|\n",
      "|modelo_b|2024-01|0.0946|\n",
      "|modelo_a|2024-02|0.0036|\n",
      "|modelo_b|2024-02|0.4872|\n",
      "|modelo_a|2024-03|8.0E-4|\n",
      "|modelo_b|2024-03|1.1972|\n",
      "|modelo_a|2024-04| 0.002|\n",
      "|modelo_b|2024-04|2.0199|\n",
      "|modelo_a|2024-05|0.0052|\n",
      "|modelo_b|2024-05|2.5983|\n",
      "|modelo_a|2024-06|0.0045|\n",
      "|modelo_b|2024-06| 3.535|\n",
      "|modelo_a|2024-07|0.0048|\n",
      "|modelo_b|2024-07|4.8706|\n",
      "+--------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reutilizar as faixas de score baseadas no DEV\n",
    "percentis = spkdf.filter(F.col(\"env\") == \"DEV\").approxQuantile(\"score\", [0.2, 0.4, 0.6, 0.8], 0.001)\n",
    "faixas = [-float(\"inf\")] + percentis + [float(\"inf\")]\n",
    "\n",
    "# Aplicar faixas\n",
    "bucketizer = Bucketizer(\n",
    "    splits=faixas,\n",
    "    inputCol=\"score\",\n",
    "    outputCol=\"score_bin\"\n",
    ")\n",
    "spkdf_binned = bucketizer.transform(spkdf)\n",
    "\n",
    "# Criar coluna per√≠odo\n",
    "spkdf_binned = spkdf_binned.withColumn(\n",
    "    \"periodo\",\n",
    "    F.concat_ws(\"-\", F.col(\"year\").cast(\"string\"), F.lpad(F.col(\"month\").cast(\"string\"), 2, \"0\"))\n",
    ")\n",
    "\n",
    "# Contagem de propor√ß√µes por modelo, faixa e per√≠odo\n",
    "dist_ref = spkdf_binned.filter(F.col(\"env\") == \"DEV\").groupBy(\"model\", \"score_bin\") \\\n",
    "    .agg(F.count(\"*\").alias(\"ref_total\"))\n",
    "dist_total = spkdf_binned.filter(F.col(\"env\") == \"DEV\").groupBy(\"model\") \\\n",
    "    .agg(F.count(\"*\").alias(\"ref_model_total\"))\n",
    "dist_ref = dist_ref.join(dist_total, on=\"model\")\n",
    "dist_ref = dist_ref.withColumn(\"p_ref\", F.col(\"ref_total\") / F.col(\"ref_model_total\"))\n",
    "\n",
    "# CSI mensal fora de DEV\n",
    "dist_cmp = spkdf_binned.filter(F.col(\"env\") != \"DEV\").groupBy(\"model\", \"periodo\", \"score_bin\") \\\n",
    "    .agg(F.count(\"*\").alias(\"cmp_total\"))\n",
    "cmp_total = spkdf_binned.filter(F.col(\"env\") != \"DEV\").groupBy(\"model\", \"periodo\") \\\n",
    "    .agg(F.count(\"*\").alias(\"cmp_model_total\"))\n",
    "dist_cmp = dist_cmp.join(cmp_total, on=[\"model\", \"periodo\"])\n",
    "dist_cmp = dist_cmp.withColumn(\"p_cmp\", F.col(\"cmp_total\") / F.col(\"cmp_model_total\"))\n",
    "\n",
    "# Juntar e calcular CSI\n",
    "csi = dist_cmp.join(dist_ref.select(\"model\", \"score_bin\", \"p_ref\"), on=[\"model\", \"score_bin\"], how=\"left\")\n",
    "csi = csi.fillna(1e-6)  # evitar log(0)\n",
    "csi = csi.withColumn(\"csi_score\",\n",
    "    (F.col(\"p_ref\") - F.col(\"p_cmp\")) * F.log(F.col(\"p_ref\") / F.col(\"p_cmp\"))\n",
    ")\n",
    "\n",
    "# CSI total por m√™s\n",
    "csi_mensal = csi.groupBy(\"model\", \"periodo\").agg(F.sum(\"csi_score\").alias(\"csi\"))\n",
    "csi_mensal = csi_mensal.withColumn(\"csi\", F.round(\"csi\", 4))\n",
    "csi_mensal.orderBy(\"periodo\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
